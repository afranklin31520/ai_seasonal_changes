title,author,pub_date,full_text,keywords,Actants,Relationships
Google’s AI-powered Ask Photos feature begins U.S. rollout,Sarah Perez,2024-09-05,"First announced at Google’s I/O developer conference this May, Google Photos’ AI-powered search feature, “Ask Photos,” is rolling out to users starting Thursday. The feature, which allows users to ask the AI to find photos using more complex queries, will initially be available in “early access” to select customers in the U.S. before expanding to a wider user base.Powered by Google’s Gemini AI model, Ask Photos lets users search their photos using natural language queries that leverage the AI’s understanding of their photo’s content and other metadata. Previously, Google Photos users could search for particular people, places or things in their photos, but the AI upgrade will allow them to ask a larger variety of questions, including those that require a deeper understanding of the photos.Image Credits: GoogleFor example, as Google suggested during I/O, you could ask for the “best photo from each of the National Parks I visited.” The AI uses a variety of signals to determine what’s the “best” of a given set, including things like lighting, blurriness, and lack of background distortion, among other things. It would then combine that with its understanding of the geolocation of the photos to find those taken at National Parks.Google said the feature could be used for more than just photo retrieval alone; users would also be able to ask questions to get helpful answers. For instance, a parent could ask Google Photos what themes they had used for their child’s last four birthdays. The AI would be able to analyze party photos and determine if a theme was involved, like “mermaid,” “princess,” “superhero” or anything else. It could then tell the parent when those themes were last used.Image Credits: GoogleMore practical questions could be those that help you recall a specific event, like “what did we order last time at this restaurant” — presuming you like to photograph your meals. Or you could ask “where did we camp last time” at a specific destination, like Yosemite, the company suggests. You could also use the feature to help you put together photos for an album or to summarize all the things you did on a trip.The AI understands the context of your photo gallery, including the important people in your life, your hobbies, your favorite foods, and other relevant details and memories. To access Ask Photos, select U.S. users will be able to find the feature within Google Labs, as it’s still in the experimental phase. The company says the feature’s development is guided by its AI Principles, and the private data in Photos will never be used for ad targeting. However, Google employees may review users’ queries to help improve the AI over time. The AI’s answers will not be reviewed by humans, unless the user reaches out for support, to provide feedback, or to report abuse or harm. Interested users can sign up on the waitlist for early access to Ask Photos.","AI, Ask Photos, Google","[{""Actant Name"": ""Google Photos"", ""Category"": ""Technological Actant"", ""Role/Function"": ""A photo management and sharing service that incorporates the Ask Photos feature.""}, {""Actant Name"": ""Ask Photos"", ""Category"": ""Technological Actant"", ""Role/Function"": ""An AI-powered search feature that allows users to find photos using natural language queries.""}, {""Actant Name"": ""Gemini AI"", ""Category"": ""Technological Actant"", ""Role/Function"": ""The AI model powering the Ask Photos feature, enabling complex photo searches.""}, {""Actant Name"": ""Google"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""The company developing and rolling out the Ask Photos feature.""}, {""Actant Name"": ""U.S. Users"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""The initial group of users who will have early access to the Ask Photos feature.""}, {""Actant Name"": ""Google Labs"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""The platform within Google where users can access the experimental Ask Photos feature.""}, {""Actant Name"": ""AI Principles"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""Guidelines that govern the development and use of AI features at Google.""}, {""Actant Name"": ""National Parks"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""Locations referenced in user queries for photo retrieval.""}, {""Actant Name"": ""Yosemite"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""A specific location mentioned in user queries for photo retrieval.""}, {""Actant Name"": ""Waitlist"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""A system for interested users to sign up for early access to the Ask Photos feature.""}]","[{""Source Actant"": ""Google"", ""Relationship Type"": ""develops"", ""Target Actant"": ""Ask Photos""}, {""Source Actant"": ""Ask Photos"", ""Relationship Type"": ""powered by"", ""Target Actant"": ""Gemini AI""}, {""Source Actant"": ""Google Photos"", ""Relationship Type"": ""includes"", ""Target Actant"": ""Ask Photos""}, {""Source Actant"": ""U.S. Users"", ""Relationship Type"": ""access"", ""Target Actant"": ""Ask Photos""}, {""Source Actant"": ""Ask Photos"", ""Relationship Type"": ""utilizes"", ""Target Actant"": ""Gemini AI""}, {""Source Actant"": ""Google"", ""Relationship Type"": ""guides development by"", ""Target Actant"": ""AI Principles""}, {""Source Actant"": ""Ask Photos"", ""Relationship Type"": ""analyzes"", ""Target Actant"": ""photo metadata""}, {""Source Actant"": ""Ask Photos"", ""Relationship Type"": ""retrieves photos from"", ""Target Actant"": ""National Parks""}, {""Source Actant"": ""Ask Photos"", ""Relationship Type"": ""retrieves photos from"", ""Target Actant"": ""Yosemite""}, {""Source Actant"": ""Interested Users"", ""Relationship Type"": ""sign up for"", ""Target Actant"": ""Waitlist""}]"
All Hands AI raises $5M to build open source agents for developers,Frederic Lardinois,2024-09-05,"At its best, programming is a creative endeavor, but in this age of shifting everything left, much of a developer’s day is filled with what All Hands AI co-founder and CEO Robert Brennan calls the “toil-oriented task” like writing unit tests, managing dependencies and keeping documentation up to date. AI, on the other hand, may not be creative, but it is pretty good at exactly those routine tasks. All Hands AI, which announced a $5 million seed funding round led by Menlo Ventures on Thursday, aims to build model-agnostic open source AI agents that can handle most of this toil and allow developers to focus more of their time on doing what they do best.Image Credits: All Hands AIA few months ago, AI Cognition showed off Devin, an AI agent that could plan and execute complex engineering tasks — and maybe more importantly: build and deploy new applications end-to-end.“The Cognition folks came out with their Devin demo and I — and I think every other software engineer in the world — was amazed at that video,” Brennan said in an interview ahead of Thursday’s announcement. “I think it really catalyzed in our imagination what the future of development is going to look like, but also kind of scared us that it was being developed as closed source and that it was being kept in this walled garden we couldn’t see and contribute to and really own as a development community.”This open source project, which started out as OpenDevin earlier this year and is now called OpenHands, started with a text file on GitHub and now has over 30,000 stars and more than 150 contributors.Image Credits: All Hands AIThe idea is for the OpenHands agent to become a proactive pair programmer who works hand-in-hand with the developer and who can handle much of the toil of a developer’s day-to-day work. That may involve writing tests and deploying and application, but also recognizing that a change in one file (maybe the name of a function) might influence how other parts of the application function and asking the developer if it should adjust the affected files accordingly.“AI is going to completely change how developers work. But it’s not going to change their preference for adopting open source, especially when it comes to technology that affects their day-to-day work,” said Joff Redfern, a partner at Menlo Ventures and former chief product officer at Atlassian. “By building in the open, All Hands is helping the software engineering community work toward an ideal AI-powered development experience.”Image Credits: All Hands AIBrennan and his two co-founders, Xingyao Wang (chief AI officer) and Graham Neubig (chief scientist), have extensive experience in working in natural language processing and building agents. Brennan previously worked on document summarization at Google and then in executive roles at a number of startups, working on machine learning and infrastructure projects. Neubig is an associate professor at Carnegie Mellon with extensive experience in natural language processing; Wang is interrupting his doctorate program at the University of Illinois Urbana-Champaign, where he did research on interactive language agents powered by foundation models.“None of us were surprised to see the Cognition demo in terms of technology,” Brennan said. “We all knew that this was there, but seeing it all come together into a user experience really just excited us to start pushing on building that in the open.” Brennan also noted that while tools like Copilot are very helpful for developers, they aren’t (yet) focused on the entire “agentic loop of writing code” akin to a self-driving car. That’s what All Hands AI is aiming for, even if this still remains somewhat aspirational. It’s not like you can give the agent access to a company’s entire JIRA backlog and let it loose and accomplishing every task in that. Indeed, Brennan — like most people in the industry today — thinks that there will be a need for human developers in the loop for a very long time.Image Credits: All Hands AIThere are also still unsolved questions around what the user/developer experience for such a system should look actually like. All Hands AI does have a designer on staff, though, and it’s good to see it looking into these questions early on. Right now, the experience is also still somewhat decoupled from the development environment, but the team plans to build integrations with VS Code and other editors soon.As with many open source startups, All Hands AI expects to monetize its service by offering paid, closed-source enterprise features. “We think that there’s a bunch of software that we can build that complements the open source that’s really delivering value to big enterprises where we can feel good about building that in a closed source way to help make sure that we have a sustainable open source project that’s getting financial contribution back from the larger enterprises that are using it,” Brennan said.With this first funding round, though, the team plans to build out its technology stack before it delves deeper into monetizing the service. In addition to Menlo, which led this round, Pillar VC, Betaworks and Rebellion also participated. The company also brought on a number of angels, including Hugging Face co-founder Thom Wolf; Cloudera co-founder Jeff Hammerbacher; and PyTorch creator and Meta VP Soumith Chintala.","AI, All Hands AI, autonomous software agents, Enterprise, seed funding","[{""Actant Name"": ""All Hands AI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Developing open source AI agents for developers.""}, {""Actant Name"": ""Robert Brennan"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder and CEO of All Hands AI.""}, {""Actant Name"": ""Menlo Ventures"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Led the $5 million seed funding round for All Hands AI.""}, {""Actant Name"": ""Devin"", ""Category"": ""Technological Actant"", ""Role/Function"": ""AI agent demonstrated by AI Cognition capable of planning and executing engineering tasks.""}, {""Actant Name"": ""OpenHands"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Open source project aimed at creating a proactive AI pair programmer.""}, {""Actant Name"": ""Joff Redfern"", ""Category"": ""Human Actant"", ""Role/Function"": ""Partner at Menlo Ventures and former chief product officer at Atlassian.""}, {""Actant Name"": ""Xingyao Wang"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder and chief AI officer at All Hands AI.""}, {""Actant Name"": ""Graham Neubig"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder and chief scientist at All Hands AI.""}, {""Actant Name"": ""Carnegie Mellon"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""University where Graham Neubig is an associate professor.""}, {""Actant Name"": ""University of Illinois Urbana-Champaign"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""University where Xingyao Wang conducted research.""}, {""Actant Name"": ""Copilot"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Tool that assists developers but is not focused on the entire agentic loop of writing code.""}, {""Actant Name"": ""VS Code"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Development environment where All Hands AI plans to build integrations.""}, {""Actant Name"": ""Hugging Face"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Company associated with angel investor Thom Wolf.""}, {""Actant Name"": ""Cloudera"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Company associated with angel investor Jeff Hammerbacher.""}, {""Actant Name"": ""PyTorch"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Framework associated with angel investor Soumith Chintala.""}, {""Actant Name"": ""Meta"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Company associated with angel investor Soumith Chintala.""}, {""Actant Name"": ""Pillar VC"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Participated in the seed funding round for All Hands AI.""}, {""Actant Name"": ""Betaworks"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Participated in the seed funding round for All Hands AI.""}, {""Actant Name"": ""Rebellion"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Participated in the seed funding round for All Hands AI.""}]","[{""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""develops"", ""Target Actant"": ""OpenHands""}, {""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""receives funding from"", ""Target Actant"": ""Menlo Ventures""}, {""Source Actant"": ""Menlo Ventures"", ""Relationship Type"": ""leads"", ""Target Actant"": ""seed funding round""}, {""Source Actant"": ""Robert Brennan"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""All Hands AI""}, {""Source Actant"": ""Xingyao Wang"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""All Hands AI""}, {""Source Actant"": ""Graham Neubig"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""All Hands AI""}, {""Source Actant"": ""Graham Neubig"", ""Relationship Type"": ""works at"", ""Target Actant"": ""Carnegie Mellon""}, {""Source Actant"": ""Xingyao Wang"", ""Relationship Type"": ""conducted research at"", ""Target Actant"": ""University of Illinois Urbana-Champaign""}, {""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""plans to integrate with"", ""Target Actant"": ""VS Code""}, {""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""aims to build"", ""Target Actant"": ""open source AI agents""}, {""Source Actant"": ""Devin"", ""Relationship Type"": ""demonstrated by"", ""Target Actant"": ""AI Cognition""}, {""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""aims to change"", ""Target Actant"": ""developer work""}, {""Source Actant"": ""All Hands AI"", ""Relationship Type"": ""expects to monetize"", ""Target Actant"": ""closed-source enterprise features""}, {""Source Actant"": ""Hugging Face"", ""Relationship Type"": ""associated with"", ""Target Actant"": ""Thom Wolf""}, {""Source Actant"": ""Cloudera"", ""Relationship Type"": ""associated with"", ""Target Actant"": ""Jeff Hammerbacher""}, {""Source Actant"": ""PyTorch"", ""Relationship Type"": ""associated with"", ""Target Actant"": ""Soumith Chintala""}, {""Source Actant"": ""Meta"", ""Relationship Type"": ""associated with"", ""Target Actant"": ""Soumith Chintala""}, {""Source Actant"": ""Pillar VC"", ""Relationship Type"": ""participated in"", ""Target Actant"": ""seed funding round""}, {""Source Actant"": ""Betaworks"", ""Relationship Type"": ""participated in"", ""Target Actant"": ""seed funding round""}, {""Source Actant"": ""Rebellion"", ""Relationship Type"": ""participated in"", ""Target Actant"": ""seed funding round""}]"
Mintlify is building a next-gen platform for writing software docs,Kyle Wiggers,2024-09-05,"Software documentation — the resources that explain how software works and how to use it — has evolved dramatically over the past few decades. Once mostly in the form of PDFs and static plaintext, docs today are more interactive and user-friendly than they used to be.But crafting them is still a time sink. Han Wang and Hahnbee Lee, both devs and entrepreneurs, say that they’ve personally struggled with this.“In the 2010s, companies like Stripe, Hashicorp, Twilio and a bunch others raised the bar on developer content,” Wang said. “They proved that a truly great developer experience for their content is not just a commodity, but a competitive advantage. Since then, every company has been trying to catch up, but it’s actually quite difficult.”Inspired to try simplifying the workflows to publish docs (mainly to make their own lives easier), Wang and Lee created Mintlify, a collection of documentation-authoring tools, including tools that can auto-generate docs from codebases.“In the 2020s, the bar for documentation is rising once again,” Wang said. “This time, it’s not just with the UI, but the way developers and editors are fundamentally interacting with the content because of AI.”An AI-powered visionWang and Lee met in college. The two attended Cornell; Lee was a computer science undergrad, and Wang was studying for a bachelor’s in information science.As a student, Wang founded two companies: FoodFul, a system for remotely monitoring livestock, and People, a platform to build customer communities. After People (which Lee helped found) was acquired by user engagement firm Bettermode, Wang stayed on for several months but eventually left to become a partner at Bain Capital Ventures.Wang left Bain in 2021, which happened to be right around the time he and Lee had the idea for Mintlify. They raised seed capital from Bain (leveraging Wang’s connections) and others, including Sourcegraph co-founder Quinn Slack, to grow the platform into a business.At a high level, Mintlify assists devs with writing guides, API references, SDK docs and chatbots (powered by OpenAI’s API) to explain the ins and outs of their software and services. It provides built-in components and templates for basic doc formatting, and structures docs so that they can be embedded in a codebase.Mintlify provides tools to write and maintain documentation for software, including tools that auto-update docs.Image Credits: MintlifyTo help maintain docs, Mintlify also routinely scans for “stale” documentation and detects how users are engaging with the content to suggest ways to improve readability.But there is some criticism of Mintlify’s automation features.An early user, DevClass’ Tim Anderson, claims Mintlify adds comments to codebases that are of “little value,” and in one instance repeated the same factually wrong sentence in a doc four times over. Others have pointed out that Mintlify can be confused by disorganized and unoptimized, or otherwise poorly written, code.Wang emphasizes the potential of the platform’s AI over its limitations, while implying that humans can’t be removed from the documentation-writing loop entirely.“As we saw it, the role of content was changing with AI. Documentation will evolve automatically in real time from support messages, the codebase and product feedback,” Wang said. “AI assistance will help companies write technical content automatically based on product changes and user feedback.”An expanding business Mintlify isn’t the only startup trying to revamp how devs make and publish technical guides.There’s Guidde, whose AI automatically generates software documentation videos. More in line with what Mintlify’s doing, Documatic automatically produces changelogs and explanations from code in addition to documentation.I mentioned rivals to Wang, and he responded by highlighting Mintlify’s rather impressive customer list, which includes Anthropic, Cursor, Perplexity, Zapier, Polymarket, Fidelity and around 3,000 other brands. (Wang estimates that Mintlify’s tools reach over 1.5 million developers a month.) He also hinted at differentiating capabilities coming to the Mintlify platform in the near future.“Every documentation now needs to have an AI chat to answer questions directly. But it will go much deeper into that,” Wang said. “Content creation will also change … The content will be used to power support, chatbots and generative AI models themselves. Content will also be personalized for every reader.”To make that vision a reality, Mintlify recently closed a $18.5 million Series A funding round led by Andreessen Horowitz with participation from Bain and Y Combinator. (Andreessen Horowitz general partner Jennifer Li is joining Mintlify’s board as a part of the deal.) This brings Mintlify’s total raised to $21.7 million; Wang says that the new cash will be put toward expanding Mintlify’s 11-person team and product development.“We have always focused on operating lean and efficiently,” Wang said. “We did not need to fundraise, but strategically decided to in order to fuel further growth.”Wang declined to answer questions about Mintlify’s revenue and profitability.","AI, AI, coding, Dev, documentation, Enterprise, Funding, Fundraising, Generative AI, Mintlify, programming, Software, Startups, Startups","[{""Actant Name"": ""Mintlify"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A platform providing documentation-authoring tools for developers.""}, {""Actant Name"": ""Han Wang"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder of Mintlify and developer focused on improving documentation workflows.""}, {""Actant Name"": ""Hahnbee Lee"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder of Mintlify and developer involved in creating documentation tools.""}, {""Actant Name"": ""Bain Capital Ventures"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Investment firm that provided seed capital to Mintlify.""}, {""Actant Name"": ""Quinn Slack"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder of Sourcegraph who invested in Mintlify.""}, {""Actant Name"": ""OpenAI API"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Technology used by Mintlify to power chatbots and enhance documentation.""}, {""Actant Name"": ""Andreessen Horowitz"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Venture capital firm that led Mintlify's Series A funding round.""}, {""Actant Name"": ""Y Combinator"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Investment firm that participated in Mintlify's Series A funding round.""}, {""Actant Name"": ""Tim Anderson"", ""Category"": ""Human Actant"", ""Role/Function"": ""An early user of Mintlify who provided critical feedback on its automation features.""}, {""Actant Name"": ""Guidde"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A startup that competes with Mintlify by generating software documentation videos.""}, {""Actant Name"": ""Documatic"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A startup that competes with Mintlify by producing changelogs and explanations from code.""}, {""Actant Name"": ""Anthropic"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""Cursor"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""Perplexity"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""Zapier"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""Polymarket"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""Fidelity"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the notable customers using Mintlify's tools.""}, {""Actant Name"": ""2021"", ""Category"": ""Temporal Actant"", ""Role/Function"": ""The year when Wang left Bain and the idea for Mintlify was conceived.""}, {""Actant Name"": ""$18.5 million"", ""Category"": ""Economic Actant"", ""Role/Function"": ""Amount raised in Mintlify's Series A funding round.""}, {""Actant Name"": ""$21.7 million"", ""Category"": ""Economic Actant"", ""Role/Function"": ""Total funding raised by Mintlify to date.""}, {""Actant Name"": ""11-person team"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""The size of Mintlify's team that will be expanded with new funding.""}, {""Actant Name"": ""1.5 million developers"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Estimated number of developers reached by Mintlify's tools monthly.""}]","[{""Source Actant"": ""Han Wang"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""Mintlify""}, {""Source Actant"": ""Hahnbee Lee"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""Mintlify""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""provides"", ""Target Actant"": ""documentation-authoring tools""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""leverages"", ""Target Actant"": ""OpenAI API""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""raised"", ""Target Actant"": ""$18.5 million""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""raised"", ""Target Actant"": ""$21.7 million""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""assists"", ""Target Actant"": ""developers""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Anthropic""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Cursor""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Perplexity""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Zapier""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Polymarket""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""has customers"", ""Target Actant"": ""Fidelity""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Guidde""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Documatic""}, {""Source Actant"": ""Wang"", ""Relationship Type"": ""left"", ""Target Actant"": ""Bain Capital Ventures""}, {""Source Actant"": ""Bain Capital Ventures"", ""Relationship Type"": ""invested in"", ""Target Actant"": ""Mintlify""}, {""Source Actant"": ""Quinn Slack"", ""Relationship Type"": ""invested in"", ""Target Actant"": ""Mintlify""}, {""Source Actant"": ""Andreessen Horowitz"", ""Relationship Type"": ""led"", ""Target Actant"": ""Mintlify's Series A funding round""}, {""Source Actant"": ""Y Combinator"", ""Relationship Type"": ""participated in"", ""Target Actant"": ""Mintlify's Series A funding round""}, {""Source Actant"": ""Tim Anderson"", ""Relationship Type"": ""provided feedback on"", ""Target Actant"": ""Mintlify""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""employs"", ""Target Actant"": ""11-person team""}, {""Source Actant"": ""Mintlify"", ""Relationship Type"": ""reaches"", ""Target Actant"": ""1.5 million developers""}, {""Source Actant"": ""2021"", ""Relationship Type"": ""is the year when"", ""Target Actant"": ""Wang left Bain""}, {""Source Actant"": ""2021"", ""Relationship Type"": ""is the year when"", ""Target Actant"": ""Mintlify was conceived""}]"
German LLM maker Aleph Alpha pivots to AI support,Natasha Lomas,2024-09-05,"Europe doesn’t have many large language model (LLM) makers but one of these rare AI beasts — Germany’s Aleph Alpha — appears to be preparing to rule itself out of the running, per Bloomberg, which has an interview with CEO Jonas Andrulis on its pivot to a broader generative AI-support play. The idea with a product it unveiled last week, called PhariaAI, is to help other companies or the public sector use AI tools regardless of whether it made the underlying tech. “The world changed,” Andrulis told Bloomberg. “Just having an European LLM is not sufficient as a business model. It doesn’t justify the investment.”Aleph Alpha raised a $500 million Series B round last November. But with category giants like OpenAI having far beefier war chests to fuel development — and, closer to home, France’s Mistral has also raked in more investor cash — the German startup had its work cut out to stay in the LLM fight.","AI, In Brief, large language models","[{""Actant Name"": ""Aleph Alpha"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""German LLM maker pivoting to broader generative AI support.""}, {""Actant Name"": ""Jonas Andrulis"", ""Category"": ""Human Actant"", ""Role/Function"": ""CEO of Aleph Alpha discussing the company's strategic pivot.""}, {""Actant Name"": ""PhariaAI"", ""Category"": ""Technological Actant"", ""Role/Function"": ""New product unveiled by Aleph Alpha to assist companies and the public sector in using AI tools.""}, {""Actant Name"": ""OpenAI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Competitor with significant funding in the LLM space.""}, {""Actant Name"": ""Mistral"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""French LLM maker that has raised substantial investor cash.""}, {""Actant Name"": ""Bloomberg"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Media outlet reporting on Aleph Alpha's pivot.""}, {""Actant Name"": ""European LLM Market"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Contextual environment in which Aleph Alpha operates.""}, {""Actant Name"": ""$500 million"", ""Category"": ""Economic Actant"", ""Role/Function"": ""Amount raised by Aleph Alpha in a Series B funding round.""}, {""Actant Name"": ""November 2023"", ""Category"": ""Temporal Actant"", ""Role/Function"": ""Date when Aleph Alpha raised its Series B funding.""}]","[{""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""unveils"", ""Target Actant"": ""PhariaAI""}, {""Source Actant"": ""Jonas Andrulis"", ""Relationship Type"": ""leads"", ""Target Actant"": ""Aleph Alpha""}, {""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""raises"", ""Target Actant"": ""$500 million""}, {""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""OpenAI""}, {""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Mistral""}, {""Source Actant"": ""Bloomberg"", ""Relationship Type"": ""reports on"", ""Target Actant"": ""Aleph Alpha""}, {""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""operates in"", ""Target Actant"": ""European LLM Market""}, {""Source Actant"": ""Aleph Alpha"", ""Relationship Type"": ""funded in"", ""Target Actant"": ""November 2023""}]"
"The AI industry is obsessed with Chatbot Arena, but it might not be the best benchmark",Kyle Wiggers,2024-09-05,"Over the past few months, tech execs like Elon Musk have touted the performance of their company’s AI models on a particular benchmark: Chatbot Arena.Maintained by a non-profit known as LMSYS, Chatbot Arena has become something of an industry obsession. Posts about updates to its model leaderboards garner hundreds of views and reshares across Reddit and X, and the official LMSYS X account has over 54,000 followers. Millions of people have visited the organization’s website in the last year alone.Still, there are some lingering questions about Chatbot Arena’s ability to tell us how “good” these models really are.In search of a new benchmarkBefore we dive in, let’s take a moment to understand what LMSYS is exactly, and how it became so popular.The non-profit only launched last April as a project spearheaded by students and faculty at Carnegie Mellon, UC Berkeley’s SkyLab and UC San Diego. Some of the founding members now work at Google DeepMind, Musk’s xAI and Nvidia; today, LMSYS is primarily run by SkyLab-affiliated researchers.LMSYS didn’t set out to create a viral model leaderboard. The group’s founding mission was making models (specifically generative models à la OpenAI’s ChatGPT) more accessible by co-developing and open-sourcing them. But shortly after LMSYS’ founding, its researchers, dissatisfied with the state of AI benchmarking, saw value in creating a testing tool of their own.“Current benchmarks fail to adequately address the needs of state-of-the-art [models], particularly in evaluating user preferences,” the researchers wrote in a technical paper published in March. “Thus, there is an urgent necessity for an open, live evaluation platform based on human preference that can more accurately mirror real-world usage.”Indeed, as we’ve written before, the most commonly used benchmarks today do a poor job of capturing how the average person interacts with models. Many of the skills the benchmarks probe for — solving Ph.D.-level math problems, for example — will rarely be relevant to the majority of people using, say, Claude.LMSYS’ creators felt similarly, and so they devised an alternative: Chatbot Arena, a crowdsourced benchmark designed to capture the “nuanced” aspects of models and their performance on open-ended, real-world tasks.The Chatbot Arena rankings as of early September 2024.Image Credits: LMSYSChatbot Arena lets anyone on the web ask a question (or questions) of two randomly-selected, anonymous models. Once a person agrees to the ToS allowing their data to be used for LMSYS’ future research, models and related projects, they can vote for their preferred answers from the two dueling models (they can also declare a tie or say “both are bad”), at which point the models’ identities are revealed.The Chatbot Arena interface.Image Credits: LMSYSThis flow yields a “diverse array” of questions a typical user might ask of any generative model, the researchers wrote in the March paper. “Armed with this data, we employ a suite of powerful statistical techniques […] to estimate the ranking over models as reliably and sample-efficiently as possible,” they explained.Since Chatbot Arena’s launch, LMSYS has added dozens of open models to its testing tool, and partnered with universities like Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), as well as companies including OpenAI, Google, Anthropic, Microsoft, Meta, Mistral and Hugging Face to make their models available for testing. Chatbot Arena now features more than 100 models, including multimodal models (models that can understand data beyond just text) like OpenAI’s GPT-4o and Anthropic’s Claude 3.5 Sonnet.Over a million prompts and answer pairs have been submitted and evaluated this way, producing a huge body of ranking data.Bias, and lack of transparencyIn the March paper, LMSYS’ founders claim that Chatbot Arena’s user-contributed questions are “sufficiently diverse” to benchmark for a range of AI use cases. “Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced model leaderboards,” they write.But how informative are the results, really? That’s up for debate. Yuchen Lin, a research scientist at the non-profit Allen Institute for AI, says that LMSYS hasn’t been completely transparent about the model capabilities, knowledge and skills it’s assessing on Chatbot Arena. In March, LMSYS released a data set, LMSYS-Chat-1M, containing a million conversations between users and 25 models on Chatbot Arena. But it hasn’t refreshed the data set since.“The evaluation is not reproducible, and the limited data released by LMSYS makes it challenging to study the limitations of models in depth,” Lin said.Comparing two models using Chatbot Arena’s tool.Image Credits: LMSYSTo the extent that LMSYS has detailed its testing approach, its researchers said in the March paper that they leverage “efficient sampling algorithms” to pit models against each other “in a way that accelerates the convergence of rankings while retaining statistical validity.” They wrote that LMSYS collects roughly 8,000 votes per model before it refreshes the Chatbot Arena rankings, and that threshold is usually reached after several days.But Lin feels the voting isn’t accounting for people’s ability — or inability — to spot hallucinations from models, nor differences in their preferences, which makes their votes unreliable. For example, some users might like longer, markdown-styled answers, while others may prefer more succinct responses.The upshot here is that two users might give opposite answers to the same answer pair, and both would be equally valid — but that kind of questions the value of the approach fundamentally. Only recently has LMSYS experimented with controlling for the “style” and “substance” of models’ responses in Chatbot Arena.“The human preference data collected does not account for these subtle biases, and the platform does not differentiate between ‘A is significantly better than B’ and ‘A is only slightly better than B,’” Lin said. “While post-processing can mitigate some of these biases, the raw human preference data remains noisy.”Mike Cook, a research fellow at Queen Mary University of London specializing in AI and game design, agreed with Lin’s assessment. “You could’ve run Chatbot Arena back in 1998 and still talked about dramatic ranking shifts or big powerhouse chatbots, but they’d be terrible,” he added, noting that while Chatbot Arena is framed as an empirical test, it amounts to a relative rating of models.The more problematic bias hanging over Chatbot Arena’s head is the current makeup of its user base. Because the benchmark became popular almost entirely through word of mouth in AI and tech industry circles, it’s unlikely to have attracted a very representative crowd, Lin says. Lending credence to his theory, the top questions in the LMSYS-Chat-1M data set pertain to programming, AI tools, software bugs and fixes, and app design — not the sorts of things you’d expect non-technical people to ask about.“The distribution of testing data may not accurately reflect the target market’s real human users,” Lin said. “Moreover, the platform’s evaluation process is largely uncontrollable, relying primarily on post-processing to label each query with various tags, which are then used to develop task-specific ratings. This approach lacks systematic rigor, making it challenging to evaluate complex reasoning questions solely based on human preference.”Testing multimodal models in Chatbot Arena.Image Credits: LMSYSCook pointed out that because Chatbot Arena users are self-selecting — they’re interested in testing models in the first place — they may be less keen to stress-test or push models to their limits.“It’s not a good way to run a study in general,” Cook said. “Evaluators ask a question and vote on which model is ‘better’ — but ‘better’ is not really defined by LMSYS anywhere. Getting really good at this benchmark might make people think a winning AI chatbot is more human, more accurate, more safe, more trustworthy and so on — but it doesn’t really mean any of those things.”LMSYS is trying to balance out these biases by using automated systems — MT-Bench and Arena-Hard-Auto — that use models themselves (OpenAI’s GPT-4 and GPT-4 Turbo) to rank the quality of responses from other models. (LMSYS publishes these rankings alongside the votes). But while LMSYS asserts that models “match both controlled and crowdsourced human preferences well,” the matter’s far from settled.Commercial ties and data sharing LMSYS’ growing commercial ties are another reason to take the rankings with a grain of salt, Lin says.Some vendors like OpenAI, which serve their models through APIs, have access to model usage data, which they could use to essentially “teach to the test” if they wished. This makes the testing process potentially unfair for the open, static models running on LMSYS’ own cloud, Lin said.“Companies can continually optimize their models to better align with the LMSYS user distribution, possibly leading to unfair competition and a less meaningful evaluation,” he added. “Commercial models connected via APIs can access all user input data, giving companies with more traffic an advantage.”Cook added, “Instead of encouraging novel AI research or anything like that, what LMSYS is doing is encouraging developers to tweak tiny details to eke out an advantage in phrasing over their competition.”LMSYS is also sponsored in part by organizations, one of which is a VC firm, with horses in the AI race.LMSYS’ corporate sponsorships.Image Credits: LMSYSGoogle’s Kaggle data science platform has donated money to LMSYS, as has Andreessen Horowitz (whose investments include Mistral) and Together AI. Google’s Gemini models are on Chatbot Arena, as are Mistral’s and Together’s.LMSYS states on its website that it also relies on university grants and donations to support its infrastructure, and that none of its sponsorships — which come in the form of hardware and cloud compute credits, in addition to cash — have “strings attached.” But the relationships give the impression that LMSYS isn’t completely impartial, particularly as vendors increasingly use Chatbot Arena to drum up anticipation for their models.LMSYS didn’t respond to TechCrunch’s request for an interview.A better benchmark?Lin thinks that, despite their flaws, LMSYS and Chatbot Arena provide a valuable service: Giving real-time insights into how different models perform outside the lab.“Chatbot Arena surpasses the traditional approach of optimizing for multiple-choice benchmarks, which are often saturated and not directly applicable to real-world scenarios,” Lin said. “The benchmark provides a unified platform where real users can interact with multiple models, offering a more dynamic and realistic evaluation.”But — as LMSYS continues to add features to Chatbot Arena, like more automated evaluations — Lin feels there’s low-hanging fruit the organization could tackle to improve testing.To allow for a more “systematic” understanding of models’ strengths and weaknesses, he posits, LMSYS could design benchmarks around different subtopics, like linear algebra, each with a set of domain-specific tasks. That’d give the Chatbot Arena results much more scientific weight, he says.“While Chatbot Arena can offer a snapshot of user experience — albeit from a small and potentially unrepresentative user base — it should not be considered the definitive standard for measuring a model’s intelligence,” Lin said. “Instead, it is more appropriately viewed as a tool for gauging user satisfaction rather than a scientific and objective measure of AI progress.”","AI, AI, Benchmark, chatbot arena, Generative AI, lmsys, Testing","[{""Actant Name"": ""Chatbot Arena"", ""Category"": ""Technological Actant"", ""Role/Function"": ""A crowdsourced benchmark designed to evaluate generative AI models based on user preferences.""}, {""Actant Name"": ""LMSYS"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A non-profit organization that maintains Chatbot Arena and aims to make generative models more accessible.""}, {""Actant Name"": ""Elon Musk"", ""Category"": ""Human Actant"", ""Role/Function"": ""Tech executive who has promoted the performance of AI models on Chatbot Arena.""}, {""Actant Name"": ""Carnegie Mellon University"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the founding institutions of LMSYS.""}, {""Actant Name"": ""UC Berkeley's SkyLab"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the founding institutions of LMSYS.""}, {""Actant Name"": ""UC San Diego"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the founding institutions of LMSYS.""}, {""Actant Name"": ""Google DeepMind"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""An organization where some founding members of LMSYS are currently employed.""}, {""Actant Name"": ""xAI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""An organization founded by Elon Musk, where some LMSYS founders are now employed.""}, {""Actant Name"": ""Nvidia"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company where some founding members of LMSYS are currently employed.""}, {""Actant Name"": ""OpenAI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Anthropic"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Microsoft"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Meta"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Mistral"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Hugging Face"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A company that has models available for testing on Chatbot Arena.""}, {""Actant Name"": ""Mohamed bin Zayed University of Artificial Intelligence"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A university that has partnered with LMSYS.""}, {""Actant Name"": ""Yuchen Lin"", ""Category"": ""Human Actant"", ""Role/Function"": ""A research scientist who critiques the transparency and effectiveness of Chatbot Arena.""}, {""Actant Name"": ""Mike Cook"", ""Category"": ""Human Actant"", ""Role/Function"": ""A research fellow who provides an assessment of Chatbot Arena's methodology.""}, {""Actant Name"": ""LMSYS-Chat-1M"", ""Category"": ""Technological Actant"", ""Role/Function"": ""A data set released by LMSYS containing a million conversations for benchmarking.""}, {""Actant Name"": ""MT-Bench"", ""Category"": ""Technological Actant"", ""Role/Function"": ""An automated system used by LMSYS to rank model responses.""}, {""Actant Name"": ""Arena-Hard-Auto"", ""Category"": ""Technological Actant"", ""Role/Function"": ""An automated system used by LMSYS to rank model responses.""}, {""Actant Name"": ""Kaggle"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A data science platform that has donated money to LMSYS.""}, {""Actant Name"": ""Andreessen Horowitz"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""A VC firm that has sponsored LMSYS and invested in Mistral.""}, {""Actant Name"": ""Together AI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""An organization that has sponsored LMSYS.""}]","[{""Source Actant"": ""Elon Musk"", ""Relationship Type"": ""touts"", ""Target Actant"": ""Chatbot Arena""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""maintains"", ""Target Actant"": ""Chatbot Arena""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""founded by"", ""Target Actant"": ""Carnegie Mellon University""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""founded by"", ""Target Actant"": ""UC Berkeley's SkyLab""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""founded by"", ""Target Actant"": ""UC San Diego""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""employs"", ""Target Actant"": ""Google DeepMind""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""employs"", ""Target Actant"": ""xAI""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""employs"", ""Target Actant"": ""Nvidia""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""OpenAI""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""Anthropic""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""Microsoft""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""Meta""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""Mistral""}, {""Source Actant"": ""Chatbot Arena"", ""Relationship Type"": ""tests"", ""Target Actant"": ""Hugging Face""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""partners with"", ""Target Actant"": ""Mohamed bin Zayed University of Artificial Intelligence""}, {""Source Actant"": ""Yuchen Lin"", ""Relationship Type"": ""critiques"", ""Target Actant"": ""LMSYS""}, {""Source Actant"": ""Mike Cook"", ""Relationship Type"": ""critiques"", ""Target Actant"": ""Chatbot Arena""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""released"", ""Target Actant"": ""LMSYS-Chat-1M""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""uses"", ""Target Actant"": ""MT-Bench""}, {""Source Actant"": ""LMSYS"", ""Relationship Type"": ""uses"", ""Target Actant"": ""Arena-Hard-Auto""}, {""Source Actant"": ""Kaggle"", ""Relationship Type"": ""donates to"", ""Target Actant"": ""LMSYS""}, {""Source Actant"": ""Andreessen Horowitz"", ""Relationship Type"": ""sponsors"", ""Target Actant"": ""LMSYS""}, {""Source Actant"": ""Together AI"", ""Relationship Type"": ""sponsors"", ""Target Actant"": ""LMSYS""}]"
Google expands AI-powered virtual try-on tool to include dresses,Lauren Forristal,2024-09-05,"Google announced Thursday that it expanded its generative AI-powered virtual try-on tool to support dresses, allowing users to virtually wear thousands of dresses from hundreds of brands, including Boden, Maje, Sandro, Simkhai and Staud.According to the company, dresses were one of the most searched apparel categories for the tool. However, as Google explained in today’s blog post, its current diffusion technique is challenging to use with dresses, as they are more detailed and complex compared to other clothing items. To provide more context, Google Shopping released the tool last year, using its own diffusion technology to create high-quality, lifelike images of tops and blouses. It simulates how the clothing would drape, fold, cling, and form wrinkles and shadows on real people in various poses. Due to the intricate details of dresses, the existing diffusion model struggled to accurately capture detailed dress prints such as floral or geometric patterns. While the model could handle low-resolution images, a different method was needed for dresses to avoid losing important details. To address this issue, Google said it developed a new training strategy that starts with lower-resolution images and gradually incorporates higher resolutions.Additionally, as dresses typically cover most of the body and come in various lengths (such as midi, maxi, and mini), placing a virtual dress on a person often leads to the obscuring or blurring of body details. A new technique called the VTO-UNet Diffusion Transformer (VTO-UDiT) aims to solve this problem by preserving a person’s features while erasing and replacing the dress, resulting in a more accurate portrayal of both the dress and the person wearing it.Virtual try-on technology aims to eliminate the guesswork when it comes to finding the right fit for customers of all body types. Various companies (Adobe, Amazon and Walmart) have launched their own tools, allowing customers to virtually try on all types of clothing, including dresses. However, with this new expansion, it seems that Google is looking to create a more advanced feature than its competitors.","AI, Clothing, Commerce, Generative AI, Google, online shopping, virtual try on","[{""Actant Name"": ""Google"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Developed and expanded an AI-powered virtual try-on tool for dresses.""}, {""Actant Name"": ""VTO-UNet Diffusion Transformer (VTO-UDiT)"", ""Category"": ""Technological Actant"", ""Role/Function"": ""A new technique developed to improve the accuracy of virtual dress try-ons.""}, {""Actant Name"": ""Dresses"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""The clothing category that the virtual try-on tool is expanding to include.""}, {""Actant Name"": ""Adobe"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Competitor that has launched its own virtual try-on tools.""}, {""Actant Name"": ""Amazon"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Competitor that has launched its own virtual try-on tools.""}, {""Actant Name"": ""Walmart"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Competitor that has launched its own virtual try-on tools.""}, {""Actant Name"": ""Google Shopping"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Released the original virtual try-on tool last year.""}, {""Actant Name"": ""Customers"", ""Category"": ""Human Actant"", ""Role/Function"": ""Users of the virtual try-on tool seeking to find the right fit.""}, {""Actant Name"": ""Floral and Geometric Patterns"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Types of detailed dress prints that the technology aims to accurately capture.""}, {""Actant Name"": ""Lower-resolution Images"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Initial input for the new training strategy for the virtual try-on tool.""}, {""Actant Name"": ""Higher-resolution Images"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Subsequent input for the new training strategy for the virtual try-on tool.""}]","[{""Source Actant"": ""Google"", ""Relationship Type"": ""develops"", ""Target Actant"": ""VTO-UNet Diffusion Transformer (VTO-UDiT)""}, {""Source Actant"": ""Google"", ""Relationship Type"": ""expands"", ""Target Actant"": ""Google Shopping""}, {""Source Actant"": ""Google Shopping"", ""Relationship Type"": ""released"", ""Target Actant"": ""Dresses""}, {""Source Actant"": ""Google Shopping"", ""Relationship Type"": ""uses"", ""Target Actant"": ""Lower-resolution Images""}, {""Source Actant"": ""Google Shopping"", ""Relationship Type"": ""uses"", ""Target Actant"": ""Higher-resolution Images""}, {""Source Actant"": ""Customers"", ""Relationship Type"": ""uses"", ""Target Actant"": ""Google's virtual try-on tool""}, {""Source Actant"": ""Adobe"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Google""}, {""Source Actant"": ""Amazon"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Google""}, {""Source Actant"": ""Walmart"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""Google""}, {""Source Actant"": ""Dresses"", ""Relationship Type"": ""includes"", ""Target Actant"": ""Floral and Geometric Patterns""}]"
"YouTube is developing AI detection tools for music and faces, plus creator controls for AI training",Sarah Perez,2024-09-05,"YouTube on Thursday announced a new set of AI detection tools to protect creators, including artists, actors, musicians and athletes, from having their likeness, including their face and voice, copied and used in other videos. One key component of the new detection technology involved the expansion of YouTube’s existing Content ID system, which today identifies copyright-protected material. This system will be expanded to include new synthetic-singing identification technology to identify AI content that simulates someone’s singing voice. Other detection technologies will be developed to identify when someone’s face is simulated with AI, the company says.Also of note, YouTube is in the early stages of coming up with a solution to address the use of its content to train AI models. This has been an issue for some time, leading creators to complain that companies like Apple, Nvidia, Anthropic, OpenAI and Google, among others, have trained on their material without their consent or compensation.YouTube hasn’t yet revealed its plan to help protect creators (or generate additional revenue of its own from AI training), only that it has something in the works.“… we’re developing new ways to give YouTube creators choice over how third parties might use their content on our platform. We’ll have more to share later this year,” the announcement briefly states.Meanwhile, the company appears to be moving forward with its promise from last year when it said it would come up with a way to compensate artists whose work was used to create AI music. At the time, YouTube began working with Universal Music Group (UMG) and its roster of talent on a solution. It also said it would work on an expansion of its Content ID system that would be able to identify which rightsholders should be paid when their works were used by AI music. The Content ID system currently processes billions of claims per year, and generates billions in revenue for creators and artists, YouTube notes.In Thursday’s announcement, YouTube doesn’t tackle the compensation component to AI music but does say it is nearing a pilot of the Content ID system’s expansion with a focus on this area. Starting early next year, YouTube will begin to test the synthetic-singing identification technology with its partners, it says.Another solution in earlier stages of development will allow high-profile figures — like actors, musicians, creators, athletes and others — to detect and manage AI-generated work that shows their faces on YouTube. This would go a long way to help prevent people from having their likeness used to mislead YouTube viewers, whether it’s for endorsing products and services they never agreed to support, or to help spread misinformation, for instance. YouTube did not say when this system would be ready to test, only that it’s in active development.“As AI evolves, we believe it should enhance human creativity, not replace it. We’re committed to working with our partners to ensure future advancements amplify their voices, and we’ll continue to develop guardrails to address concerns and achieve our common goals,” according to YouTube’s announcement.","AI, Media & Entertainment, YouTube","[{""Actant Name"": ""YouTube"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Developing AI detection tools to protect creators and manage AI-generated content.""}, {""Actant Name"": ""Content ID system"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Existing system to identify copyright-protected material, being expanded to include synthetic-singing identification technology.""}, {""Actant Name"": ""Universal Music Group (UMG)"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Partnering with YouTube to develop solutions for compensating artists whose work is used in AI music.""}, {""Actant Name"": ""AI models"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Technologies that have been trained on creators' content without consent, prompting YouTube's response.""}, {""Actant Name"": ""Apple"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the companies accused of using creators' content without consent for AI training.""}, {""Actant Name"": ""Nvidia"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the companies accused of using creators' content without consent for AI training.""}, {""Actant Name"": ""Anthropic"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the companies accused of using creators' content without consent for AI training.""}, {""Actant Name"": ""OpenAI"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the companies accused of using creators' content without consent for AI training.""}, {""Actant Name"": ""Google"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""One of the companies accused of using creators' content without consent for AI training.""}, {""Actant Name"": ""Creators"", ""Category"": ""Human Actant"", ""Role/Function"": ""Artists, actors, musicians, and athletes whose likeness and content are being protected by YouTube's new tools.""}, {""Actant Name"": ""High-profile figures"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Individuals like actors and musicians who will benefit from detection and management of AI-generated work.""}, {""Actant Name"": ""Synthetic-singing identification technology"", ""Category"": ""Technological Actant"", ""Role/Function"": ""New technology being developed to identify AI-generated singing voices.""}, {""Actant Name"": ""AI-generated work"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Content that simulates the likeness or voice of creators, which YouTube aims to manage.""}]","[{""Source Actant"": ""YouTube"", ""Relationship Type"": ""develops"", ""Target Actant"": ""AI detection tools""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""expands"", ""Target Actant"": ""Content ID system""}, {""Source Actant"": ""Content ID system"", ""Relationship Type"": ""identifies"", ""Target Actant"": ""copyright-protected material""}, {""Source Actant"": ""Content ID system"", ""Relationship Type"": ""includes"", ""Target Actant"": ""synthetic-singing identification technology""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""partners with"", ""Target Actant"": ""Universal Music Group (UMG)""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""develops"", ""Target Actant"": ""solutions for compensating artists""}, {""Source Actant"": ""AI models"", ""Relationship Type"": ""trained on"", ""Target Actant"": ""creators' content""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""provides"", ""Target Actant"": ""choice over content use""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""develops"", ""Target Actant"": ""detection and management system""}, {""Source Actant"": ""High-profile figures"", ""Relationship Type"": ""benefit from"", ""Target Actant"": ""detection and management system""}, {""Source Actant"": ""YouTube"", ""Relationship Type"": ""tests"", ""Target Actant"": ""synthetic-singing identification technology""}]"
"US, UK and EU sign on to the Council of Europe’s high-level AI safety treaty",Ingrid Lunden,2024-09-05,"We’re not very close to any specifics on how, exactly, AI regulations will be implemented and ensured, but today a swathe of countries including the U.S., the U.K. and the European Union signed up to a treaty on AI safety laid out by the Council of Europe (COE), an international standards and human rights organization.The Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law — as the treaty is formally called — is described by the COE as “the first-ever international legally binding treaty aimed at ensuring that the use of AI systems is fully consistent with human rights, democracy and the rule of law.” At a meeting today in Vilnius, Lithuania, the treaty was formally opened for signature. Alongside the aforementioned trio of major markets, other signatories include Andorra, Georgia, Iceland, Norway, the Republic of Moldova, San Marino and Israel.The list means the COE’s framework has netted a number of countries where some of the world’s biggest AI companies are either headquartered or are building substantial operations. But perhaps as important are the countries not included so far: none in Asia, the Middle East, nor Russia, for example.The high-level treaty sets out to focus on how AI intersects with three main areas: human rights, which includes protecting against data misuse and discrimination, and ensuring privacy; protecting democracy; and protecting the “rule of law.” Essentially the third of these commits signing countries to setting up regulators to protect against “AI risks.” (It doesn’t specify what those risks might be, but it’s also a circular requirement referring to the other two main areas it’s addressing.)The more specific aim of the treaty is as lofty as the areas it hopes to address. “The treaty provides a legal framework covering the entire lifecycle of AI systems,” the COE notes. “It promotes AI progress and innovation, while managing the risks it may pose to human rights, democracy and the rule of law. To stand the test of time, it is technology-neutral.”(For background: The COE is not a lawmaking entity, but was founded in the wake of World War II with a function to uphold human rights, democracy and Europe’s legal systems. It draws up treaties which are legally binding for its signatories and enforces them; for example, it’s the organization behind the European Court of Human Rights.)Artificial intelligence regulation has been a hot potato in the world of technology, tossed among a complicated matrix of stakeholders.Various antitrust, data protection, financial and communications watchdogs — possibly thinking of how they failed to anticipate other technological innovations and problems — have made some early moves to try to frame how they might have a better grip on AI. The idea seems to be that if AI does represent a mammoth change to how the world operates, if not watched carefully, not all of those changes may turn out to be for the best, so it’s important to be proactive. However there is also clearly nervousness among regulators about overstepping the mark and being accused of crimping innovation by acting too early or applying too broad a brush. AI companies have also jumped in early to proclaim that they, too, are just as interested in what’s come to be described as AI Safety. Cynics describe private interest as regulatory capture; optimists believe that companies need seats at the regulatory table to communicate better about what they are doing and what might be coming next to inform appropriate policies and rulemaking. Politicians are also ever-present, sometimes backing regulators, but sometimes taking an even more pro-business stance that centers the interests of companies in the name of growing their countries’ economies. (The last U.K. government fell into this AI cheerleading camp.)That mix has produced a smorgasbord of frameworks and pronouncements, such as those coming out of events like the U.K.’s AI Safety Summit in 2023 or the G7-led Hiroshima AI Process or the resolution adopted by the UN earlier this year. We’ve also seen country-based AI safety institutes established and regional regulations such as the SB 1047 bill in California, the European Union’s AI Act and more. It sounds like the COE’s treaty is hoping to provide a way for all of these efforts to align.“The treaty will ensure countries monitor its development and ensure any technology is managed within strict parameters,” the U.K. Ministry of Justice noted in a statement on the signing of the treaty. “Once the treaty is ratified and brought into effect in the U.K., existing laws and measures will be enhanced.”“We must ensure that the rise of AI upholds our standards, rather than undermining them,” said COE Secretary General Marija Pejčinović Burić in a statement. “The Framework Convention is designed to ensure just that. It is a strong and balanced text — the result of the open and inclusive approach by which it was drafted and which ensured that it benefits from multiple and expert perspectives.”“The Framework Convention is an open treaty with a potentially global reach. I hope that these will be the first of many signatures and that they will be followed quickly by ratifications, so that the treaty can enter into force as soon as possible,” she added. While the original framework convention was first negotiated and adopted by the COE’s committee of ministers in May 2024 it will formally enter into force “on the first day of the month following the expiration of a period of three months after the date on which five signatories, including at least three Council of Europe member states, have ratified it.” In other words, countries that signed on Thursday will still individually need to ratify it, and from then it will take another three months before the provisions go into effect. It’s not clear how long that process might take. The U.K., for example, has said it intends to work on AI legislation but has not put a firm timeline on when a draft bill might be introduced. On the COE framework specifically, it only says that it will have more updates on its implementation “in due course.”","AI, ai safety, council of europe, Government & Policy","[{""Actant Name"": ""Council of Europe"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""An international standards and human rights organization that laid out the AI safety treaty.""}, {""Actant Name"": ""United States"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the major countries that signed the AI safety treaty.""}, {""Actant Name"": ""United Kingdom"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the major countries that signed the AI safety treaty.""}, {""Actant Name"": ""European Union"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the major entities that signed the AI safety treaty.""}, {""Actant Name"": ""Lithuania"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""The location where the treaty was formally opened for signature.""}, {""Actant Name"": ""Andorra"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""Georgia"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""Iceland"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""Norway"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""Republic of Moldova"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""San Marino"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""Israel"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""One of the signatories of the AI safety treaty.""}, {""Actant Name"": ""AI Safety"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""A concept that encompasses the regulatory and safety measures for AI systems.""}, {""Actant Name"": ""Marija Pej\u010dinovi\u0107 Buri\u0107"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Secretary General of the Council of Europe who commented on the treaty.""}, {""Actant Name"": ""U.K. Ministry of Justice"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Provided a statement regarding the signing of the treaty.""}, {""Actant Name"": ""AI Companies"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Entities that are interested in AI safety and may influence regulatory frameworks.""}, {""Actant Name"": ""G7"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Group that led the Hiroshima AI Process related to AI safety.""}, {""Actant Name"": ""UN"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Adopted a resolution earlier in the year related to AI safety.""}, {""Actant Name"": ""California SB 1047"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""A regional regulation related to AI safety.""}, {""Actant Name"": ""European Union AI Act"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""A regulatory framework established by the EU concerning AI.""}, {""Actant Name"": ""AI Regulation"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""The broader context of laws and guidelines governing AI technologies.""}, {""Actant Name"": ""AI Risks"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""Potential issues that the treaty aims to address through regulation.""}, {""Actant Name"": ""AI Lifecycle"", ""Category"": ""Technological Actant"", ""Role/Function"": ""The entire process of AI system development and deployment that the treaty aims to cover.""}]","[{""Source Actant"": ""Council of Europe"", ""Relationship Type"": ""develops"", ""Target Actant"": ""AI Safety""}, {""Source Actant"": ""United States"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""United Kingdom"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""European Union"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Lithuania"", ""Relationship Type"": ""hosts"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Andorra"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Georgia"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Iceland"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Norway"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Republic of Moldova"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""San Marino"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Israel"", ""Relationship Type"": ""signs"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""AI Companies"", ""Relationship Type"": ""influences"", ""Target Actant"": ""AI Regulation""}, {""Source Actant"": ""G7"", ""Relationship Type"": ""leads"", ""Target Actant"": ""Hiroshima AI Process""}, {""Source Actant"": ""UN"", ""Relationship Type"": ""adopts"", ""Target Actant"": ""AI Safety""}, {""Source Actant"": ""U.K. Ministry of Justice"", ""Relationship Type"": ""states"", ""Target Actant"": ""Council of Europe""}, {""Source Actant"": ""Council of Europe"", ""Relationship Type"": ""addresses"", ""Target Actant"": ""AI Risks""}, {""Source Actant"": ""Council of Europe"", ""Relationship Type"": ""covers"", ""Target Actant"": ""AI Lifecycle""}]"
ZipRecruiter’s new tool will quickly match and schedule an intro call with potential candidates,Ivan Mehta,2024-09-05,"Hiring platform ZipRecruiter is launching a new tool, called ZipIntro, to let employers schedule introductory calls with potential candidates at a set time. The tool will also help recruiters suggest potential candidates using AI.Employers can input information about the role and select a date and time for introductory calls. After that, ZipIntro matches them with potential candidates using AI and sends them an invitation for the call. The tool takes into account employment, education, skills, certifications, interests and types of jobs users are looking for while matching.Image Credits: ZipRecruiterEmployers can review these responses from candidates, further screen candidates and line up back-to-back calls. ZipRecruiter then allows employers to connect with candidates through one-on-one video calls on the platform.The company said these intro sessions are typically 30 minutes to one hour, with each intro call lasting about five minutes. It noted that while these are initial screening calls, some organizations also use this tool to hire high-volume roles that may require fewer interview stages.Image Credits: ZipRecruiterZipRecruiter noted that with ZipIntro, employers get their first RSVP from candidates within 20 minutes of posting the job requirement. “With ZipIntro, recruiters and hiring managers can forge those critical connections faster to assess the true potential of each candidate,” Megan Allen, SVP of product at ZipRecruiter said in a statement. “For job seekers, we’re excited to provide them with the opportunity to speak with an employer faster, allowing them to showcase their true personality, soft skills, and passion.”The company is not the only platform utilizing AI to make the hiring process easier. Indeed is also using AI to help people write about their job experiences. Microsoft-owned LinkedIn has also deployed an AI tool to help recruiters write better job descriptions.","AI, ziprecruiter","[{""Actant Name"": ""ZipRecruiter"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Hiring platform launching a new tool called ZipIntro to facilitate scheduling introductory calls with candidates.""}, {""Actant Name"": ""ZipIntro"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Tool developed by ZipRecruiter to match employers with potential candidates and schedule calls.""}, {""Actant Name"": ""Megan Allen"", ""Category"": ""Human Actant"", ""Role/Function"": ""SVP of product at ZipRecruiter, providing insights on the benefits of ZipIntro.""}, {""Actant Name"": ""Indeed"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Another hiring platform utilizing AI to assist job seekers.""}, {""Actant Name"": ""LinkedIn"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Platform owned by Microsoft, deploying AI tools to help recruiters.""}, {""Actant Name"": ""AI"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Technology used by ZipIntro and other platforms to enhance the hiring process.""}, {""Actant Name"": ""Candidates"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Individuals seeking employment who interact with the ZipIntro tool.""}, {""Actant Name"": ""Employers"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Organizations or individuals looking to hire candidates using ZipIntro.""}, {""Actant Name"": ""Job Seekers"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Individuals looking for jobs who benefit from the ZipIntro tool.""}, {""Actant Name"": ""Intro Calls"", ""Category"": ""Temporal Actant"", ""Role/Function"": ""Scheduled interactions between employers and candidates facilitated by ZipIntro.""}]","[{""Source Actant"": ""ZipRecruiter"", ""Relationship Type"": ""launches"", ""Target Actant"": ""ZipIntro""}, {""Source Actant"": ""ZipIntro"", ""Relationship Type"": ""matches"", ""Target Actant"": ""Candidates""}, {""Source Actant"": ""ZipIntro"", ""Relationship Type"": ""schedules"", ""Target Actant"": ""Intro Calls""}, {""Source Actant"": ""Employers"", ""Relationship Type"": ""uses"", ""Target Actant"": ""ZipIntro""}, {""Source Actant"": ""Megan Allen"", ""Relationship Type"": ""describes"", ""Target Actant"": ""ZipIntro""}, {""Source Actant"": ""Candidates"", ""Relationship Type"": ""interacts with"", ""Target Actant"": ""ZipIntro""}, {""Source Actant"": ""Indeed"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""ZipRecruiter""}, {""Source Actant"": ""LinkedIn"", ""Relationship Type"": ""competes with"", ""Target Actant"": ""ZipRecruiter""}, {""Source Actant"": ""AI"", ""Relationship Type"": ""enhances"", ""Target Actant"": ""ZipIntro""}]"
Sedric monitors the communications of employees at financial institutions to ensure compliance,Kyle Wiggers,2024-09-05,"For financial institutions, complying with regulations is becoming a costlier proposition. According to a recent poll, 76% of financial services firms increased their compliance expenditure from 2022 to 2023, with most blaming new laws.With the cost of compliance averaging out to around $10,000 per employee these days, many firms are searching for ways to reduce spending without running afoul of regulators. Entrepreneurs Nir Laznik and Eyal Peleg say that they’ve created a solution — powered by generative AI, as is the trend.Laznik and Peleg co-founded Sedric, an AI-powered platform designed to help financial institutions implement compliance rules and flag possible issues. Prior to Sedric, Laznik spearheaded several startups, including a photo kiosk software firm, while Peleg spent close to eight years at Intel’s AI and machine learning org.“We realized there was disproportionate pressure on mid-size organizations, combined with a new set of challenges for banks,” Laznik said. “We knew the rapid advancements in AI could address these problems in an entirely new way. This convergence of factors led us to create Sedric.”Sedric’s AI acts as an overseer of sorts, monitoring a workforce’s outbound and inbound calls, chats, emails, social media DMs, and instant messages. It attempts to flag compliance problems (e.g. omitted disclosures, missed steps, and misconduct) as they happen; Sedric can automatically “mitigate” issues and provide coaching to the offending staff in many cases, Laznik claims.“This technology empowers compliance officers with a holistic view of their customer touchpoints across multiple channels, allowing them to flag deviations from established compliance policies and guidelines quickly and efficiently,” Laznik said. “Our platform covers the entire compliance lifecycle, from policy setting to enforcement, correction and audit.”A screenshot of Sedric’s backend dashboard.Image Credits: SedricSurveillance that deep might sound a little intrusive — not least of which because Sedric “scores” interactions on a per-employee basis according to adherence to company policies. But, for better or worse, U.S. state and federal guidelines give wide discretion to businesses engaged in monitoring their staff so long as the businesses are reasonably transparent about it. Moreover, some federal-level regulations — particularly regulations pertaining to insider trading, collusion, and the sharing of certain earnings documents — mandate that financial institutions closely track workers in their interactions with customers and the broader marketplace. These preempt state laws, like New York’s and Connecticut’s, that impose additional requirements on employers conducting workforce monitoring.I asked Laznik about the potential for bias in Sedric’s AI, given that the AI is likely to be monitoring communications of staff from all different backgrounds. Biased AI can lead to discrimination, depending on where and how it’s deployed — whether intentional or no. Studies have shown that some AI trained to detect toxicity sees phrases in African-American Vernacular English, the informal grammar used by some Black Americans, as disproportionately “toxic.” Other studies have demonstrated how speech recognition systems are more likely to wrongly transcribe audio of Black speakers as opposed to their white counterparts.Laznik says that Sedric uses “fine-tuned models” trained on “proprietary datasets curated and validated in collaboration with industry experts” to try to minimize bias. The company also monitors for performance dips in deployed models and retrains models when necessary. Image Credits: Sedric“Our platform enables customers to provide direct feedback through various annotation inputs, which are then vetted by compliance teams and are used for re-training or integrated into the prediction process,” he added. “This ensures that our models become increasingly tailored for each customer.”To protect customer — and employee — privacy and security, Sedric allows companies to configure where their data is stored and implement controls that redact (or at least attempt to redact) personally identifiable information.“At Sedric, we’ve designed our platform with compliance and security at its core,” Lazink said. “Enterprises can set their own retention policies and compliance guidelines according to their internal guidelines and specific regulations.”Sedric, which also offers tools to support call center agents as they’re chatting with clients on the phone, has “hundreds” of paying compliance officers and enterprise customers in the U.S. and Europe, Laznik claims. Revenue has increased fivefold over the last year — although Laznik declined to give firmer numbers.“For small- and medium-sized businesses, we offer an off-the-shelf solution, and for enterprises and banks, we offer a hybrid model with tailored customizations,” Lazink said. “Our focus on the specific needs of financial institutions, combined with our proprietary library of pre-trained, regulation-inspired models that can also be customized to each organization’s unique requirements, sets us apart in the market.”Going after finance customers and use cases specifically certainly appears to have worked in Sedric’s favor, setting the company apart from workplace monitoring rivals such as Fairwords, Shield, Erudit and Aware. It’s a crowded — and often controversial — market, but investors still sense some opportunity, particularly as AI becomes more deeply embedded in these types of tools.Case in point: Seemingly pleased with Sedric’s progress so far, Foundation Capital led an $18.5 million Series A investment in the four-year-old company that also had participation from Amex Ventures. The new cash will be put toward growing the firm’s go-to-market and R&D teams “significantly” in NYC and Tel Aviv, Lazink said, and brings New York-based Sedric’s total raised to $22 million.Sedric plans to double its headcount in the next 12 months.","AI, AI, compliance, Enterprise, finance, Fintech, Funding, Fundraising, Generative AI, sedric, startup, Startups","[{""Actant Name"": ""Sedric"", ""Category"": ""Technological Actant"", ""Role/Function"": ""AI-powered platform designed to help financial institutions implement compliance rules and flag possible issues.""}, {""Actant Name"": ""Nir Laznik"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder of Sedric and entrepreneur with experience in startups.""}, {""Actant Name"": ""Eyal Peleg"", ""Category"": ""Human Actant"", ""Role/Function"": ""Co-founder of Sedric with a background in AI and machine learning at Intel.""}, {""Actant Name"": ""Foundation Capital"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Led an $18.5 million Series A investment in Sedric.""}, {""Actant Name"": ""Amex Ventures"", ""Category"": ""Institutional Actant"", ""Role/Function"": ""Participated in the Series A investment in Sedric.""}, {""Actant Name"": ""Financial Institutions"", ""Category"": ""Social and Cultural Actant"", ""Role/Function"": ""Entities that are subject to compliance regulations and use Sedric for monitoring communications.""}, {""Actant Name"": ""U.S. Federal Guidelines"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""Regulations that provide discretion to businesses monitoring their staff.""}, {""Actant Name"": ""New York State Laws"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""State laws that impose additional requirements on employers conducting workforce monitoring.""}, {""Actant Name"": ""Connecticut State Laws"", ""Category"": ""Ethical and Regulatory Actant"", ""Role/Function"": ""State laws that impose additional requirements on employers conducting workforce monitoring.""}, {""Actant Name"": ""AI Models"", ""Category"": ""Technological Actant"", ""Role/Function"": ""Models used by Sedric to monitor communications and minimize bias.""}, {""Actant Name"": ""Employees"", ""Category"": ""Human Actant"", ""Role/Function"": ""Individuals whose communications are monitored by Sedric for compliance purposes.""}, {""Actant Name"": ""Investors"", ""Category"": ""Economic Actant"", ""Role/Function"": ""Entities that provide funding to Sedric based on its market potential.""}, {""Actant Name"": ""NYC"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""Location where Sedric plans to grow its go-to-market and R&D teams.""}, {""Actant Name"": ""Tel Aviv"", ""Category"": ""Geographical Actant"", ""Role/Function"": ""Location where Sedric plans to grow its go-to-market and R&D teams.""}]","[{""Source Actant"": ""Nir Laznik"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""Sedric""}, {""Source Actant"": ""Eyal Peleg"", ""Relationship Type"": ""co-founded"", ""Target Actant"": ""Sedric""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""monitors"", ""Target Actant"": ""Employees""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""uses"", ""Target Actant"": ""AI Models""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""helps"", ""Target Actant"": ""Financial Institutions""}, {""Source Actant"": ""Foundation Capital"", ""Relationship Type"": ""led"", ""Target Actant"": ""Series A investment""}, {""Source Actant"": ""Amex Ventures"", ""Relationship Type"": ""participated in"", ""Target Actant"": ""Series A investment""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""received"", ""Target Actant"": ""Series A investment""}, {""Source Actant"": ""U.S. Federal Guidelines"", ""Relationship Type"": ""governs"", ""Target Actant"": ""Financial Institutions""}, {""Source Actant"": ""New York State Laws"", ""Relationship Type"": ""imposes requirements on"", ""Target Actant"": ""Financial Institutions""}, {""Source Actant"": ""Connecticut State Laws"", ""Relationship Type"": ""imposes requirements on"", ""Target Actant"": ""Financial Institutions""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""plans to grow in"", ""Target Actant"": ""NYC""}, {""Source Actant"": ""Sedric"", ""Relationship Type"": ""plans to grow in"", ""Target Actant"": ""Tel Aviv""}]"
