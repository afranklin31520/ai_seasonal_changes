title,author,pub_date,source_url,summary,full_text,keywords,funding_info,geo_aff,ins_aff,id
"Here is what’s illegal under California’s 8 (and counting) new AI laws","Maxwell Zeff",2024-09-19,https://techcrunch.com/2024/09/19/here-is-whats-illegal-under-californias-8-and-counting-new-ai-laws/,"California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly contentious SB 1047, which the state’s legislature sent to his desk for final approval. These bills try…","California Governor Gavin Newsom is currently considering 38 AI-related bills, including the highly contentious SB 1047, which the state’s legislature sent to his desk for final approval. These bills try to address the most pressing issues in artificial intelligence: everything from futuristic AI systems creating existential risk, deepfake nudes from AI image generators, to Hollywood studios creating AI clones of dead performers.“Home to the majority of the world’s leading AI companies, California is working to harness these transformative technologies to help address pressing challenges while studying the risks they present,” said Governor Newsom’s office in a press release.So far, Governor Newsom has signed eight of them into law, some of which are America’s most far reaching AI laws yet.Deepfake nudesNewsom signed two laws that address the creation and spread of deepfake nudes on Thursday. SB 926 criminalizes the act, making it illegal to blackmail someone with AI-generated nude images that resemble them.SB 981, which also became law on Thursday, requires social media platforms to establish channels for users to report deepfake nudes that resemble them. The content must then be temporarily blocked while the platform investigates it, and permanently removed if confirmed.WatermarksAlso on Thursday, Newsom signed a bill into law to help the public identify AI-generated content. SB 942 requires widely used generative AI systems to disclose they are AI-generated in their content’s provenance data. For example, all images created by OpenAI’s Dall-E now need a little tag in their metadata saying they’re AI generated.Many AI companies already do this, and there are several free tools out there that can help people read this provenance data and detect AI-generated content.Election deepfakesEarlier this week, California’s governor signed three laws cracking down on AI deepfakes that could influence elections. One of California’s new laws, AB 2655, requires large online platforms, like Facebook and X, to remove or label AI deepfakes related to elections, as well as create channels to report such content. Candidates and elected officials can seek injunctive relief if a large online platform is not complying with the act.Another law, AB 2839, takes aim at social media users who post, or repost, AI deepfakes that could deceive voters about upcoming elections. The law went into effect immediately on Tuesday, and Newsom suggested Elon Musk may be at risk of violating it.AI-generated political advertisements now require outright disclosures under California’s new law, AB 2355. That means moving forward, Trump may not be able to get away with posting AI deepfakes of Taylor Swift endorsing him on Truth Social (she endorsed Kamala Harris). The FCC has proposed a similar disclosure requirement at a national level and has already made robocalls using AI-generated voices illegal.Actors and AITwo laws that Newsom signed on Tuesday — which SAG-AFTRA, the nation’s largest film and broadcast actors union, was pushing for — create new standards for California’s media industry. AB 2602 requires studios to obtain permission from an actor before creating an AI-generated replica of their voice or likeness. Meanwhile, AB 1836 prohibits studios from creating digital replicas of deceased performers without consent from their estates (e.g., legally cleared replicas were used in the recent “Alien” and “Star Wars” movies, as well as in other films).What’s left?Governor Newsom still has 30 AI-related bills to decide on before the end of September. During a chat with Salesforce CEO Marc Benioff on Tuesday during the 2024 Dreamforce conference, Newsom may have tipped his hat about SB 1047, and how he’s thinking about regulating the AI industry more broadly.“There’s one bill that is sort of outsized in terms of public discourse and consciousness; it’s this SB 1047,” said Newsom onstage Tuesday. “What are the demonstrable risks in AI and what are the hypothetical risks? I can’t solve for everything. What can we solve for? And so that’s the approach we’re taking across the spectrum on this.”Check back on this article for updates on what AI laws California’s governor signs, and what he doesn’t.","AI, ai deepfakes, AI regulation, california, Gavin Newsom, Government & Policy, SB 1047",,,,1
"Elon Musk’s reposts of Kamala Harris deepfakes may not fly under new California law","Maxwell Zeff",2024-09-19,https://techcrunch.com/2024/09/19/elon-musks-reposts-of-kamala-harris-deepfakes-may-not-fly-under-new-california-law/,"California’s newest law could land social media users who post, or repost, AI deepfakes that deceive voters about upcoming elections in legal trouble. Governor Gavin Newsom suggests that AB 2839,…","California’s newest law could land social media users who post, or repost, AI deepfakes that deceive voters about upcoming elections in legal trouble. Governor Gavin Newsom suggests that AB 2839, which went into effect immediately after he signed it on Tuesday, could be used to reel in the retweets of Elon Musk, among others who spread deceptive content.“I just signed a bill to make this illegal in the state of California,” said Newsom in a tweet, referencing an AI deepfake Musk reposted earlier this year that made it appear Kamala Harris called herself an incompetent candidate and a diversity hire (she did not).“You can no longer knowingly distribute an ad or other election communications that contain materially deceptive content — including deepfakes,” Newsom said later in the tweet.California’s new law targets the distributors of AI deepfakes, specifically if the post resembles a candidate on California ballots, and the poster knows it’s a fake that will cause confusion. AB 2839 is unique because it doesn’t go after the creators of AI deepfakes, or the platforms they appear on, but rather those who maliciously spread them. Anyone who sees an AI deepfake on social media can now file for injunctive relief, meaning a judge could order the poster to take it down, or issue monetary damages against the person who posted it.It’s one of America’s strongest laws against election-related AI deepfakes heading into the 2024 presidential election.A sponsor that helped draft AB 2839, California Initiative for Technology and Democracy (CITED), tells TechCrunch this law can impact any social media user — not just Musk — who posts or reposts election-related AI deepfakes with malice. “Malice” means the poster knew it was false and would confuse voters.“[AB 2839] goes after the creators or distributors of content, if the content falls within the terms of the bill,” said CITED’s policy director, Leora Gershenzon, in an interview with TechCrunch. “This is materially deceptive content that is distributed knowing it’s false, with reckless disregard of the truth, and is likely to influence the election.”When asked whether Musk could face legal action for reposting deepfakes, Newsom did not rule out the possibility.“I think Mr. Musk has missed the punchline,” said Governor Newsom at a press conference Thursday. “Parody is still alive and well in California, but deepfakes and manipulations of elections — that hurts democracy.”Specifically, the new law bans election-related AI deepfakes from TV, radio, phone, texts, or any communication “distributed through the internet.” The bill is not exclusive to political campaign ads, which other laws have focused on, but also posts from everyday people. AB 2839 creates a window –120 days before a California election and 60 days after — where there are stricter rules about what you can, and can not, post about political candidates on social media.“The real goal is actually neither the damages or the injunctive relief,” said Gershenzon. “It’s just to have people not do it in the first place. That actually would be the best outcome… to just have these deepfakes not fraudulently impact our elections.”This law pertains to candidates for state and local elections in California, as well as federal candidates that will appear on California’s ballot, such as Kamala Harris and Donald Trump. If there’s an obvious disclaimer on an AI deepfake, stating that it has been digitally altered, then AB 2839 does not apply to it.Musk is already trying to test the will to enforce California’s new law. Musk reposted the deepfake resembling Kamala Harris that Newsom referenced in his tweet on Tuesday, amassing more than 31 million impressions on X. Musk also reposted an AI deepfake resembling Governor Newsom on Wednesday, which received more than 7 million impressions.Musk and X are facing other legal problems related to moderation. For instance, a Brazilian Supreme Court judge fined the X Corporation on Thursday for skirting the country’s ban on the platform. The judge previously said X’s failure to combat fake news and hate speech is harming Brazil’s democracy.","2024 election, AI, ai deepfakes, Elon Musk, Government & Policy",,,,2
"Amazon releases a video generator — but only for ads","Kyle Wiggers",2024-09-19,https://techcrunch.com/2024/09/19/amazon-releases-a-video-generator-but-only-for-ads/,"Like its rival, Google, Amazon has launched an AI-powered video generator — but it’s only for advertisers at the moment, and somewhat limited in what it can do. Today at…","Like its rival, Google, Amazon has launched an AI-powered video generator — but it’s only for advertisers at the moment, and somewhat limited in what it can do. Today at its Accelerate conference, Amazon unveiled Video Generator, which turns a single product image into video showcases of that product after some amount of processing. The company says that the tool can curate “custom,” AI-generated videos that “showcase a product’s features” at no additional cost.“[Videos from Video Generator] leverage Amazon’s unique retail insights to vividly bring a product story to life in ways that are relevant to customers,” Amazon writes in a blog post.In a statement, Amazon Ads VP Jay Richman said that Video Generator, which is currently in beta for select U.S. advertisers (and specifically for Sponsored Brands campaigns), will be fine-tuned over the next several months ahead of a wider release.“Video Generator is another meaningful innovation that leverages generative AI to inspire creativity and deliver more value for both advertisers and shoppers,” Richman said. “We are hard at work delivering generative AI applications that empower advertisers to craft visually stunning, high-performing ads.”A related new capability announced today, live image, generates few-seconds-long, animated GIFs from a still frame. Also in limited beta, it’s a part of Image generator, Amazon’s AI-powered image generation suite for marketers. Amazon didn’t provide sample footage from Video Generator, and it initially revealed very few technical details about the tool and live image. Late this afternoon, an Amazon spokesperson answered a few of TechCrunch’s Video Generator-related questions via email. Clips from Video Generator are 6-9 seconds in length at a 720p resolution (24 frames per second). They’re automatically generated “around” a seed product image — “inspired by the product and its details,” the spokesperson said — and take up to five minutes to create. Users get four variations to choose from.Video Generator outputs seem to follow the same basic formula: Two scenes with headlines (e.g. “Nourishing Lavender Moisturizer”), background music, and a call to action. The font and soundtrack can be customized, as well as the brand logo that appears in the upper-right-hand corner of the frame.Amazon’s expansion into generative video comes as other players release their own video-generating tech. Startups Runway and Luma launched generative video APIs this month, and Google says that it’s beginning to integrate its flagship video model, Veo, into YouTube Shorts. Elsewhere, Adobe promised that video generation would come to its Creative Suite platform by the end of the year, and OpenAI is expected to roll out its technology, Sora, in some capacity this fall.As with all generative AI systems, there are risks to using these tools.Video-generating models are trained on a vast number of examples of videos to “learn” the patterns in these videos to generate new clips. Some vendors train models on copyrighted videos without obtaining permission from the owners or creators, and, when these models “regurgitate” copyrighted stills, it exposes users of the models to IP lawsuits. Amazon is one of several companies that has said it’ll protect customers accused of violating copyright with media generated by its models, in keeping with its indemnification policy. We’ve asked the company if Video Generator and live image are also covered under that policy.However the legal battles shake out, one thing’s becoming clear: Generative AI threatens to upend the film and television industry as we know it. A 2024 study commissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, estimates that by 2026, more than 100,000 U.S.-based entertainment jobs will be disrupted by generative AI.Updated 9/19 at 4 p.m. Pacific: Added technical details about Video Generator.","Ads, Adtech, AI, AI, Amazon, Commerce, Enterprise, Generative AI, live image, Media & Entertainment, video generator",,,,3
"Amazon debuts Project Amelia, an AI assistant for sellers","Sarah Perez",2024-09-19,https://techcrunch.com/2024/09/19/amazon-debuts-an-ai-assistant-for-sellers-project-amelia/,"Amazon sellers now have access to an AI assistant designed to help grow their business by answering questions about their metrics, and later, helping to resolve issues that arise. The…","Amazon sellers now have access to an AI assistant designed to help grow their business by answering questions about their metrics, and later, helping to resolve issues that arise. The assistant, code-named Project Amelia and built on AWS’s Amazon Bedrock, is available in beta to U.S. sellers, starting Thursday.The retail giant says select U.S. sellers will gain access immediately, followed by a broader rollout across the U.S. Later this year, the feature will begin to arrive in more countries and in other languages besides English.The goal with Project Amelia, explains Amazon, is to offer sellers tools that can then manage and grow their business.Image Credits: AmazonAt launch, sellers will be able to retrieve information like sales data and customer traffic information, and be able to ask the assistant questions like “How is my business doing?” In response, the AI will offer a summary of metrics, including recent sales, units sold, and website traffic, comparing those metrics to the same time last year.Sellers will also be able to ask follow-up questions, like those focused on a single product’s sale, growth, and customer traffic, among other things.Later, the AI assistant will be able to help resolve issues and aid with other tasks. For example, Amazon sellers will be able to ask something like “I have 300 units on the way and don’t see that reflected in the report. Can someone look into this?” and they’ll receive personalized guidance. If needed, they may also be connected with Amazon’s support team to help them investigate the issue further, which makes the assistant sound more like a traditional chatbot, in that case.Further down the road, Project Amelia will be able to offer sellers “additional help managing the task” or may even “offer to solve the problem on a seller’s behalf,” Amazon says, without providing specifics or a time frame to launch.Image Credits: Amazon“We are always seeking to equip our selling partners with the most effective tools and capabilities, empowering them to more easily start and grow a successful business,” reads a blog post, penned by Mary Beth Westmoreland, VP of Amazon’s Worldwide Selling Partner Experience. “By leveraging the transformative power of generative AI, we are creating and deploying technologies that will improve how sellers can manage and grow their businesses. Innovative solutions like Project Amelia are reducing the time, effort, and resources required from sellers to manage their business, allowing them more time for building great products and delighting customers,” she adds.Amelia’s launch follows the launch of another AI chatbot aimed at consumers, Rufus, which went live in the U.S. this summer. On the consumer side, Amazon is also leveraging AI to help customers find clothes that fit and to enhance product reviews, among other things. For sellers, Amazon had previously introduced generative AI tools to help them create product listings, and for those who advertise on Amazon, tools to generate backgrounds using AI.On Thursday, Amazon also shared how it was using generative AI to improve its product recommendations for consumers as well as its product descriptions.","AI, Amazon, Commerce, Project Amelia",,,,4
"AI notetaker Fathom raises $17M","Frederic Lardinois",2024-09-19,https://techcrunch.com/2024/09/19/ai-notetaker-fathom-raises-17m/,"In many meetings today, it sometimes feels like there are more AI notetaking and transcription bots than people. There are seemingly dozens of options to choose from these days, but…","In many meetings today, it sometimes feels like there are more AI notetaking and transcription bots than people. There are seemingly dozens of options to choose from these days, but one I’ve seen with increasing regularity is Fathom. The company was one of the earlier players when it launched in 2020. Fathom then raised a $4.7 million seed round in early 2022 and, today, the company announced its $17 million Series A round, led by Telescope partners. Notably, $2 million of the $17 million came from Fathom users via crowdfunding on Wefunder.The company says its revenue increased by 90x and usage by 20x over the last two years. That was likely from a relatively low baseline, but while the company didn’t share exact active user numbers, Fathom, which offers a generous free plan, did say that more than 8,500 companies now use its HubSpot integration. “We always built Fathom around the expectation that AI would get really good,” the company’s CEO and co-founder Richard White told me. “When we started in 2020, AI wasn’t there yet. But we were like: Hey, we’re going to really focus on the things that we think are hard, which is getting distribution, building a really reliable infrastructure, and an easy-to-use product, with this expectation that when AI gets there, we’ll be able to drop that into this already widely distributed easy-to-use product, and it’ll just make it go from good to great.”One thing that always made Fathom stand out is that the company relies on its own models — or at least its own fine-tuned versions of open models. Fathom has its own team working and experimenting with models — and as White noted, working with models is very different from typical engineering projects.“Their output is not a feature, it’s actually spec,” he said about this team. “And it has a failure rate. It’s not like engineering, where you put something on the roadmap, it gets done. It’s like 50% time right now. If it’s not good enough, let’s check back in six months. I think it required rethinking the product development process a little bit.”Over time, the team added a number of new features, including automatically creating action items and drafts for follow-up emails, as well as the “Ask Fathom” chatbot and more features geared towards teams. Most of these more advanced features are gated behind its paid plans, which start at $19/month on its monthly plans.Image Credits: FathomWhile most of the large meeting services are starting to offer their own takes on what Fathom is doing, White doesn’t seem to be too worried about that. “Our vision is that we want to get all of your meetings in one place,” he said. That broader vision, he said, includes becoming the central source of intelligence for a company’s leadership, something that’s hard to do when you only support a single meeting platform. Part of this vision — and something the new funding round will help Fathom to work on — is to not just help its users with meeting notes and action items, but also with a lot more of the busy work that follows a meeting. It’s starting down this path with its automated action items and follow-up email features, but the idea here is to build more integrations and use AI agents to perform more of these tasks and directly interface with CRM systems, for example. White also noted that there is a lot of data in meetings that isn’t currently being used and that may provide more ambient intelligence to leadership teams over time. Nobody can sit in on every meeting, after all, but White envisions a more proactive system that can alert decision-makers when a sales team, for example, is confronted with a question that they don’t have a good answer for, or when the name of a competitor suddenly becomes more prevalent in meetings.I’ve taken Fathom for a spin in a few meetings this week and have generally been impressed by the quality of its transcriptions but especially by its meeting summaries. Where some other tools (looking at you, Otter) seem to try to shoehorn every meeting into a somewhat rigid flow that seems to be mostly geared toward users in sales, Fathom simply presents a useful summary that smartly creates chapters for every meeting — and you get the option to tell it what kind of meeting it was (one-on-one, Q&A, demo, sales meeting, etc.) and it will tune its summary accordingly.Below is a screenshot of the summary of my interview with Fathom for your viewing pleasure.Image Credits: Fathom","AI, Enterprise, Startups, TC",,,,5
"Brightband sees a bright (and open source) future for AI-powered weather forecasting","Devin Coldewey",2024-09-19,https://techcrunch.com/2024/09/19/brightband-sees-a-bright-and-open-source-future-for-ai-powered-weather-forecasting/,"With an explosion of weather and climate data that the last generation of tools can’t handle, is AI the future of forecasting? Research certainly suggests so, and a newly funded…","With an explosion of weather and climate data that the last generation of tools can’t handle, is AI the future of forecasting? Research certainly suggests so, and a newly funded startup called Brightband is taking a shot at turning machine learning forecast models into both a business and open source standard.Today’s weather prediction and climate monitoring techniques are rooted in statistical and numerical models that are going on decades old. That doesn’t mean they’re bad or wrong — just not particularly efficient. These physics-based models are the kind of thing you set aside a few weeks on a supercomputer for.But AI has a knack for pulling patterns out of large bodies of data, and research has shown that, when AI is trained on years of weather patterns and observations around the world, it can predict upcoming events with surprising accuracy. So why isn’t it being used all over the place?“The reason there’s this gap is that the government finds it hard to attract top talent, as do weather companies, while for these tech companies, weather is not their core industry. They don’t go deep into the domain and work with the players to give them the tools they need,” explained Julian Green, CEO and co-founder of Brightband (formerly known as OpenEarthAI). “We think a startup brings great AI people, great data people, and great weather people together. There’s a real opportunity to operationalize AI and make it available to everyone.”The startup is in the process of designing its own model trained on years of weather observation data, but Daniel Rothenberg, co-founder and head of data and weather, was quick to note that they’re “standing on the shoulders of giants.”“The big physics-based models are monsters,” he said. “But AI is the beneficiary of those models — the first leap was taking advantage of them, finding that the models really can learn those patterns. We’re building on top of that and extending it. We’re shooting for state of the art: as good or better than the available global weather forecasting.”It would also be orders of magnitude faster, Green noted. “That’s sort of the core disruption: it’s faster and cheaper,” making it more suitable to custom and fast-moving use cases.“People have very specific needs across different industries,” Green went on. “Energy companies need to be able to predict the supply of renewables from wind and sun, and demand for heating and cooling; transportation companies need to avoid extreme weather; agriculture needs to plan weeks out to hire people to seed, water, fertilize, or harvest.”Interestingly, the company is committing to releasing its models for anyone to use.“Our goal is to open source the basic forecasting capability, not just the model but the data you use to train it, and the metrics you use to evaluate it; business model is to layer on top, paid-for services for more specific capabilities,” Green said.Part of doing so means including (and processing, and releasing) lots of data that has been skipped over in favor of pre-processed databases.“There’s petabytes upon petabytes of historical data from weather balloons and satellites that are ignored because they’re hard to work with,” said Rothenberg; but as with most AI models, the more data the better, and a carefully curated variety can significantly improve the quality of their output. “We really feel that building a community around this is going to accelerate the things we can do in terms of understanding the atmosphere and doing it at scale.”I suggested that this seemed almost like they were doing what the National Weather Service (which provides tons of observational data and forecasts for free as a public service) and other agencies would do if they could.Green demurred, saying they work closely with those agencies and that they are indeed the keepers of a trove of important data — it just isn’t necessarily the kind of fast, portable data that a highly responsive consumer-facing company needs. He said they see this as a continuation of the international collaboration on weather data.As for where they actually are in building the product: “It’s relatively early,” Green admitted. “We’ve been working on this for a few months, nothing is live today but we hope to have a model by the end of 2024 that takes in observations [i.e. satellite or local radar imagery] and produces a forecast for them.”Brightband is structured as a public benefit corporation, but that’s “primarily signaling,” Green said. “We’re trying to lay out our mission transparently, pinning our cause to the mast and saying ‘this is what we’re interested in doing.’ I think the 10 million we raised is testament to the fact that we’re able to attract capital.”A PBC in this case basically means the board has to balance shareholder interests with those of the stated mission in certain circumstances, but doesn’t limit profits or anything like that.Expect a weather-related product before a climate one — but neither has a hard timeline except for the end-of-year show-and-tell.Brightband’s $10 million Series A round was led by Prelude Ventures, with participation from Starshot Capital, Garage Capital, Future Back Ventures, Preston-Werner Ventures, CLAI Ventures, Adrien Treuille, and Cal Henderson.","AI, brightband, Fundraising, prelude ventures, Startups, weather",,,,6
"AI governance can’t be left to the vested interests","Natasha Lomas",2024-09-19,https://techcrunch.com/2024/09/19/ai-governance-cant-be-left-to-the-vested-interests/,"A final report by the UN’s high-level advisory body on artificial intelligence makes for, at times, a surreal read. Named “Governing AI for Humanity,” the document underlines the contradictory challenges…","A final report by the UN’s high-level advisory body on artificial intelligence makes for, at times, a surreal read. Named “Governing AI for Humanity,” the document underlines the contradictory challenges of making any kind of governance stick on such a fast developing, massively invested and heavily hyped technology.On the one hand, the report observes — quite correctly — that there’s “a global governance deficit with respect to AI.” On the other, the UN advisory body dryly points out that: “Hundreds of [AI] guides, frameworks and principles have been adopted by governments, companies and consortiums, and regional and international organizations.” Even as this report adds plus-one-more set of recommendations to the AI governance pile.The overarching problem the report is highlighting is there’s a patchwork of approaches building up around governing AI, rather than any collective coherence on what to do about a technology that’s both powerful and stupid. AI automation can certainly be powerful: Press the button and you get outputs scaled on demand. But AI can also be stupid because, despite what the name implies, AI is not intelligence; its outputs are a reflection of its inputs; and bad inputs can lead to very bad (and unintelligent) outcomes.Add scale to stupidity and AI can cause very big problems indeed, as the report highlights. For instance, it can amplify discrimination or spread disinformation. Both of which are already happening, in all sorts of domains, at problematic scale, which leads to very real-world harms.But those with commercial irons in the generative AI fire that’s been raging over the past few years are so in thrall to the potential scale upside of this technology that they’re doing everything they can to downplay the risks of AI stupidity.In recent years, this has included heavy lobbying about the idea that the world needs rules to protect against so-called AGI (artificial general intelligence), or the concept of an AI that can think for itself and could even out-think humans. But this is a flashy fiction intended to grab policymakers’ attention and focus lawmakers’ minds on nonexistent AI problems, thereby normalizing the harmful stupidities of current gen AI tools. (So really, the PR game being played is about defining and defusing the notion of concept of “AI Safety” by making it mean let’s just worry about science fiction.)A narrow definition of AI safety serves to distract from the vast environmental harms of pouring ever more compute power, energy, and water into building data centers big enough to feed this voracious new beast of scale. Debates about whether we can afford to keep scaling AI like this are not happening at any high level — but maybe they should be?The ushered-in spector of AGI also serves to direct the conversation to skip over the myriad legal and ethical issues chain-linked to the development and use of automation tools trained on other people’s information without their permission. Jobs and livelihoods are at stake. Even whole industries. And so are individual people’s rights and freedoms.Words like “copyright” and “privacy” scare AI developers far more than the claimed existential risks of AGI because these are clever people who haven’t actually lost touch with reality.But those with a vested interest in scaling AI choose to harp only about the potential upside of their innovations in order to minimize the application of any “guardrails” (to use the minimalist metaphor of choice when technologists are finally forced to apply limits to their tech) standing in the way of achieving greater profits.Toss in geopolitical rivalries and a bleak global economic picture and nation states’ governments can often be all too willing to join the AI hype and fray, pushing for less governance in the hopes it might help them scale their own national AI champions.With such a skewed backdrop, is it any wonder AI governance remains such a horribly confusing and tangled mess? Even in the European Union where, earlier this year, lawmakers did actually adopt a risk-based framework for regulating a minority of applications of AI, the loudest voices discussing this landmark effort are still decrying its existence and claiming the law spells doom for the bloc’s chances of homegrown innovation. And they’re doing that even after the law got watered down after earlier tech industry lobbying (led by France, with its eye on the interests of Mistral, its hope for a national GenAI champion).A new push to deregulate EU privacy lawsVested interests aren’t stopping there, either. We now have Meta, owner of Facebook and Instagram — turned Big AI developer — openly lobbying to deregulate European privacy laws to remove limits on how it can use people’s information to train AIs. Will no one rid Meta of this turbulent data protection regulation so it can strip-mine Europeans of their culture for ad profit?  Its latest open letter lobbying against the EU’s General Data Protection Regulation (GDPR), which was written up in the WSJ, loops in a bunch of other commercial giants also willing to deregulate for profit, including Ericsson, Spotify, and SAP.“Europe has become less competitive and less innovative compared to other regions and it now risks falling further behind in the AI era due to inconsistent regulatory decision making,” the letter reportedly suggests. Meta has a long history of breaking EU privacy law — chalking up a majority of the 10 largest-ever GDPR fines to date, for example, and racking up billions of dollars in fines — so it really shouldn’t be a poster child for lawmaking priorities. Yet, when it comes to AI, here we are! Having broken so many EU laws, we’re apparently supposed to listen to Meta’s ideas for removing the obstacle of having laws to break in the first place? This is the kind of magical thinking AI can provoke.But the really scary thing is there’s a danger lawmakers might inhale this propaganda and hand the levers of power to those who would automate everything — putting blind faith in a headless god of scale in the hopes that AI will automagically deliver economic prosperity for all. It’s a strategy — if we can even call it that — which totally ignores the fact that the last several decades of (very lightly regulated) digital development have delivered the very opposite: a staggering concentration of wealth and power sucked in by a handful of massive platforms — Big Tech.Clearly, platform giants want to repeat the trick with Big AI. But policymakers risk walking mindlessly down the self-serving pathways being recommended to them by its handsomely rewarded army of policy lobbyists. This isn’t remotely close to a fair fight — if it’s even a fight at all.Economic pressures are certainly driving a lot of soul searching in Europe right now. A much anticipated report earlier this month by the Italian economist Mario Draghi on the never-so-sensitive topic of the future of European competitiveness itself chafes at self-imposed “regulatory burdens” that are also specifically described as “self-defeating for those in the digital sectors.”Given the timing of Meta’s open letter, it’s surely aiming to hook into the same conclusion. But that’s hardly surprising: Meta and several of the others adding their signatures to this push to deregulate EU privacy laws are among the long list of companies that Draghi directly consulted for his report. (Meanwhile, as others have pointed out, the economist’s contributor disclosure list does not include any digital rights or human rights groups, aside from the consumer group BEUC.)Recommendations from the UN AI advisory group The asymmetry of interests driving AI uptake while simultaneously seeking to downgrade and dilute governance efforts makes it hard to see how a genuinely global consensus can emerge on how to control AI’s scale and stupidity. But the UN AI advisory group has a few solid-looking ideas if anyone is willing to listen.The report’s recommendations include setting up an independent international scientific panel to survey AI capabilities, opportunities, risks, and uncertainties and identify areas where more research is needed with a focus on the public interest (albeit, good luck finding academics not already on Big AI’s payroll). Another recommendation is intergovernmental AI dialogues that would take place twice a year on the margins of existing UN meetings to share best practices, exchange info, and push for more international interoperability on governance. The report also mentions an AI standards exchange that would maintain a register of definitions and work to foster standards harmonization internationally.The UN body also suggests creating what it calls an “AI capacity development network” to pool expertise and resources to support the development of AI governance within governments and for the public interest; and also setting up a global fund for AI to tackle digital divides that the unequal distribution of automation technology also risks scaling drastically.On data, the report suggests establishing what it calls a “global AI data framework” to set definitions and principles for governing training data, including with a view to ensuring cultural and linguistic diversity. The effort should establish common standards around the provenance of data and its use — to ensure “transparent and rights-based accountability across jurisdictions.”The UN body also recommends setting up data trusts and other mechanisms that it suggests could help foster AI growth without compromising information stewardship, such as through “well-governed global marketplaces for exchange of anonymized data for training AI models” and via “model agreements” to allow for cross border access to data.A final recommendation is for the UN to establish an AI Office within the Secretariat to act as a coordination body, reporting to the secretary general to provide support, engage in outreach and advise the UN chief. And one thing is clear: AI is going to demand a massive mobilization of effort, organization, and sweating toil if we’re to avoid the vested interests setting the governance agenda. (","AI, AI governance, Government & Policy",,,,7
"Fal.ai, which hosts media-generating AI models, raises $23M from a16z and others","Kyle Wiggers",2024-09-18,https://techcrunch.com/2024/09/18/fal-ai-which-hosts-media-generating-ai-models-raises-23m-from-a16z-and-others/,"Fal.ai, a dev-focused platform for AI-generated audio, video, and images, today revealed that it’s raised $23 million in funding from investors including Andreessen Horowitz (a16z), Black Forest Labs co-founder Robin…","Fal.ai, a dev-focused platform for AI-generated audio, video, and images, today revealed that it’s raised $23 million in funding from investors including Andreessen Horowitz (a16z), Black Forest Labs co-founder Robin Rombach, and Perplexity CEO Aravind Srinivas.It’s a two-round deal: $14 million of Fal’s total came from a Series A tranche led by Kindred Ventures; the remaining $9 million is from a previously unannounced, a16z-led seed round.Burkay Gur and Gorkem Yurtseven co-launched Fal (short for “Features and labels”) in 2021. Yurtseven previously worked at Amazon as a software dev, while Gur, an ex-Oracle engineer, led machine learning development at Coinbase for several years.While hacking together side projects during the pandemic, Gur and Yurtseven, longtime friends, realized the growing demand for AI cloud infrastructure — particularly infrastructure to run generative AI models.“The big bet was that the nascent space of generative media was about to change all media consumed,” Gur told TechCrunch. “The timing worked out perfectly, because there were some breakthrough models that were released right after Fal started.”Fal offers two products: privately managed compute and workflows for running models, and APIs for open source models that generate images, audio, and video. Fal was one of the first platforms to host Black Forest Labs’ Flux, the model powering image generation in Grok, X’s controversial chatbot. Many cloud rivals like CoreWeave provide resources along these same lines. But what makes Fal different is its scalability, Gur argues.“Our platform can handle hundreds of millions of requests [and our] own inference engine is the most performant,” he said. “Using Fal, you can integrate models into your applications — the product is for enterprises that have media at the core of what they do.”Whether those claims hold up to scrutiny or not, Fal has managed to grow an impressive customer roster. In addition to Perplexity (which explains Srinivas’ investment) and enterprise customers in the retail and e-commerce sector, popular generative AI apps Photoroom, Freepik, and PlayHT are all paying for Fal’s services, Gur says.Models in Fal.ai’s model gallery.Image Credits: FalIt’s a profitable bunch. A source tells TechCrunch that Fal’s annual run rate has climbed to nearly $10 million (~$800,000 per month), up around 10x from January. The Series A valued the startup at $80 million.“Fal has reached 500,000 developers on the platform,” Gur said, “generating 50 million images, videos, or audio streams a day.”Given the many deepfake and misinformation risks around generative technologies, I asked Gur if Fal has moderation policies or filters in place for sensitive content. He said that Fal prefers to take a hands-off approach, leaving the decision whether to implement safety features up to the companies developing models on Fal’s platform.“For moderation, a lot of what is done happens during training, so we leave that to the companies building the models,” Gur said. “As you might guess, having a very robust program requires more research and resources.”It’s a bit of an empty answer, given that Fal sponsors some open source training efforts under its research grants program. One would assume that Fal has a say in the development of models it funds.Gur did suggest, however, that Fal is looking to undertake some de-toxifying efforts itself… at some point. “We do have plans to do more of this in-house, and rely on some vendors specialized in this type of work,” he said.I asked about IP liability, as well. Should the models on Fal’s platform regurgitate any copyrighted data, will the company protect customers if they’re sued? Gur wouldn’t answer. But the language in Fal’s terms of service imply that customers are on their own.That’s in contrast to generative AI products from Adobe, Canva, Google, Microsoft, and Shutterstock, all of which have indemnity clauses (albeit with some carve-outs). Vendors like Getty Images, as well as startups such as Fairly Trained, have gone so far as to train models only on “commercially safe” content to avoid the threat of copyright lawsuits altogether.That’s all to say, those who use Fal assume some risk.Fal intends to spend the bulk of the capital it’s raised so far on upgrading its inference optimization product to make it self-serve. The company is also establishing a research team that’ll focus on model optimizations and will join Fal’s 17-person staff.Fal’s other backers include Vercel founder Guillermo Rauch, entrepreneur and investor Balaji Srinivasan, and Hugging Face CTO Julien Chaumond.","AI, AI, Exclusive, fal.ai, Funding, Fundraising, Generative AI, generative media, Kindred Ventures, Startups",,,,8
"LinkedIn scraped user data for training before updating its terms of service","Kyle Wiggers",2024-09-18,https://techcrunch.com/2024/09/18/linkedin-scraped-user-data-for-training-before-updating-its-terms-of-service/,"LinkedIn may have trained AI models on user data without updating its terms. LinkedIn users in the U.S. — but not the EU, EEA, or Switzerland, likely due to those…","LinkedIn may have trained AI models on user data without updating its terms.LinkedIn users in the U.S. — but not the EU, EEA, or Switzerland, likely due to those regions’ data privacy rules — have an opt-out toggle in their settings screen disclosing that LinkedIn scrapes personal data to train “content creation AI models.” The toggle isn’t new. But, as first reported by 404 Media, LinkedIn initially didn’t refresh its privacy policy to reflect the data use.The terms of service have now been updated, but ordinarily that occurs well before a big change like using user data for a new purpose like this. The idea is it gives users an option to make account changes or leave the platform if they don’t like the changes. Not this time, it seems.So what models is LinkedIn training? Its own, the company says in a Q&A, including models for writing suggestions and post recommendations. But LinkedIn also says that generative AI models on its platform may be trained by “another provider,” like its corporate parent Microsoft.“As with most features on LinkedIn, when you engage with our platform we collect and use (or process) data about your use of the platform, including personal data,” the Q&A reads. “This could include your use of the generative AI (AI models used to create content) or other AI features, your posts and articles, how frequently you use LinkedIn, your language preference, and any feedback you may have provided to our teams. We use this data, consistent with our privacy policy, to improve or develop the LinkedIn services.”LinkedIn previously told TechCrunch that it uses “privacy enhancing techniques, including redacting and removing information, to limit the personal information contained in datasets used for generative AI training.”To opt out of LinkedIn’s data scraping, head to the “Data Privacy” section of the LinkedIn settings menu on desktop, click “Data for Generative AI improvement,” then toggle off the “Use my data for training content creation AI models” option. You can also attempt to opt out more comprehensively via this form, but LinkedIn notes that any opt-out won’t affect training that’s already taken place.Image Credits: LinkedInThe nonprofit Open Rights Group (ORG) has called on the Information Commissioner’s Office (ICO), the U.K.’s independent regulator for data protection rights, to investigate LinkedIn and other social networks that train on user data by default. Earlier this week, Meta announced that it was resuming plans to scrape user data for AI training after working with the ICO to make the opt-out process simpler.“LinkedIn is the latest social media company found to be processing our data without asking for consent,” Mariano delli Santi, ORG’s legal and policy officer, said in a statement. “The opt-out model proves once again to be wholly inadequate to protect our rights: the public cannot be expected to monitor and chase every single online company that decides to use our data to train AI. Opt-in consent isn’t only legally mandated, but a common-sense requirement.”Ireland’s Data Protection Commission (DPC), the supervisory authority responsible for monitoring compliance with the GDPR, the EU’s overarching privacy framework, told TechCrunch that LinkedIn informed it last week that clarifications to its global privacy policy would be issued today.“LinkedIn advised us that the policy would include an opt-out setting for its members who did not want their data used for training content generating AI models,” a spokesperson for the DPC said. “This opt-out is not available to EU/EEA members as LinkedIn is not currently using EU/EEA member data to train or fine-tune these models.”TechCrunch has reached out to LinkedIn for comment. We’ll update this piece if we hear back.The demand for more data to train generative AI models has led a growing number of platforms to repurpose or otherwise reuse their vast troves of user-generated content. Some have even moved to monetize this content — Tumblr owner Automattic, Photobucket, Reddit, and Stack Overflow are among the networks licensing data to AI model developers.Not all of them have made it easy to opt out. When Stack Overflow announced that it would begin licensing content, several users deleted their posts in protest — only to see those posts restored and their accounts suspended.","AI, AI, Enterprise, Generative AI, LinkedIn, social network",,,,9
"Runway announces an API for its video-generating AI models","Kyle Wiggers",2024-09-16,https://techcrunch.com/2024/09/16/runway-announces-an-api-for-its-video-generating-models/,"Runway, one of several AI startups developing video-generating tech, today announced an API to allow devs and organizations to build the company’s generative AI models into third-party platforms, apps, and…","Runway, one of several AI startups developing video-generating tech, today announced an API to allow devs and organizations to build the company’s generative AI models into third-party platforms, apps, and services.Currently in limited access (there’s a waitlist), the Runway API only offers a single model to choose from — Gen-3 Alpha Turbo, a faster but less capable version of Runway’s flagship, Gen-3 Alpha — and two plans, Build (which is aimed at individuals and teams) and Enterprise. Base pricing is one cent per credit (one second of video costs five credits), and Runway says that “trusted strategic partners” including marketing group Omnicom are already using the API.The Runway API also comes with unusual disclosure requirements. Any interfaces using the API must “prominently display” a “Powered by Runway” banner linking to Runway’s website, the company writes in a blog post, to “[help] users understand the technology behind [applications] while adhering to our usage terms.”Runway, which is backed by investors including Salesforce, Google, and Nvidia and was last valued at $1.5 billion, faces stiff competition in the video generation space, including from OpenAI, Google, and Adobe. OpenAI is expected to release its video-generation model, Sora, in some form this fall, while startups like Luma Labs continue to refine their technologies.Image Credits: RunwayCase in point, in what seems unlikely to be coincidental timing, Luma today launched its API for video generation, which doesn’t have a waitlist and offers features beyond Runway’s, including the ability to “control” the virtual camera in AI-generated scenes.With the preliminary launch of the Runway API, Runway becomes one of the first AI vendors to offer a video-generation model through an API. But while the API might help the company along its path to profitability (or at least recouping the high costs of training and running models), it won’t resolve the lingering legal questions around those models and generative AI tech more broadly.Runway’s video-generating models, like all video-generating models, were trained on a vast number of examples of videos to “learn” the patterns in these videos to generate new footage. Where did the training data come from? Runway refuses to say, like many vendors these days  — partly out of fear of sacrificing competitive advantage.But training details are also a potential source of IP-related lawsuits if Runway trained on copyrighted data without permission. There’s evidence that it did, in fact — a report from 404 Media in July exposed a Runway spreadsheet of training data that included links to YouTube channels belonging to Netflix, Disney, Rockstar Games, and creators like Linus Tech Tips and MKBHD.It’s unclear whether Runway ultimately ended up sourcing any of the videos in the spreadsheet to train its video models. In an interview with TechCrunch in June, Runway co-founder Anastasis Germanidis would only say that the company uses “curated, internal datasets” for model training. But if it did, it wouldn’t be the only AI vendor playing fast and loose with copyright laws.Earlier this year, OpenAI CTO Mira Murati didn’t outright deny that Sora was trained on YouTube content. And Nvidia reportedly used YouTube videos to train an internal video-generating model called Cosmos.Many generative AI vendors believe that the doctrine known as fair use provides legal cover — and they’re asserting this in court and in public statements. Others are less inclined to take chances, and/or they view a more “ethical” approach to model training as a selling point for their services. To develop its video-generating Firefly models, Adobe is said to be offering artists payments in exchange for clips, for example.In its terms of service, Luma says that it’ll agree to defend and indemnify API business customers for damages arising out of IP violation claims. Other vendors, including OpenAI, offer similar indemnification policies; Runway does not, although it said last December that it would partner with stock media library Getty to develop more “commercially safe” versions of its products. However the lawsuits pertaining to the legality of training on copyright content shake out, one thing’s becoming clear: Generative AI video tools threaten to upend the film and TV industry as we know it. A 2024 study commissioned by the Animation Guild, a union representing Hollywood animators and cartoonists, found that 75% of film production companies that have adopted AI have reduced, consolidated, or eliminated jobs after incorporating the tech. The study also estimates that by 2026, more than 100,000 U.S. entertainment jobs will be disrupted by generative AI.Updated 9/16 at 11:18 Pacific: Added info about Luma’s API launch.","AI, AI, api, Generative AI, Media & Entertainment, runway, Startups, video generation, video-generating model",,,,10
"Oracle’s Larry Ellison says that AI will someday track your every move","Kyle Wiggers",2024-09-16,https://techcrunch.com/2024/09/16/oracle-ceo-larry-ellison-says-that-ai-will-someday-track-your-every-move/,"Speaking at an Oracle financial analysts meeting, Oracle founder Larry Ellison said he expects AI to one day power massive law enforcement surveillance networks. “We’re going to have supervision,” he…","Speaking at an Oracle financial analysts meeting, Oracle founder Larry Ellison said he expects AI to one day power massive law enforcement surveillance networks.“We’re going to have supervision,” he said. “Every police officer is going to be supervised at all times, and if there’s a problem, AI will report that problem and report it to the appropriate person. Citizens will be on their best behavior because we are constantly recording and reporting everything that’s going on.”Ellison believes that continuous surveillance, driven by AI, could greatly reduce crime. But the evidence doesn’t necessarily support his assertion.As the Washington Post notes, police data in the U.S. is historically biased, and feeding it into an AI model could lead it to suggest more criminal activity is in those areas, creating racially and socioeconomically biased feedback loops.In 2019, the LAPD suspended its crime prediction program after an audit showed it resulted in subjecting Black and Latino people to more surveillance.Correction: An earlier version of this article misstated Larry Ellison’s title. He is Oracle’s chairman and CTO.","AI, AI, In Brief, oracle, surveillance",,,,11
"11x.ai raises $24M led by Benchmark to build AI digital employees","Dominic-Madori Davis",2024-09-16,https://techcrunch.com/2024/09/16/ai-digital-employee-startup-11xai-raises-24m-led-by-benchmark/,"The Series A comes about a year after 11x.ai raised a $2 million seed round led by Project A Ventures.","A startup that builds AI bots for process automation (aka automating end-to-end workflows), 11x.ai just raised a fresh $24 million Series A led by Benchmark. It is also one of a growing crowd of AI startups relocating its headquarters to San Francisco, Hasan Sukkar, the company’s founder and CEO, told us. It was founded in London.The Series A comes about a year after 11x.ai raised a $2 million seed round led by Project A Ventures. Founded in 2022, the company calls its AI agents “automated digital workers,” and like others in this field, its pitch is that its software can handle repetitive tasks, allowing human employees to focus on more strategic work. The company focuses on go-to-market teams, like sales, marketing, and revenue operations. It started out with Alice, an AI sales representative, and has now launched Jordan, which serves as an AI phone representative. “He sounds like a real human. He can have conversations up to 30 minutes in real-time in a way that’s really intelligent,” Sukkar said. He says the company is also approaching $10 million in annual recurring revenue and says it counts companies like Brex, DataStax, and Otter as customers, according to its website. “Thinking ahead, there will be two additional digital workers that we are launching in the coming months,” Sukkar continued. “All of this is part of our plan to build a suite of deeply integrated agents” — or virtual employees, he added, that have names and faces with job categories they are trained on. The 11x.ai digital workers are currently trained on 25 languages, including Swedish, Italian, German, and Hebrew. Sukkar previously told TechCrunch that he was working on a bot named James and one named Bob trained to do talent acquisition and human resources tasks, but Sukkar said the company decided to release Jordan, the phone representative, first. While Sukkar obviously believes that autonomous agents are the future of the workforce, he also says that such agents are in the very early days of innovation.“Instead of traditional software, which is tools and workflows that make people slightly more productive or efficient, agents enable us to automate activities in a way that operates on autopilot, in a way that requires no humanity, in a way that is extremely high skill,” he says of his vision of a highly proficient, no-human-required workforce.When AI agents can reliably replace humans in manual processes, “it would be a shift almost as big as the internet or the cloud,” he said. But 11x.ai is not without competition in this area. Large established competitors include companies like UiPath, ServiceNow, and even Salesforce. Plus, as we previously reported, AI sales bots are such a fast-growing AI market that there are a good dozen of them beyond 11x.ai that are growing quickly, VCs have told TechCrunch. Some of the others include Docket, Regie.ai, AiSDR, and Artisan.  Investors, like Sarah Tavel, a general partner at Benchmark, who led the $24 million Series A, is quite bullish on 11x.ai, though. Tavel, who also wrote a thesis on the importance of AI in work software, now joins the board at 11x.ai. Sukkar said that the company received about eight investment offers within 10 days. “It was a really fast process,” he said. “We leaned into partnering with the team at Benchmark because of the alignment on the thesis and their track record as one of the most successful investors in the world.” Other investors in the round included 20VC, Project A, Lux Capital, and SV Angel. The company will use the money to further product development and expand its team, which currently has a headcount of 27. The company will retain an office in London, though most key staff will be relocated to SF. “I started 11x out of an experience where, in one of my first ever jobs I did back when I was a student, a lot of work that was monotonous and repetitive,” he said, adding that he recalls wishing there was a computer that would do it for him and how much human potential is wasted every day doing such laborious tasks. “Agents enable us to automate in a way that redefines what’s possible.”","11xAI, AI, AI SDR, Exclusive, Fundraising, robotic process automation, sales automation, Startups",,,,12
"Colin Kaepernick is coming to TechCrunch Disrupt 2024","Maxwell Zeff",2024-09-16,https://techcrunch.com/2024/09/16/colin-kaepernick-is-coming-to-techcrunch-disrupt-2024/,"Earlier this year, former NFL quarterback and civil rights activist Colin Kaepernick launched his AI startup, Lumi. Kaepernick has had thousands of stories written about him, and he knows a…","Earlier this year, former NFL quarterback and civil rights activist Colin Kaepernick launched his AI startup, Lumi. Kaepernick has had thousands of stories written about him, and he knows a thing or two about losing control of his narrative. Now with Lumi, he’s trying to help creators take control of their own narratives, offering AI tools to write and take ownership of their stories.We’re thrilled to welcome Kaepernick to the main stage at TechCrunch Disrupt 2024 in San Francisco, where we’ll discuss his run-ins with the media industry, the problems creators face today, and how Lumi is trying to empower its storytellers. We’ll also discuss how Kaepernick’s company is addressing the biases that plague AI models throughout the tech industry.While many of us know Kaepernick for his Super Bowl XLVII performance or his kneel to protest racial injustice, you may be surprised to know that he’s been quietly angel investing in Silicon Valley startups since 2017. He previously told TechCrunch he has more than 50 investments to date.He’s also become a well-rounded media executive over the last decade. The former NFL quarterback founded and runs Kaepernick Media and Kaepernick Publishing, where he sees the media industry’s deeply entrenched problems firsthand. He also sits on the board of Medium alongside a16z co-founder Ben Horowitz, who Kaepernick calls a mentor in navigating Silicon Valley.Lumi tries to give creators more tools that were previously only available through big media companies. The startup is starting by focusing on the world of Japanese comic books, also known as manga. Some of Lumi’s tools use AI, helping storytellers with the ideation process, writing, and generating images of characters. Other tools don’t involve AI, such as publishing resources and merchandising assistance. Kaepernick also describes Lumi’s platform as a destination, where viewers can come to browse through content from a diverse group of creators.It’s a broad and ambitious idea from someone with experience inside and outside the media industry. We’ll ask him all about how these plans are going.Don’t miss it!You definitely won’t want to miss it. Join over 10,000 startup, tech, and VC leaders at Disrupt 2024, where you’ll engage in inspiring conversations with industry giants like Kaepernick. Secure your tickets now before prices increase at the door.","AI, Startups, TC, TechCrunch Disrupt 2024",,,,13
"Generative AI startup Typeface acquires two companies, Treat and Narrato, to bolster its portfolio","Kyle Wiggers",2024-09-16,https://techcrunch.com/2024/09/16/generative-ai-startup-typeface-acquires-two-companies-treat-and-narrato-to-bolster-its-portfolio/,"Typeface, a generative AI startup focused on enterprise use cases, has acquired a pair of companies just over a year after raising $165 million at a $1 billion valuation. Typeface…","Typeface, a generative AI startup focused on enterprise use cases, has acquired a pair of companies just over a year after raising $165 million at a $1 billion valuation.Typeface revealed on Monday that it has purchased Treat, a company using AI to create personalized photo products, and Narrato, an AI-powered content creation and management platform.Treat and Narrato will “enrich [Typeface’s] multimodal capabilities,” the company said in a press release, while “propelling [its] vision of end-to-end content lifecycle transformation.”“Building on our foundation of multimodal AI workflows, these acquisitions’ top-tier AI technology and talent further enrich our visual and textual capabilities,” Typeface wrote in the release. “By integrating these technologies, we’re supercharging the entire Typeface portfolio.”Typeface, founded in 2022 by former Adobe CTO Abhay Parasnis, offers tools for text and image generation, a fine-tuning engine to personalize AI to a brand’s style, and integrations with third-party apps, software, and services. Typeface claims to place a greater emphasis on brand governance and privacy than its generative AI rivals; for example, Typeface trains dedicated AI models for each customer to ensure their assets and activity remain private.So how do Treat and Narrato fit into this vision? Well, both were started by founders well-acquainted with the enterprise landscape. And — not for nothing — the startups offer products appealing to the sorts of corporate clients with whom Typeface does business.NYC-based Treat, the brainchild of Matt Osman and ex-Drizly CTO Hugh Hunter, uses a company’s data on customers to generate product images that incorporate elements known to perform well with certain target demographics. For example, if a fruit vendor’s data suggested that younger men prefer seeing food ads that show a person eating the product, Treat may create an ad that depicts someone biting into fruit.An image generated by Treat.Image Credits: TreatAn Australian venture, Narrato — which coincidentally also launched in 2022 — sells access to an “AI content assistant” designed to help orgs achieve their internal content creation and planning goals. As founder Sophia Solanki explained to TechCrunch in an interview last March, Narrato customers also get collaboration and workflow tools including templates for articles, video scripts, blogs, emails, social media content, art, and more.Image Credits: NarratoTreat raised at least $8.5 million from investors including Greylock prior to the acquisition, while Narrato manage to raise more than $1 million from Airtree Ventures, OfBusiness, and serial entrepreneur Shreesha Ramdas.Typeface wouldn’t disclose the terms of either acquisition.Treat and Narrato mark the third and fourth acquisitions for Typeface, which purchased AI photo and video editing suite TensorTour in January and chatbot app Cypher in May. It’s unclear how much of a dent those deals have made in Typeface’s $165 million war chest.","AI, AI, Enterprise, Enterprise, Funding, Fundraising, Generative AI, Media & Entertainment, Mergers and Acquisitions, Narrato, Startups, treat, typeface",,,,14
"AI coding assistant Supermaven raises cash from OpenAI and Perplexity co-founders","Kyle Wiggers",2024-09-16,https://techcrunch.com/2024/09/16/ai-coding-assistant-supermaven-raises-cash-from-openai-and-perplexity-founders/,"Supermaven, an AI coding assistant, has raised $12 million in a funding round that had participation from OpenAI and Perplexity co-founders.","Jacob Jackson was all-in on AI early in his career. Jackson co-founded Tabnine, the AI coding assistant that went on to raise close to $60 million in venture backing, while still a computer science student at the University of Waterloo. After selling Tabnine to Codata in 2019 (during his final exams), Jackson joined OpenAI as an intern, where he worked until 2022. It was at that juncture that Jackson had the urge to start a company again, one focused on supporting common developer workflows.“In the years since I built Tabnine, tools like ChatGPT and GitHub Copilot have changed the way developers work,” Jackson told TechCrunch. “It’s a really exciting time to be working on developer tools because the underlying technology has improved so much since I started Tabnine — which has led to many more developers becoming interested in using AI tools to accelerate their workflow.”So Jackson started Supermaven, an AI coding platform along the lines of Tabnine but with a few quality of life and technical upgrades.Supermaven’s in-house generative AI model, Babble, can understand a lot of code at once, Jackson says, thanks to a 1 million-token context window. (In data science, tokens are subdivided bits of raw data — like the syllables “fan,” “tas” and “tic” in the word “fantastic.”) A model’s context, or context window, refers to input data (e.g. code) that the model considers before generating output (e.g. additional code). Long context can prevent models from “forgetting” the content of recent docs and data, and from veering off topic and extrapolating wrongly.“Our large context window helps reduce the frequency of hallucinations because it lets the model draw answers from the context in situations where it would otherwise have to guess,” Jackson said. One million tokens is a big context window, indeed. But it’s not bigger than AI coding startup Magic’s, which is 100 million tokens. Meanwhile, Google’s recently introduced Code Assist tool matches Supermaven’s context at 1 million tokens.So what are Supermaven’s advantages over rivals? Well, Jackson claims that Babble is lower-latency thanks to a “new neural architecture.” He wouldn’t elaborate beyond saying that the architecture was developed “from scratch.” “Supermaven spends 10 to 20 seconds processing a developer’s code repository to become familiar with its APIs and the unique conventions of its codebase,” Jackson said. “With lower latency because of our in-house model serving infrastructure, our tool remains responsive while working with the long prompts that come with large codebases.”The market for AI coding tools is a large and growing one, with Polaris Research projecting that it’ll be worth $27.17 billion by 2032. The vast majority of respondents in GitHub’s latest dev poll say that they’ve adopted AI tools in some form, and over 1.8 million people — and ~50,000 businesses — are paying for GitHub Copilot.But Supermaven — along with startup competitors like Cognition, Anysphere, Poolside, Codeium, and Augment — have ethical and legal challenges to overcome.Businesses are often wary of exposing proprietary code to a third party; for instance, Apple reportedly banned staff from using Copilot last year, citing concerns about confidential data leakage. Some code-generating tools trained using restrictively licensed or copyrighted code have been shown to regurgitate that code when prompted in a certain way, posing a liability risk (i.e. developers that incorporate the code could be sued). And, because AI makes mistakes, assistive coding tools can result in more mistaken and insecure code being pushed to codebases.Jackson said that Supermaven doesn’t use customer data to train its models. He did admit, however, that the company retains data for a week to “make the system quick and responsive,” he said. On the subject of copyright, Jackson didn’t explicitly deny that Babble was trained on IP-protected code — only that it was “trained almost exclusively on publicly available code rather than a scrape of the public internet” to “reduce exposure to toxic content during training.”Customers don’t appear to be dissuaded. More than 35,000 developers are using Supermaven, Jackson says, and a sizeable chunk are paying for the premium Pro ($10 per month) and Team ($10 per month per use) plans. Supermaven’s annual recurring revenue reached $1 million this year on the back of a user base that’s grown 3x since the platform’s February launch.That momentum got the attention of VCs. Supermaven this week announced its first outside funding: a $12 million round led by Bessemer Venture Partners and high-profile angel investors including OpenAI co-founder John Schulman and Perplexity co-founder Denis Yarats. Jackson says that the plan is to spend the money on hiring developers (Supermaven has a five-person team presently) and developing Supermaven’s text editor, which is currently in beta. “We plan to grow significantly through the end of the year,” he added. “Despite headwinds for tech overall, the market for coding copilots has been growing quickly. Our growth since our launch in February — as well as our most recent funding round — position us well as we head into next year.”","AI, AI, Bessemer Venture Partners, coding assistant, developer, Enterprise, Funding, Fundraising, Generative AI, Startups, Startups, supermaven",,,,15
"DryMerge promises to connect apps that normally don’t talk to each other — and when it works, it’s great","Kyle Wiggers",2024-09-15,https://techcrunch.com/2024/09/15/drymerge-promises-to-connect-apps-that-normally-dont-talk-to-each-other-and-when-it-works-its-great/,"Platforms to connect apps that wouldn’t normally talk to each other have been around for a minute (see: Zapier). But they have not gotten dramatically simpler to use if you’re…","Platforms to connect apps that wouldn’t normally talk to each other have been around for a minute (see: Zapier). But they have not gotten dramatically simpler to use if you’re nontechnical. Generative AI has lowered the barrier to entry somewhat. However, getting the most out of these platforms — and fixing things when they break — still requires a bit of programming know-how.Software developers Sam Brashears and Edward Frazer perceived this to be the case as well. During internships at tech giants like Meta and Stripe, they struggled to get automations working using some of the more popular app-linking tools.“I’d been dealing with the pain of designing integrations and automations from scratch,” Frazer told TechCrunch in an interview. “And Sam believed that generative AI models would solve the biggest problem in integrations — transforming data between APIs.”So Brashears and Frazer, longtime friends who’d been building software together since elementary school, decided to try their hands at a streamlined, easy-to-use app-to-app integration platform.DryMerge is the fruit of their work. A chatbot for building workflows, DryMerge lets you describe an automation you want between apps — for instance, “Whenever I get an email from a new prospect, ping the team on Slack and add them to HubSpot” — and handles the necessary technical scaffolding.“Currently, IT departments use complicated no-code tools to automate workflows on behalf of non-IT teams,” Frazer said. “A natural language interface opens up automation to nontechnical people.”It sounded like a neat idea, a chatbot that can string apps together for you — particularly if you, like me, have spent countless hours wrestling with IFTTT. So, I decided to give DryMerge a go, hoping to replace my old and rickety automations once and for all.DryMerge’s UI is quite clean and minimalist. It reminds me a bit of ChatGPT; there’s not much to look at besides a text bot. Each new request (e.g., “Text me a summary of my calendar meetings every morning”) starts a new chat session, and these sessions can be revisited at any time from a list on the left-side panel.DryMerge’s automations management screen.Image Credits: DryMergeDryMerge hooks into an expanding library of apps, including Gmail, Microsoft Outlook, Salesforce, storage services like Dropbox and OneDrive, social media platforms (e.g., X), and messaging clients (e.g., Discord). Once the platform creates an automation with these, it plops that automation into a dedicated window showing when the automation last run and whether DryMerge encountered any errors.I tried setting up a few automations I thought might be useful for a reporter with an overfull schedule, like one to throw Gmail contacts into a spreadsheet and add dates from recent email invitations to a Google Calendar. Things started out promising — DryMerge had me log into the relevant apps and asked whether I’d like to test the automations to ensure everything was working properly. But then, problems started to crop up.Several times, DryMerge’s chatbot stopped responding altogether. Other times, it missed key details in a request. I tried repeatedly to get DryMerge to understand that I wanted to copy Gmail contacts to my Google Calendar, but every attempt, it thought I wanted to manually enter contacts into a spreadsheet.The setbacks didn’t completely ruin my DryMerge experience. Giving credit where it’s due, the platform’s nifty when it works. For example, I successfully got DryMerge to set up an automation that copies posts from my X account to the personal Discord server I use to aggregate various notifications. A niche use case? Perhaps. But it’s going to save this reporter a lot of task switching.Chatting with DryMerge’s bot.Image Credits: DryMergeThe bugs, Frazer assures me, will be addressed in time. He and Brashears are DryMerge’s only employees, so there’s lots on the to-do list. “We think we’re well-positioned to iterate quickly and nimbly,” Frazer said. Assuming Frazer and Brashears can get DryMerge’s platform in good working condition, the bigger challenge the duo will have to face is staying relevant in the fiercely competitive integration-platform-as-a-service (iPaaS) space. According to recent poll released by IDG and TeamDynamix, iPaaS is one of the fastest-growing software markets, projected to reach $2.7 billion this year.AWS has its own iPaaS called AppFabric. IBM recently acquired iPaaS tech from Software AG. A growing number of startups aside from DryMerge are attempting to break into the segment, while incumbents like Zapier and IFTTT are aggressively deploying generative AI capabilities.Frazer makes the case that DryMerge’s differentiator is — and will remain — “being 10x easier to use” than drag-and-drop integration builders.“Our users include online fashion retailers, school administrators, and asset managers — the vast majority of which have never touched a line of code,” he said. “They use us to save hours a day on tasks ranging from customer support automation to customer relationship management data entry.”Frazer’s not wrong about the opportunity. Per the IDG and TeamDynamix poll, 66% percent of companies said that they’ll invest in iPaaS to address internal automation and data integration challenges.“We think a gigantic enterprise opportunity is in increasing the simplicity of automation and delivering easy-to-use tooling that empowers nontechnical folks,” Frazer said.It’s very early days for DryMerge, which only has around 2,000 users at present. But the company was accepted into Y Combinator’s Winter 2024 batch, and DryMerge this past summer closed a $2.2 million seed round led by Garage Capital with participation from Goodwater Capital, Ritual Capital, and angels whose names Frazer wouldn’t reveal.Frazer says that the funds are being put toward adding new app integrations and doubling the size of DryMerge’s team in the next few months.","AI, Automation, drymerge, Exclusive, Funding, Fundraising, integration platform a service, iPaaS, Startups, TC, workflow, Y Combinator",,,,16
"Cohere co-founder Nick Frosst’s indie band, Good Kid, is almost as successful as his AI company","Rebecca Szkutak",2024-09-15,https://techcrunch.com/2024/09/15/cohere-co-founder-nick-frossts-indie-band-good-kid-is-almost-as-successful-as-his-ai-company/,"Nick Frosst, the co-founder of $5.5 billion Canadian AI startup Cohere, has been a musician his whole life. He told TechCrunch that once he started singing, he never shut up. That’s still true today. In addition to his full-time job at Cohere, Frosst is also the front man of Good…","Nick Frosst, the co-founder of $5.5 billion Canadian AI startup Cohere, has been a musician his whole life. He told TechCrunch that once he started singing, he never shut up. That’s still true today. In addition to his full-time job at Cohere, Frosst is also the front man of Good Kid, an indie rock band composed entirely of programmers.Good Kid isn’t just a group of friends jamming on the weekends in someone’s garage. The band has 2.3 million monthly Spotify listeners and recently played at Lollapalooza. It was nominated for the Canadian Academy of Recording Arts and Sciences breakthrough group of the year at the Juno Awards this year and opened for the band Portugal. The Man when it toured Canada last fall.Good Kid was formed at the University of Toronto in 2015 as a hobby, Frosst told TechCrunch. All of the members were in the computer science program except one, guitar player David Wood, but they all convinced him to switch. Good Kid launched its first single, Nomu, at the end of 2015. Nomu’s musical medley sounds like a nod to indie pop rock group Two Door Cinema Club, with Frosst’s vocals ringing out in a style that could be compared to Bloc Party front man Kele Okereke. Both Bloc Party and Two Door Cinema Club are inspirations for the group.“We didn’t really have high hopes for it,” Frosst admits about releasing that first single. “We just wanted to create something that we liked, instead of recording a bunch of songs. It did much better than we thought it would.”Good Kid dropped a handful more singles until releasing its first self-titled EP in 2018. The band has gone on to release four more albums, the latest of which came out earlier this year.About a year after the band’s debut album came out in 2018, Frosst launched Cohere with Aidan Gomez and Ivan Zhang. Cohere has since grown into a top-watched startup offering AI models for enterprises. The company has raised more than $970 million in venture capital from backers like Salesforce, Nvidia, Cisco, and Oracle, and is currently valued at $5.5 billion. Although Good Kid’s profile has continued to grow, Frosst said that he’s privileged to be able to be a musician at that level, but Cohere and working in AI is his real career.“Cohere is my life’s work,” Frosst said. “I spend the vast majority of my time [on] Cohere and music is a thing I get to do and unwind and relax.”Frosst said finding balance between the two hasn’t been too difficult. The band meets twice a week for two-hour practices. When Good Kid goes on tour, the band bangs out a full day of remote work — everyone works as a programmer — from the bus before taking the stage at night to play shows. Frosst said he actually feels he might be able to focus better on his work for Cohere when they go on tour because it prevents him from having too many meetings.“I think they are additive,” Frosst said. “I really think being able to play music helps me with my job at Cohere. It clears my mind and gives me a dedicated time to focus and makes me a smarter person.”But even when the members of the band are focused on making music, they are still thinking about AI. In the band’s first single Nomu, produced years before Cohere was founded, that first song used the line “languages lost, tokens unknown,” a reference to the tech upon which Frosst’s company would one day be found.When the band got to play on the last day of Chicago’s Lollapalooza festival in August, Frosst said it was an incredible experience. He admitted that prior to that, he actually had never even attended a musical festival, let alone played at one. Good Kid went on at 1:45 p.m. and opened the set with its song “No Time to Explain,” playing just hours before one of the group’s inspirations, Two Door Cinema Club, took the stage.Frosst says he feels grateful to be having such a successful musical career without the fear that it won’t work out, a dynamic not common in the music industry.“Getting to come to music for fun, getting to come from creativity and not for career aspirations, I’m very lucky to have found myself in this situation,” he said.","AI, Canada, Cohere, Media & Entertainment, Nick Frosst, North America, Ontario, Startups, Venture",,,,17
"OpenAI could shake up its nonprofit structure next year","Anthony Ha",2024-09-14,https://techcrunch.com/2024/09/14/openai-could-shake-up-its-nonprofit-structure-next-year/,"It’s looking increasingly likely that OpenAI will soon alter its complex corporate structure. Reports earlier this week suggested that the AI company was in talks to raise $6.5 billion at…","It’s looking increasingly likely that OpenAI will soon alter its complex corporate structure.Reports earlier this week suggested that the AI company was in talks to raise $6.5 billion at a $150 billion pre-money valuation. Now Reuters says the deal is contingent on whether OpenAI can restructure and remove a profit cap for investors.In fact, according to Fortune, co-founder and CEO Sam Altman told employees at a company-wide meeting that OpenAI’s structure is likely to change next year, bringing it closer to a traditional for-profit business. OpenAI is currently structured so that its for-profit arm is controlled by a nonprofit, which seems to frustrate investors.“We remain focused on building AI that benefits everyone and as we’ve previously shared we’re working with our board to ensure that we’re best positioned to succeed in our mission,” OpenAI said in a statement. “The nonprofit is core to our mission and will continue to exist.”","AI, In Brief, OpenAI, Venture",,,,18
"Fei-Fei Li’s World Labs comes out of stealth with $230M in funding","Marina Temkin",2024-09-13,https://techcrunch.com/2024/09/13/fei-fei-lis-world-labs-comes-out-of-stealth-with-230m-in-funding/,"Fei-Fei Li, the Stanford professor many deem the “Godmother of AI,” has raised $230 million for her new startup, World Labs, from backers including Andreessen Horowitz, NEA, and Radical Ventures.…","Fei-Fei Li, the Stanford professor many deem the “Godmother of AI,” has raised $230 million for her new startup, World Labs, from backers including Andreessen Horowitz, NEA, and Radical Ventures.World Labs is valued at over $1 billion, and the capital was raised over two rounds spaced a couple of months apart, TechCrunch reported in August.Li’s company, which hopes to have its first product ready in 2025, aims to build AI models that understand and interact with the 3D world. World Labs is developing what it calls “large world models” that will be used by professionals such as artists, designers, developers, and engineers. Martin Casado, a general partner at Andreessen Horowitz, told Wired that World Labs’ customers could include game companies or movie studios.","a16z, AI, Fei-Fei Li, In Brief, World Labs",,,,19
"First impressions of OpenAI o1: An AI designed to overthink it","Maxwell Zeff",2024-09-13,https://techcrunch.com/2024/09/13/first-impressions-of-openai-o1-an-ai-designed-to-overthink-it/,"OpenAI released its new o1 models on Thursday, giving ChatGPT users their first chance to try AI models that pause to “think” before they answer. There’s been a lot of…","OpenAI released its new o1 models on Thursday, giving ChatGPT users their first chance to try AI models that pause to “think” before they answer. There’s been a lot of hype building up to these models, codenamed “Strawberry” inside OpenAI. But does Strawberry live up to the hype?Sort of.Compared to GPT-4o, the o1 models feel like one step forward and two steps back. OpenAI o1 excels at reasoning and answering complex questions, but the model is roughly four times more expensive to use than GPT-4o. OpenAI’s latest model lacks the tools, multimodal capabilities, and speed that made GPT-4o so impressive. In fact, OpenAI even admits that “GPT-4o is still the best option for most prompts” on its help page, and notes elsewhere that o1 struggles at simpler tasks.“It’s impressive, but I think the improvement is not very significant,” said Ravid Shwartz Ziv, an NYU professor who studies AI models. “It’s better at certain problems, but you don’t have this across-the-board improvement.”For all of these reasons, it’s important to use o1 only for the questions it’s truly designed to help with: big ones. To be clear, most people are not using generative AI to answer these kinds of questions today, largely because today’s AI models are not very good at it. However, o1 is a tentative step in that direction.Thinking through big ideasOpenAI o1 is unique because it “thinks” before answering, breaking down big problems into small steps and attempting to identify when it gets one of those steps right or wrong. This “multi-step reasoning” isn’t entirely new (researchers have proposed it for years, and You.com uses it for complex queries), but it hasn’t been practical until recently.“There’s a lot of excitement in the AI community,” said Workera CEO and Stanford adjunct lecturer Kian Katanforoosh, who teaches classes on machine learning, in an interview. “If you can train a reinforcement learning algorithm paired with some of the language model techniques that OpenAI has, you can technically create step-by-step thinking and allow the AI model to walk backwards from big ideas you’re trying to work through.”OpenAI o1 is also uniquely pricey. In most models, you pay for input tokens and output tokens. However, o1 adds a hidden process (the small steps the model breaks big problems into), which adds a large amount of compute you never fully see. OpenAI is hiding some details of this process to maintain its competitive advantage. That said, you still get charged for these in the form of “reasoning tokens.” This further emphasizes why you need to be careful about using OpenAI o1, so you don’t get charged a ton of tokens for asking where the capital of Nevada is.The idea of an AI model that helps you “walk backwards from big ideas” is powerful, though. In practice, the model is pretty good at that.In one example, I asked ChatGPT o1 preview to help my family plan Thanksgiving, a task that could benefit from a little unbiased logic and reasoning. Specifically, I wanted help figuring out if two ovens would be sufficient to cook a Thanksgiving dinner for 11 people and wanted to talk through whether we should consider renting an Airbnb to get access to a third oven.(Maxwell Zeff/OpenAI)(Maxwell Zeff/OpenAI)After 12 seconds of “thinking,” ChatGPT wrote me out a 750+ word response ultimately telling me that two ovens should be sufficient with some careful strategizing, and will allow my family to save on costs and spend more time together. But it broke down its thinking for me at each step of the way and explained how it considered all of these external factors, including costs, family time, and oven management.ChatGPT o1 preview told me how to prioritize oven space at the house that is hosting the event, which was smart. Oddly, it suggested I consider renting a portable oven for the day. That said, the model performed much better than GPT-4o, which required multiple follow-up questions about what exact dishes I was bringing, and then gave me bare-bones advice I found less useful.Asking about Thanksgiving dinner may seem silly, but you could see how this tool would be helpful for breaking down complicated tasks. I also asked o1 to help me plan out a busy day at work, where I needed to travel between the airport, multiple in-person meetings in various locations, and my office. It gave me a very detailed plan, but maybe was a little bit much. Sometimes, all the added steps can be a little overwhelming.For a simpler question, o1 does way too much — it doesn’t know when to stop overthinking. I asked where you can find cedar trees in America, and it delivered an 800+ word response, outlining every variation of cedar tree in the country, including their scientific name. It even had to consult with OpenAI’s policies at some point, for some reason. GPT-4o did a much better job answering this question, delivering me about three sentences explaining you can find the trees all over the country.Tempering expectationsIn some ways, Strawberry was never going to live up to the hype. Reports about OpenAI’s reasoning models date back to November 2023, right around the time everyone was looking for an answer about why OpenAI’s board ousted Sam Altman. That spun up the rumor mill in the AI world, leaving some to speculate that Strawberry was a form of AGI, the enlightened version of AI that OpenAI aspires to ultimately create.Altman confirmed o1 is not AGI to clear up any doubts, not that you’d be confused after using the thing. The CEO also trimmed expectations around this launch, tweeting that “o1 is still flawed, still limited, and it still seems more impressive on first use than it does after you spend more time with it.”The rest of the AI world is coming to terms with a less exciting launch than expected.“The hype sort of grew out of OpenAI’s control,” said Rohan Pandey, a research engineer with the AI startup ReWorkd, which builds web scrapers with OpenAI’s models.He’s hoping that o1’s reasoning ability is good enough to solve a niche set of complicated problems where GPT-4 falls short. That’s likely how most people in the industry are viewing o1, but not quite as the revolutionary step forward that GPT-4 represented for the industry.“Everybody is waiting for a step function change for capabilities, and it is unclear that this represents that. I think it’s that simple,” said Brightwave CEO Mike Conover, who previously co-created Databricks’ AI model Dolly, in an interview. What’s the value here?The underlying principles used to create o1 go back years. Google used similar techniques in 2016 to create AlphaGo, the first AI system to defeat a world champion of the board game Go, former Googler and CEO of the venture firm S32, Andy Harrison, points out. AlphaGo trained by playing against itself countless times, essentially self-teaching until it reached superhuman capability.He notes that this brings up an age-old debate in the AI world.“Camp one thinks that you can automate workflows through this agentic process. Camp two thinks that if you had generalized intelligence and reasoning, you wouldn’t need the workflow and, like a human, the AI would just make a judgment,” said Harrison in an interview.Harrison says he’s in camp one and that camp two requires you to trust AI to make the right decision. He doesn’t think we’re there yet.However, others think of o1 as less of a decision-maker and more of a tool to question your thinking on big decisions.Katanforoosh, the Workera CEO, described an example where he was going to interview a data scientist to work at his company. He tells OpenAI o1 that he only has 30 minutes and wants to asses a certain number of skills. He can work backward with the AI model to understand if he’s thinking about this correctly, and o1 will understand time constraints and whatnot.The question is whether this helpful tool is worth the hefty price tag. As AI models continue to get cheaper, o1 is one of the first AI models in a long time that we’ve seen get more expensive.","AI, AI chatbot, ChatGPT, gpt-4, TC",,,,20
"TechCrunch Minute: Meta acknowledges it’s scraping all public posts for AI training","Anthony Ha",2024-09-13,https://techcrunch.com/video/techcrunch-minute-meta-acknowledges-its-scraping-all-public-posts-for-ai-training/,"If you’re wondering if your Facebook and Instagram posts have been used to train AI models at parent company Meta, the answer is almost certainly…","If you’re wondering if your Facebook and Instagram posts have been used to train AI models at parent company Meta, the answer is almost certainly yes.That’s probably not a huge surprise. Meta already announced that it’s using user content and data to train AI — but this week, its global privacy director, Melinda Claybaugh, acknowledged just how much of that content was actually used.The topic came up at an inquiry with Australian lawmakers, where Greens senator David Shoebridge said, “Meta has just decided that you will scrape all of the photos and all of the texts from every public post on Instagram or Facebook since 2007, unless there was a conscious decision to set them on private. That’s the reality, isn’t it?”To which Claybaugh answered: “Correct.”On today’s TechCrunch Minute, we discuss what’s been scraped, what’s been excluded, and how that differs depending on where you live.","AI, Government & Policy, Social, TechCrunch Minute, the techcrunch minute",,,,21
"A fireside chat with Andreessen Horowitz partner Martin Casado at TechCrunch Disrupt 2024","TechCrunch Events",2024-09-13,https://techcrunch.com/2024/09/13/a-fireside-chat-with-andreessen-horowitz-partner-martin-casado-at-techcrunch-disrupt-2024/,"Martin Casado, a general partner at Andreessen Horowitz, will tackle one of the most pressing issues facing today’s tech world — AI regulation — only at TechCrunch Disrupt 2024, taking…","Martin Casado, a general partner at Andreessen Horowitz, will tackle one of the most pressing issues facing today’s tech world — AI regulation — only at TechCrunch Disrupt 2024, taking place at Moscone West in San Francisco on October 28-30.Casado is a pioneering figure in software-defined networking and is a key player in the venture capital scene. He will offer insights into why startups, in particular, need to take AI regulation seriously, drawing from his deep expertise in building and investing in transformative technologies.As someone who has successfully navigated the transition from entrepreneur to investor, Casado brings a unique perspective to the discussion on the implications of regulatory frameworks for innovation and competition in the tech sector. With a track record of scaling companies from stealth to billion-dollar exits, Casado deeply understands both the opportunities and challenges AI presents for emerging businesses.Casado will draw from his experience leading Andreessen Horowitz’s $1.25 billion infrastructure practice, speaking on how companies can protect their interests in an evolving regulatory landscape while proactively engaging in regulatory conversation to shape the future of AI. Casado’s unique blend of technical knowledge, entrepreneurial success, and investment acumen makes him one of the most insightful voices on the future of AI and its regulation. He will be on the Builders Stage to share his insights and strategies on how to navigate the next wave of tech innovation with confidence.Be among the 10,000 startup and tech leaders at Disrupt 2024 to learn how you can play an active role in shaping the future of technology. Grab your ticket today before rates rise at the door.","AI, Startups, TC, TechCrunch Disrupt 2024",,,,22
"Taylor Swift cites ‘fears around AI’ as she endorses the Democratic ticket","Amanda Silberling",2024-09-11,https://techcrunch.com/2024/09/11/taylor-swift-cites-fears-around-ai-as-she-endorses-the-democratic-ticket/,"After a historic presidential debate replete with discourse about eating pets, Taylor Swift ended the evening with a bang. Arguably the most powerful figure in American pop culture, the singer-songwriter…","After a historic presidential debate replete with discourse about eating pets, Taylor Swift ended the evening with a bang. Arguably the most powerful figure in American pop culture, the singer-songwriter chose debate night to announce on Instagram that she plans to vote for Kamala Harris in the presidential election.Swift’s endorsement is monumental. She holds enough political sway to drive tens of thousands of Americans to register to vote, simply by sharing a link. But more surprisingly, she also used her announcement to express her concerns around AI deepfakes.Swift wrote on Instagram: “Recently I was made aware that AI of ‘me’ falsely endorsing Donald Trump’s presidential run was posted to his site. It really conjured up my fears around AI, and the dangers of spreading misinformation. It brought me to the conclusion that I need to be very transparent about my actual plans for this election as a voter. The simplest way to combat misinformation is with the truth.”        View this post on Instagram            A post shared by Taylor Swift (@taylorswift)By writing about her experience being deepfaked to show support for a candidate she doesn’t actually plan to vote for, Swift’s statement seemed a bit more personal.“Her statement, in my opinion, was super thought-out and written in such a compelling way, but the AI piece gives her a personal viewpoint that not everyone else would have about this election and what the candidates are doing,” Linda Bloss-Baum, an American University professor in the Business and Entertainment program, told TechCrunch.Celebrities, especially ones as prominent as Swift, are particularly vulnerable to deepfakes, since enough photos and videos of them exist online to conjure especially sophisticated AI fakes. “One of the things I’m seeing a lot of in my practice right now is the rise of AI impersonators across the board for endorsements,” Noah Downs, an IP and entertainment lawyer, told TechCrunch in August. These fake AI endorsements have become so widespread that even “Shark Tank” had to publish a PSA to warn fans about the prevalence of scams that impersonate the show’s investors. As for Swift, the artist has been the subject of viral, nonconsensual, AI-generated pornography, sparking discussion from lawmakers seeking to legislate against this harmful by-product of generative AI.“This certainly happens all of the time with average people sadly that have had their name, image, and likeness deepfaked with AI products,” Bloss-Baum said.But when celebrities like Swift are implicated, it can make lawmakers pay more attention. “As a longtime lobbyist for the entertainment industry, I can tell you that you get more attention when you go to Capitol Hill with celebrities telling their stories,” she said.When deepfakes play a role in the election to one of the most powerful seats in global politics, the stakes are a bit higher than an uncanny valley version of Lori Greiner selling diet supplements. But as election day looms closer, the U.S. holds little to no legislative ability to deter the spread of this misinformation across social media, where voters are getting their news more than ever.“Unfortunately, AI is playing a bigger role in this election, just because of the proliferation of the technology,” Bloss-Baum said. “We’ve been subject to robocalls in the past, but now the technology has gotten so good that they really can be deepfaked in such a way that the callers won’t necessarily know that it’s not the candidate.”Bloss-Baum said that since Swift is a Tennessee resident, she could potentially sue former president Trump under the ELVIS Act. Since the law is so new, however, there is little legal precedent. Regardless, Bloss-Baum thinks that consumers and celebrities alike will have more power to defend themselves if federal legislation were passed. She sees the bipartisan NO FAKES Act as particularly promising, but it’s unlikely that there will be any meaningful legislative change before the election in early November.“There’s positive things campaigns are using AI for, I’m sure, with data collection and analytics, but we need to be careful that AI is not misrepresenting candidates,” Bloss-Baum said.","AI, deepfakes, elections, Politics, Social, taylor swift",,,,23
"This Week in AI: OpenAI’s new Strawberry model may be smart, yet sluggish","Kyle Wiggers",2024-09-11,https://techcrunch.com/2024/09/11/this-week-in-ai-openais-new-strawberry-model-may-be-smart-yet-sluggish/,"Hiya, folks, welcome to TechCrunch’s regular AI newsletter. If you want this in your inbox every Wednesday, sign up here. This week in AI, OpenAI’s next major product announcement is imminent,…","Hiya, folks, welcome to TechCrunch’s regular AI newsletter. If you want this in your inbox every Wednesday, sign up here.This week in AI, OpenAI’s next major product announcement is imminent, if a piece in The Information is to be believed.The Information reported on Tuesday that OpenAI plans to release Strawberry, an AI model that can effectively fact-check itself, in the next two weeks. Strawberry will be a stand-alone product but will be integrated with ChatGPT, OpenAI’s AI-powered chatbot platform.Strawberry is reportedly better at programming and math problems than other top-end generative AI models (including OpenAI’s own GPT-4o). And it avoids some of the reasoning pitfalls that normally trip up those same models. But the improvements come at a cost: Strawberry is said to be slow — quite slow. Sources tell The Information that the model takes 10-20 seconds to answer a single question.Granted, OpenAI will likely position Strawberry as a model for mission-critical tasks where accuracy is paramount. This could resonate with businesses, many of which have grown frustrated with the limitations of today’s generative AI tech. A survey this week by HR specialist Peninsula found that inaccuracies are a key concern for 41% of firms exploring generative AI, and Gartner predicts that a third of all generative AI projects will be abandoned by the end of the year due to adoption blockers.But while some companies might not mind chatbot lag time, I think the average person will.Hallucinatory tendencies aside, today’s models are fast — incredibly fast. We’ve grown accustomed to this; the speed makes interactions feel more natural, in fact. If Strawberry’s “processing time” is indeed an order of magnitude longer than that of existing models, it’ll be challenging to avoid the perception that Strawberry is a step backward in some aspect.That’s assuming the best-case scenario: that Strawberry answers questions consistently correctly. If it’s still error-prone, like the reporting suggests, the lengthy wait times will be even tougher to swallow.OpenAI’s no doubt feeling the pressure to deliver as it burns through billions spending on AI training and staffing efforts. Its investors and potential new backers hope to see a return sooner rather than later, one imagines. But rushing to put out an unpolished model such as Strawberry — and considering charging substantially more for it — seems ill-advised.I’d think the wiser move would be to let the tech mature a bit. As the generative AI race grows fiercer, perhaps OpenAI doesn’t have the luxury. NewsApple rolls out visual search: The Camera Control, the new button on the iPhone 16 and 16 Plus, can launch what Apple calls “visual intelligence” — basically a reverse image search combined with some text recognition. The company is partnering with third parties, including Google, to power search results.Apple punts on AI: Devin writes about how many of Apple’s generative AI features are pretty basic when it comes down to it — contrary to what the company’s bombastic marketing would have you believe.Audible trains AI for audiobooks: Audible, Amazon’s audiobook business, said that it’ll use AI trained on professional narrators’ voices to generate new audiobook recordings. Narrators will be compensated for any audiobooks created using their AI voices on a title-by-title, royalty-sharing basis.Musk denies Tesla-xAI deal: Elon Musk has pushed back against a Wall Street Journal report that one of his companies, Tesla, has discussed sharing revenue with another of his companies, xAI, so that it can use the latter’s generative AI models.Bing gets deepfake-scrubbing tools: Microsoft says it’s collaborating with StopNCII — an organization that allows victims of revenge porn to create a digital fingerprint of explicit images, real or not — to help remove nonconsensual porn from Bing search results.Google’s Ask Photos launches: Google’s AI-powered search feature Ask Photos began rolling out to select Google Photos users in the U.S. late last week. Ask Photos allows you to ask complex queries like “Show the best photo from each of the National Parks I visited,” “What did we order last time at this restaurant?,” and “Where did we camp last August?”U.S. and EU sign AI treaty: At a summit this past week, the U.S., U.K., and EU signed up to a treaty on AI safety laid out by the Council of Europe (COE), an international standards and human rights organization. The COE describes the treaty as “the first-ever international legally binding treaty aimed at ensuring that the use of AI systems is fully consistent with human rights, democracy and the rule of law.”Research paper of the weekEvery biological process depends on interactions between proteins, which occur when proteins bind together. “Binder” proteins — proteins that bind to specific target molecules — have applications in drug development, disease diagnosis, and more.But creating binder proteins is often a laborious and costly undertaking — and comes with a risk of failure. In search of an AI-powered solution, Google’s AI lab DeepMind developed AlphaProteo, a model that predicts proteins to bind to target molecules. Given a few parameters, AlphaProteo can output a candidate protein that binds to a molecule at a specified binding site.In tests with seven target molecules, AlphaProteo generated protein binders with 3x to 300x better “binding affinity” (i.e., molecule-binding strength) than previous binder-finding methods managed to create. Moreover, AlphaProteo became the first model to successfully develop a binder for a protein associated with cancer and complications arising from diabetes (VEGF-A).DeepMind admits, however, that AlphaProteo failed on an eighth testing attempt — and that strong binding is usually only the first step in creating proteins that might be useful for practical applications.Model of the week There’s a new, highly capable generative AI model in town — and anyone can download, fine-tune, and run it.The Allen Institute for AI (AI2), together with startup Contextual AI, developed a text-generating English-language model called OLMoE, which has a 7-billion-parameter mixture-of-experts (MoE) architecture. (“Parameters” roughly correspond to a model’s problem-solving skills, and models with more parameters generally — but not always — perform better than those with fewer parameters.)MoEs break down data processing tasks into subtasks and then delegate them to smaller, specialized “expert” models. They aren’t new. But what makes OLMoE noteworthy — besides the fact that it’s openly licensed — is the fact that it outperforms many models in its class, including Meta’s Llama 2, Google’s Gemma 2, and Mistral’s Mistral 7B, on a range of applications and benchmarks.Several variants of OLMoE, along with the data and code used to create them, are available on GitHub.  Grab bagThis week was Apple week. The company held an event on Monday where it announced new iPhones, Apple Watch models, and apps. Here’s a rundown in case you weren’t able to tune in.Apple Intelligence, Apple’s suite of AI-powered services, predictably got airtime. Apple reaffirmed that ChatGPT would be integrated with the experience in several key ways. But curiously, there wasn’t any mention of AI partnerships beyond the previously announced OpenAI deal — despite Apple lightly telegraphing such partnerships earlier this summer.In June at WWDC 2024, SVP Craig Federighi confirmed Apple’s plans to work with additional third-party models, including Google’s Gemini, in the future. “Nothing to announce right now,” he said, “but that’s our general direction.” It’s been radio silence since.Perhaps the necessary paperwork is taking longer to hammer out than expected — or there’s been a technical setback. Or maybe Apple’s possible investment in OpenAI rubbed some model partners the wrong way. Whatever the case may be, it seems that ChatGPT will be the solo third-party model in Apple Intelligence for the foreseeable future. Sorry, Gemini fans.","AI, AI, newsletter, OpenAI, this week in AI, this week in ai newsletter",,,,24
"Google’s AI note-taking app NotebookLM can now explain complex topics to you out loud","Aisha Malik",2024-09-11,https://techcrunch.com/2024/09/11/googles-ai-note-taking-app-notebooklm-can-now-explain-complex-topics-to-you-out-loud/,"Google announced on Wednesday that its AI note-taking and research app, NotebookLM, is adding an “Audio Overview” feature. Audio Overview will give users another way to digest and comprehend the…","Google announced on Wednesday that its AI note-taking and research app, NotebookLM, is adding an “Audio Overview” feature. Audio Overview will give users another way to digest and comprehend the information in the documents they have uploaded to the app, such as course readings or legal briefs.Since its launch, NotebookLM has used text to summarize and explain source materials, but now, it can do so out loud using audio. The feature is geared toward people who grasp materials better by listening to explanations as opposed to reading them.AI-generated virtual hosts will use conversational speech patterns to give you a summary of the materials you have shared. The hosts will share facts or compelling topics from the source material and do things like use metaphors to explain complicated concepts. Google says that listening to these discussions will help users find new connections between their documents or get inspiration for their drafts.To get started with Audio Overview, you need to open an existing notebook, navigate to the Notebook guide, and click on the “generate” button on the right-hand side. It can take up to five minutes for an audio conversation to generate, and for now, you can only generate conversations in English.You also have the option to download the conversation and listen to it on the go to get a quick understanding of your source materials.Audio conversations are still in beta and there may be some inaccuracies in the conversations, Google says. The company first demoed NotebookLM under the name Project Tailwind back in June 2023 at Google I/O before making it available to everyone above the age of 18 in the U.S. last December. The app is now available in over 200 countries in more than 108 languages.","AI, Apps, Google, notebooklm",,,,25
"Meet Verse, an AI-powered creative app that helps Gen Z design and publish expressive content","Aisha Malik",2024-09-11,https://techcrunch.com/2024/09/11/meet-verse-an-ai-powered-creative-app-that-helps-gen-z-design-and-publish-expressive-content/,"Verse, a new AI-powered creative app, is aiming to help Gen Z users create hyper-visual and expressive content. The iOS app allows users to design and publish multimedia content on…","Verse, a new AI-powered creative app, is aiming to help Gen Z users create hyper-visual and expressive content. The iOS app allows users to design and publish multimedia content on an interactive canvas with the help of an AI assistant. You can create a mini website, called a Verse, for things like moodboards, greeting cards, invitations, storefronts, fan pages, blogs, and more. Verse also gives content creators and influencers a creative way to connect with their audience and share information via a link-in-bio format. Verse was founded by Bobby Pinckney, a former management consultant at PwC, and Michelle Yin, a former engineer at Meta. The duo met in college and previously founded a YC-backed music discovery app called Discz, which currently has more than 1.5 million users.Pinckney and Yin came up with the idea for Verse while they were working on Discz. They added a Profile feature for the app that users could drag and drop songs or images onto. Although the duo added the feature to allow users to express what kind of music they like, they saw that people were using it as a creative tool. “What we thought was going to be a way for people to express like, this is who I am and what music I like, turned out to be a tool of choice for users,” Pinckney told TechCrunch. “And this just blew our minds, because we didn’t expect it at all. We’re like, this is a music app, and we gave these users a Profile, but they’re literally using our platform to create media that they then share elsewhere.”Image Credits: VerseThe duo then decided to create Verse. The platform launched to the public on iOS in June, and users have created over 200,000 Verses since then. While current popular design and publishing platforms like Canva and Wix are static and somewhat template-based, Verse offers a scrollable, multimodal canvas. You can add all sorts of elements to your creation, such as photos, stickers, videos, links, GIFs, text, backgrounds, songs, and more. You can also link a Verse within another Verse. The platform’s AI assistant will guide you through the entire process, from designing to publishing. The assistant leverages LLMs from OpenAI, Anthropic, Meta’s Llama, and Mistral. “We’ve essentially taken all these super complex technologies, like publishing and design, and we’ve made it accessible directly from your mobile phone, and also made it incredibly easy to use,” Yin said. Once you’ve created your Verse, you can publish it and share it as a mini website across social media.“Self-expression is a very common use case,” Pinckney said. “Not everyone wants to be on camera and make a TikTok, right? And so, you have so many people who want to express themselves and communicate an interest or hobby or information but don’t want to be making TikToks, for example. And so this is a creative medium for them to express that.”Image Credits: VerseIn addition to being used by everyday users to express themselves, Verse is also a way for artists and companies to make immersive content for their brands.For example, British singer and songwriter Kenya Grace created a Verse to mark the launch of her EP. The Verse includes a link to her new single, a list of her tour dates and where to buy tickets, links to her social media, images of herself, and more. Plus, hard seltzer company Lunar has created a Verse that it has in its Instagram bio to market its different products and link out to where users can purchase them. While Verse is mainly a design platform, it also includes a social aspect. You can browse through Verses that other people have created based on different topics, such as Trending, Featured, Music, Lifestyle, Art, Film, Gaming, and more. If you come across a Verse you like, you can leave a comment.The app is free to use, but the company may explore a subscription model at some point in the future. In terms of the future, Verse plans to launch an Android app. The company also plans to launch a way for users to create Verses on the web, especially as it has been seeing demand from marketing teams that want to create experiences for their brands on the web.","AI, Apps, Apps, Startups",,,,26
"Adobe says video generation is coming to Firefly this year","Maxwell Zeff",2024-09-11,https://techcrunch.com/2024/09/11/adobe-says-video-generation-is-coming-to-firefly-this-year/,"Users will get their first chance to try Adobe’s AI model for video generation in just a couple months. The company says features powered by Adobe’s Firefly Video model will…","Users will get their first chance to try Adobe’s AI model for video generation in just a couple months. The company says features powered by Adobe’s Firefly Video model will become available before the end of 2024 on the Premiere Pro beta app and on a free website.Adobe says three features — Generative Extend, Text to Video, and Image to Video — are currently in a private beta, but will be public soon.Generative Extend, which lets you extend any input video by two seconds, will be embedded into the Premiere Pro beta app later this year. Firefly’s Text to Video and Image to Video models, which create five-second videos from prompts or input images, will be available on Firefly’s dedicated website later this year as well. (The time limit may increase, Adobe noted.)Prompt: Cinematic closeup and detailed portrait of a reindeer in a snowy forest at sunset. The lighting is cinematic and gorgeous and soft and sun-kissed, with golden backlight and dreamy bokeh and lens flaresAdobe’s software has been a favorite among creatives for decades, but generative AI tools like these may upend the very industry the company serves, for better or worse. Firefly is Adobe’s answer to the recent wave of generative AI models, including OpenAI’s Sora and Runway’s Gen-3 Alpha. The tools have captivated audiences, making clips in minutes that would have taken hours for a human to create. However, these early attempts at tools are generally considered too unpredictable to use in professional settings.But controllability is where Adobe thinks it can set itself apart. Adobe’s CTO of digital media, Ely Greenfield, tells TechCrunch there is a “huge appetite” for Firefly’s AI tools where they can complement or accelerate existing workflows.For instance, Greenfield says Firefly’s generative fill feature, added to Adobe Photoshop last year, is “one of the most frequently used features we’ve introduced in the past decade.” Adobe would not disclose the price of these AI video features. For other Firefly tools, Adobe allots Creative Cloud customers a certain number of “generative credits,” where one credit typically yields one generation result. More expensive plans, obviously, provide more credits.In a demo with TechCrunch, Greenfield showcased the Firefly-powered features coming later this year.Generative Extend can pick up where the original video stops, adding an extra two seconds of footage in a relatively seamless way. The feature takes the last few frames in a scene, running them through Firefly’s Video model to predict the next couple seconds. For the scene’s audio, Generative Extend will recreate background noise, such as traffic or the sounds of nature, but not people’s voices or music. Greenfield says that’s to comply with licensing requirements from the music industry.Generative Extend was used on this clip right around the :08 second mark, just after the lens flare.In one example, Greenfield showed a video clip of an astronaut looking out into space that had been modified with the feature. I was able to tell the moment it had been extended, just after an unusual lens flare appeared on screen, but the camera pan and objects in the scene stayed consistent. I could see it being useful when your scene ends a moment too soon, and you need to draw it out just a bit longer to transition or fade out.Firefly’s Text to Video and Image to Video feature are more familiar. They allow you to input a text or image prompt and get up to five seconds of video out. Users will be able to access these AI video generators on firefly.adobe.com, likely with rate limits (though Adobe did not specify).Adobe also says Firefly’s Text to Video features are quite good at spelling words correctly, something AI video models tend to struggle with.Prompt: Macro detailed shot of water splashing and freezing to spell the word ICEIn terms of safeguards, Adobe is erring on the side of caution to start out. Greenfield says Firefly’s video models have blocks around generating videos including nudity, drugs, and alcohol. Further, he added, Adobe’s video generation models are not trained on public figures, like politicians and celebrities. The same certainly can’t be said for some of the competition.","Adobe, Adobe Firefly, Adobe Premiere, AI, generative AI videos",,,,27
"Connectly, now backed by Alibaba, taps AI to personalize text messages to customers","Kyle Wiggers",2024-09-11,https://techcrunch.com/2024/09/11/alibaba-backed-connectly-taps-ai-to-personalize-customer-messages/,"Stefanos Loukakos, formerly a director at Meta’s business-focused Messenger division and, briefly, the tech giant’s blockchain org, noticed several years ago that online retailers were struggling to connect with potential shoppers. The…","Stefanos Loukakos, formerly a director at Meta’s business-focused Messenger division and, briefly, the tech giant’s blockchain org, noticed several years ago that online retailers were struggling to connect with potential shoppers. The problem, in his opinion, was that their marketing campaigns weren’t tailored enough. Merchants were sending generic social media, text, and email blasts that failed to resonate with buyers and convert.“Businesses need a solution to create winning messaging campaigns and automate conversations with both leads and customers,” Loukakos said. “Ideally, it can also tailor suggestions to ensure customers discover products they’ll love, and help companies gain a deeper understanding of their customers.”Things clicked when Loukakos met Yandong Liu, formerly the CTO of Strava and a former Yahoo researcher, through a mutual friend in the founder community. The pair quickly bonded over their shared interest in messaging-based marketing, and in 2020, they founded Connectly.ai, which leverages AI to help businesses, like retailers and enterprise e-commerce leaders, sell their products and services across any messaging platform. According to Loukakos, customers can “send and receive messages without having to host, manage, or take care of software updates.”Connectly’s platform integrates with a range of messaging apps and services — including WhatsApp, Instagram, SMS, and web-based chatbots — to let brands create ad campaigns and automate certain basic conversations with customers. AI, fine-tuned on a retailer’s product catalog and preferences and plugged into the brand’s online store, sends texts informing customers of things like price changes, stock availability, and offers.Connectly allows brands, in particular e-commerce retailers, to customize the types of text messages that their customers receive.Image Credits: Connectly.aiConnectly also attempts to figure out which products customers are most interested in and automatically build audience segments. This allows it to, for example, detect when a customer abandons a cart on a brand’s website and then follow up with a message containing a discount code or lower-cost shipping offer.I asked Loukakos about Connectly’s transparency and data privacy policies. He said that the company’s bots always identify themselves as such and that Connectly is “fully compliant” with GDPR, at least in the sense that users can opt out of receiving messages from brands at any time. But hold the phone — do people actually want to engage with companies via chatbots? Surveys suggest they don’t. One commissioned earlier this year by customer experience platform Callvu found that the majority of people would rather wait at least a minute to speak with a live agent than chat instantly with an AI.Of course, companies aren’t necessarily embracing AI to improve customer experiences first and foremost. Gartner predicts that contact center operators will target a combined $80 billion in labor cost savings by widely deploying AI over the next two years. One in 10 customer service agent interactions will be automated by 2026, Gartner estimates, as firms look to make do with less.A decent-sized chunk of brands view Connectly’s tech as a good investment. Loukakos said that Connectly has over 300 paying customers and expects revenue to grow 100% in 2024, after revenue grew 5x last year.Loukakos wouldn’t give me a firm number on revenue. But considering that Connectly’s revenue was $3.5 million last year, one can assume that it’s on track to reach $7 million by the end of this year.  In spite of stiff competition from startups and incumbents alike in the conversational e-commerce space (e.g. Attentive, Twilio, Infobip, Bird, Take Blip, and Yalo), VCs like what they see with Connectly. Chinese retail giant Alibaba led a $20 million Series B round in the company this week, bringing Connectly’s total raised to $37.2 million at around a $100 million valuation.Could Alibaba’s involvement portend some sort of strategic collaboration between the retailer and Connectly down the line? Loukakos wouldn’t say — but he did call the support “profoundly impactful to Connectly’s potential.”Said a spokesperson for Alibaba, “We look to partner with innovative companies that are paving the way in their industry. Connectly is doing just that with AI-powered conversational commerce.” Unusual Ventures, Volpe Capital, RX Ventures and Falabella Ventures also participated in Connectly’s Series B. Loukakos said that the funds will be used to expand Connectly’s platform and grow its San Francisco-based workforce from 65 employees to nearly 80 by the end of the year.","advertising, AI, brand, Commerce, Connectly, connectly.ai, eCommerce, Enterprise, Exclusive, Funding, Fundraising, Marketing, messaging, retailer, startup, Startups",,,,28
"Mistral releases Pixtral 12B, its first multimodal model","Kyle Wiggers",2024-09-11,https://techcrunch.com/2024/09/11/mistral-releases-pixtral-its-first-multimodal-model/,"French AI startup Mistral has released its first model that can process images as well as text.","French AI startup Mistral has released its first model that can process images as well as text.Called Pixtral 12B, the 12-billion-parameter model is about 24GB in size. Parameters roughly correspond to a model’s problem-solving skills, and models with more parameters generally perform better than those with fewer parameters.Built on one of Mistral’s text models, Nemo 12B, the new model can answer questions about an arbitrary number of images of an arbitrary size given either URLs or images encoded using base64, the binary-to-text encoding scheme. Similar to other multimodal models such as Anthropic’s Claude family and OpenAI’s GPT-4o, Pixtral 12B should — at least in theory — be able to perform tasks like captioning images and counting the number of objects in a photo.Available via a torrent link on GitHub and AI and machine learning development platform Hugging Face, Pixtral 12B can be downloaded, fine-tuned and used under an Apache 2.0 license without restrictions. (A Mistral spokesperson confirmed the license being applied to Pixtral 12B via email.)This writer wasn’t able to take Pixtral 12B for a spin, unfortunately — there weren’t any working web demos at the time of publication. In a post on X, Sophia Yang, head of Mistral developer relations, said Pixtral 12B will be available for testing on Mistral’s chatbot and API-serving platforms, Le Chat and Le Plateforme, soon.It’s unclear which image data Mistral might have used to develop Pixtral 12B.Most generative AI models, including Mistral’s other models, are trained on vast quantities of public data from around the web, which is often copyrighted. Some model vendors argue that “fair use” rights entitle them to scrape any public data, but many copyright holders disagree, and have filed lawsuits against larger vendors like OpenAI and Midjourney to put a stop to the practice.Pixtral 12B comes in the wake of Mistral closing a $645 million funding round led by General Catalyst that valued the company at $6 billion. Just over a year old, Mistral — minority owned by Microsoft — is seen by many in the AI community as Europe’s answer to OpenAI. The younger company’s strategy thus far has involved releasing free “open” models, charging for managed versions of those models, and providing consulting services to corporate customers.Updated 9/11 at 8:11 a.m. Pacific: Clarified that Pixtral 12B is being made available under an Apache 2.0 license, not Mistral’s standard dev license that carries with it certain restrictions on commercial usage.","AI, AI, Generative AI, mistral, multimodal, open, Pixtral, Pixtral 12B",,,,29
"Sergey Brin says he’s working on AI at Google ‘pretty much every day’","Kyle Wiggers",2024-09-10,https://techcrunch.com/2024/09/10/sergey-brin-says-hes-working-at-google-pretty-much-every-day-on-ai/,"Google co-founder and ex-Alphabet president Sergey Brin said he’s back working at Google “pretty much every day” because he hasn’t seen anything as exciting as the recent progress in AI…","Google co-founder and ex-Alphabet president Sergey Brin said he’s back working at Google “pretty much every day” because he hasn’t seen anything as exciting as the recent progress in AI — and doesn’t want to miss out.Brin revealed the tidbit in an interview during the All-In Summit in L.A. this week. Last year, several publications reported that Brin was back at Google HQ working on various AI projects, but the sit-down is the first time Brin has publicly commented on his return.“It’s a big, fast-moving field,” Brin said of AI, adding that there is “tremendous value to humanity,” before explaining why he doesn’t think training more capable AI will require massively scaling up compute.“I’ve read some articles that extrapolate [compute] … and I don’t know if I’m quite a believer,” he said, “partly because the algorithmic improvements that have come over the last few years maybe are actually even outpacing the increased compute that’s being put into these models.”","AI, AI, Alphabet, Google, In Brief, interview, Sergey Brin",,,,30
"Senate leaders ask FTC to investigate AI content summaries as anti-competitive","Devin Coldewey",2024-09-10,https://techcrunch.com/2024/09/10/senate-leaders-ask-ftc-to-investigate-ai-content-summaries-as-anti-competitive/,"A group of Democratic senators is urging the FTC and Justice Department to investigate whether AI tools that summarize and regurgitate online content like news and recipes may amount to…","A group of Democratic senators is urging the FTC and Justice Department to investigate whether AI tools that summarize and regurgitate online content like news and recipes may amount to anticompetitive practices.In a letter to the agencies, the senators, led by Amy Klobuchar (D-MN), explained their position that the latest AI features are hitting creators and publishers while they’re down.As journalistic outlets experience unprecedented consolidation and layoffs, “dominant online platforms, such as Google and Meta, generate billions of dollars per year in advertising revenue from news and other original content created by others. New generative AI features threaten to exacerbate these problems.”The letter continues:While a traditional search result or news feed links may lead users to the publisher’s website, an AI-generated summary keeps the users on the original search platform, where that platform alone can profit from the user’s attention through advertising and data collection. […] Moreover, some generative AI features misappropriate third-party content and pass it off as novel content generated by the platform’s AI.Publishers who wish to avoid having their content summarized in the form of AI-generated search results can only do so if they opt out of being indexed for search completely, which would result in a materially significant drop in referral traffic. In short, these tools may pit content creators against themselves without any recourse to profit from AI-generated content that was composed using their original content. This raises significant competitive concerns in the online marketplace for content and advertising revenues.Essentially, the senators are saying that a handful of major companies control the market for monetizing original content via advertising, and that those companies are rigging that market in their favor. Either you consent to having your articles, recipes, stories, and podcast transcripts indexed and used as raw material for an AI, or you’re cut out of the loop.The letter goes on to ask the FTC and DOJ to investigate whether these new methods are “a form of exclusionary conduct or an unfair method of competition in violation of the antitrust laws.”Though it’s clearly a serious issue — and one that affects this outlet — the FTC may have its work cut out for it here. While AI summaries of web content may provide highly lopsided benefits, there are many power relationships in play in business and media, and the bar for anticompetitive behavior is quite high.For instance, in this case, it would have to be shown that the AI makers have overwhelming market power and that they are using that power in ways specifically forbidden by law. Something can be unfair, unethical, and perfectly legal.Considering how hawkish the FTC is on these matters already, however, it’s likely that Sen. Klobuchar and her colleagues are preaching to the choir as a prelude to taking action of their own. Klobuchar herself, watching out for journalism and local papers especially, introduced a bill last year aimed to empowering the supply side of news licensing negotiations and giving news outlets a bit more clout when asking Google or whoever to pay for their content.Fast-forward a year and the concerns of 2022 and early 2023 look quaint: The same companies accused of strong-arming content providers are now, many argue, circumventing the whole market by feeding the content to the AI for summaries.Asking the regulators to take a swing at an industry’s undesirable behaviors is part of a paper trail that legislators leave when trying to make a law. If the FTC and DOJ find they can’t act, it clears the signatories of this letter to propose a new law so that those agencies can act. While last year’s save-the-papers bill didn’t go far, a new one tied to fears about AI overlords might do better — certainly it’s a good talking point for the election cycle.The letter was co-signed by Senators Richard Blumenthal (D-CT), Mazie Hirono (D-HI), Dick Durbin (D-IL), Sheldon Whitehouse (D-RI), Tammy Duckworth (D-IL), Elizabeth Warren (D-MA), and Tina Smith (D-MN).","AI, FTC, Government & Policy",,,,31
"The real power of Apple Intelligence will show up in third-party apps","Sarah Perez",2024-09-10,https://techcrunch.com/2024/09/10/the-real-power-of-apple-intelligence-will-show-up-in-third-party-apps/,"Apple Intelligence, the iPhone maker’s new set of AI capabilities arriving in iOS 18, is laying the groundwork for a new way to use apps. Today, the dated App Store…","Apple Intelligence, the iPhone maker’s new set of AI capabilities arriving in iOS 18, is laying the groundwork for a new way to use apps. Today, the dated App Store model is under constant regulatory attack. Meanwhile, users can accomplish a lot of tasks with fairly simple questions to an AI assistant like ChatGPT. Proponents believe AI could become the preferred way we’ll search for answers, be productive at work, and experiment with creativity. Where does that leave the world of apps, and the growing services revenue (more than $6 billion last quarter) they generate for Apple? The answer cuts to the core of Apple’s AI strategy.Apple Intelligence itself only offers a small set of capabilities out-of-the-box, like writing helpers, summarization tools, generative art, and other baseline offerings. But earlier this year at its Worldwide Developers Conference (WWDC) in June, Apple presented new features that will allow developers’ apps to connect more deeply with both Siri and Apple Intelligence.Improvements to the smart assistant will allow Siri to invoke any item from an app’s menu without additional work on a developer’s part. That means users could ask Siri to “show me my presenter notes” in a slide deck, for instance, and Siri would know what to do. Siri will also be able to access any text displayed on the page, allowing users to reference and act on what’s on their screen.So, if you were looking at your reminder to wish a family member a “happy birthday,” you could say something like “FaceTime him” and Siri would know what action to take.Image Credits: AppleThat’s already an upgrade from the basic functionality today’s Siri offers, but it doesn’t end there. Apple is also providing developers with tools to use Apple Intelligence in their own apps. At WWDC, the company indicated that Apple Intelligence would first be made available to certain categories of apps, including Books, Browsers, Cameras, Document readers, File management, Journals, Mail, Photos, Presentations, Spreadsheets, Whiteboards, and Word processors. Over time, Apple is likely to open up these capabilities to all developers across the App Store.The AI functionality will be built on top of the App Intents framework, which is being expanded with new intents for developers. The eventual goal is to allow users to interact with Siri not just to open their apps, but also to use them.That means a user wouldn’t have to dig around in an app’s menus to find the feature they needed to perform a task. They could just ask Siri. Users could also make these requests while speaking naturally — conversationally — and could reference things that related to their personal context. So, for instance, you could ask a photo-editing app like Darkroom to “apply a cinematic present to the photo I took of Ian yesterday.” Today’s version of Siri would balk at this sort of request, but the AI-powered Siri would instead know to leverage the app’s Apply Filter intent, as well as which photo you’re asking to use it on.Siri will be able to take action even if you stumbled over your words or referenced an earlier part of the conversation in your instructions, Apple has said.You could also take action across apps. For example, after editing your photo, you could ask Siri to move it into another app, like Notes, without having to tap on anything.Image Credits: AppleIn addition, the iPhone’s search feature, Spotlight, will be able to search data from apps by incorporating app entities into its index. This refers to Apple Intelligence’s understanding of things like photos, messages, files, calendar events, and more.This subtler use case for AI, of course, requires developer adoption. Apple has over the years alienated some of its larger developers and even some of its indies with its revenue-sharing rules, which generally allow the company to keep 30% of revenues for products and services sold through any app. But developers could be drawn back in as Siri takes apps that were previously hidden in a back-of-the-phone App Library and makes them easily accessible through voice commands.Instead of boring onboarding screens to train users on how to navigate and use their app, developers could instead focus on making sure Siri understands how their app works, and how users might ask for the things they want to do in it. That way, users could engage with the app via Siri either by speaking or typing in commands, similar to how they today engage with an AI chatbot like ChatGPT.Third-party developers will gain other benefits from Apple’s new AI architecture, too.ScreenshotImage Credits: AppleWith its OpenAI partnership, Siri will be able to hand off queries to ChatGPT when it doesn’t have the answer. With its visual search feature on the iPhone 16 lineup, Apple will also allow users to access OpenAI’s chatbot or Google Search just by tapping on the new Camera Control button on the side, turning what they’re seeing through the camera’s viewfinder into an actionable query.These developments won’t feel as immediately revolutionary as the introduction of something like ChatGPT did because the rate of developer adoption will likely vary. Moreover, these future promises seem like they’re still a ways out. In the latest iOS 18 betas, the functionality feels incomplete. As often as I was surprised by what the new Siri can do, I was just as often confused by those things it can’t. That includes within Apple’s own apps. For instance, you can ask Siri in the Photos app to send a photo you’re viewing to someone, but you can’t ask it to do something more complex, like turn the photo into a sticker. Until Siri stops hitting these kinds of roadblocks, the functionality may end up feeling frustrating to use.","AI, Apps",,,,32
"Google Gemini: Everything you need to know about the generative AI models","Kyle Wiggers",2024-09-10,https://techcrunch.com/2024/09/10/what-is-google-gemini-ai/,"Gemini is Google’s long-promised, next-gen generative AI model family.","Google’s trying to make waves with Gemini, its flagship suite of generative AI models, apps, and services. But what’s Gemini? How can you use it? And how does it stack up to other generative AI tools such as OpenAI’s ChatGPT, Meta’s Llama, and Microsoft’s Copilot?To make it easier to keep up with the latest Gemini developments, we’ve put together this handy guide, which we’ll keep updated as new Gemini models, features, and news about Google’s plans for Gemini are released.What is Gemini?Gemini is Google’s long-promised, next-gen generative AI model family. Developed by Google’s AI research labs DeepMind and Google Research, it comes in four flavors:Gemini UltraGemini ProGemini Flash, a speedier, “distilled” version of ProGemini Nano, two small models: Nano-1 and the slightly more capable Nano-2, which is meant to run offlineAll Gemini models were trained to be natively multimodal — that is, able to work with and analyze more than just text. Google says they were pre-trained and fine-tuned on a variety of public, proprietary, and licensed audio, images, and videos; a set of codebases; and text in different languages.This sets Gemini apart from models such as Google’s own LaMDA, which was trained exclusively on text data. LaMDA can’t understand or generate anything beyond text (e.g., essays, emails, and so on), but that isn’t necessarily the case with Gemini models.We’ll note here that the ethics and legality of training models on public data, in some cases without the data owners’ knowledge or consent, are murky. Google has an AI indemnification policy to shield certain Google Cloud customers from lawsuits should they face them, but this policy contains carve-outs. Proceed with caution — particularly if you’re intending on using Gemini commercially.What’s the difference between the Gemini apps and Gemini models?Gemini is separate and distinct from the Gemini apps on the web and mobile (formerly Bard).The Gemini apps are clients that connect to various Gemini models and layer a chatbot-like interface on top. Think of them as front ends for Google’s generative AI, analogous to ChatGPT and Anthropic’s Claude family of apps.Image Credits: GoogleGemini on the web lives here. On Android, the Gemini app replaces the existing Google Assistant app. And on iOS, the Google and Google Search apps serve as that platform’s Gemini clients.On Android, it also recently became possible to bring up the Gemini overlay on top of any app to ask questions about what’s on the screen (e.g., a YouTube video). Just press and hold a supported smartphone’s power button or say, “Hey Google”; you’ll see the overlay pop up. Gemini apps can accept images as well as voice commands and text — including files like PDFs and soon videos, either uploaded or imported from Google Drive — and generate images. As you’d expect, conversations with Gemini apps on mobile carry over to Gemini on the web and vice versa if you’re signed in to the same Google Account in both places.Gemini AdvancedThe Gemini apps aren’t the only means of recruiting Gemini models’ assistance with tasks. Slowly but surely, Gemini-imbued features are making their way into staple Google apps and services like Gmail and Google Docs.To take advantage of most of these, you’ll need the Google One AI Premium Plan. Technically a part of Google One, the AI Premium Plan costs $20 and provides access to Gemini in Google Workspace apps like Docs, Slides, Sheets, and Meet. It also enables what Google calls Gemini Advanced, which brings the company’s more sophisticated Gemini models to the Gemini apps.Gemini Advanced users get extras here and there, too, like priority access to new features, the ability to run and edit Python code directly in Gemini, and a larger “context window.” Gemini Advanced can remember the content of — and reason across — roughly 750,000 words in a conversation (or 1,500 pages of documents). That’s compared to the 24,000 words (or 48 pages) the vanilla Gemini app can handle.Image Credits: GoogleAnother Gemini Advanced exclusive is trip planning in Google Search, which creates custom travel itineraries from prompts. Taking into account things like flight times (from emails in a user’s Gmail inbox), meal preferences, and information about local attractions (from Google Search and Maps data), as well as the distances between those attractions, Gemini will generate an itinerary that updates automatically to reflect any changes. Gemini across Google services is also available to corporate customers through two plans, Gemini Business (an add-on for Google Workspace) and Gemini Enterprise. Gemini Business costs as low as $20 per user per month, and Gemini Enterprise — which adds meeting note-taking and translated captions as well as document classification and labeling — is priced at $30 and up per user per month. (Both plans require an annual commitment.)Gemini in Gmail, Docs, Chrome, dev tools, and moreIn Gmail, Gemini lives in a side panel that can write emails and summarize message threads. You’ll find the same panel in Docs, where it helps you write and refine your content and brainstorm new ideas. Gemini in Slides generates slides and custom images. And Gemini in Google Sheets tracks and organizes data, creating tables and formulas.Gemini’s reach extends to Drive as well, where it can summarize files and give quick facts about a project. In Meet, meanwhile, Gemini translates captions into additional languages.Image Credits: GoogleGemini recently came to Google’s Chrome browser in the form of an AI writing tool. You can use it to write something completely new or rewrite existing text; Google says it’ll consider the web page you’re on to make recommendations.Elsewhere, you’ll find hints of Gemini in Google’s database products, cloud security tools, and app development platforms (including Firebase and Project IDX), as well as in apps like Google Photos (where Gemini handles natural language search queries), YouTube (where it helps brainstorm video ideas), and the NotebookLM note-taking assistant.Code Assist (formerly Duet AI for Developers), Google’s suite of AI-powered assistance tools for code completion and generation, is offloading heavy computational lifting to Gemini. So are Google’s security products underpinned by Gemini, like Gemini in Threat Intelligence, which can analyze large portions of potentially malicious code and let users perform natural language searches for ongoing threats or indicators of compromise.Gemini extensions and GemsAnnounced at Google I/O 2024, Gemini Advanced users can create Gems, custom chatbots powered by Gemini models. Gems can be generated from natural language descriptions — for example, “You’re my running coach. Give me a daily running plan” — and shared with others or kept private.Gems are available on desktop and mobile in 150 countries and most languages. Eventually, they’ll be able to tap an expanded set of integrations with Google services, including Google Calendar, Tasks, Keep, and YouTube Music, to complete custom tasks.Image Credits: GoogleSpeaking of integrations, the Gemini apps on the web and mobile can tap into Google services via what Google calls “Gemini extensions.” Gemini today integrates with Google Drive, Gmail, and YouTube to respond to queries such as “Could you summarize my last three emails?” Later this year, Gemini will be able to take additional actions with Google Calendar, Keep, Tasks, YouTube Music and Utilities, the Android-exclusive apps that control on-device features like timers and alarms, media controls, the flashlight, volume, Wi-Fi, Bluetooth, and so on.Gemini Live in-depth voice chatsA new experience called Gemini Live, exclusive to Gemini Advanced subscribers, allows users to have “in-depth” voice chats with Gemini. It’s available in the Gemini apps on mobile and the Pixel Buds Pro 2, where it can be accessed even when your phone’s locked.With Gemini Live enabled, you can interrupt Gemini while the chatbot’s speaking (in one of several new voices) to ask a clarifying question, and it’ll adapt to your speech patterns in real time. And sometime later this year, Gemini will be able to see and respond to your surroundings, either via photos or video captured by your smartphones’ cameras.Image Credits: GoogleLive is also designed to serve as a virtual coach of sorts, helping you rehearse for events, brainstorm ideas, and so on. For instance, Live can suggest which skills to highlight in an upcoming job or internship interview, and it can give public speaking advice.You can read our review of Gemini Live here. Spoiler alert: We think the feature has a ways to go before it’s super useful — but it’s early days, admittedly.Image generation via Imagen 3Gemini users can generate artwork and images using Google’s built-in Imagen 3 model. Google says that Imagen 3 can more accurately understand the text prompts that it translates into images versus its predecessor, Imagen 2, and is more “creative and detailed” in its generations. In addition, the model produces fewer artifacts and visual errors (at least according to Google), and is the best Imagen model yet for rendering text.A sample from Imagen 3.Image Credits: GoogleBack in February, Google was forced to pause Gemini’s ability to generate images of people after users complained of historical inaccuracies. But in August, the company reintroduced people generation for certain users, specifically English-language users signed up for one of Google’s paid Gemini plans (e.g., Gemini Advanced) as part of a pilot program.Gemini for teensIn June, Google introduced a teen-focused Gemini experience, allowing students to sign up via their Google Workspace for Education school accounts.The teen-focused Gemini has “additional policies and safeguards,” including a tailored onboarding process and an “AI literacy guide” to (as Google phrases it) “help teens use AI responsibly.” Otherwise, it’s nearly identical to the standard Gemini experience, down to the “double check” feature that looks across the web to see if Gemini’s responses are accurate.Gemini in smart home devicesA growing number of Google-made devices tap Gemini for enhanced functionality, from the Google TV Streamer to the Pixel 9 and 9 Pro to the newest Nest Learning Thermostat.On the Google TV Streamer, Gemini uses your preferences to curate content suggestions across your subscriptions and summarize reviews and even whole seasons of TV.Image Credits: GoogleOn the latest Nest thermostat (as well as Nest speakers, cameras, and smart displays), Gemini will soon bolster Google Assistant’s conversational and analytic capabilities.Subscribers to Google’s Nest Aware plan later this year will get a preview of new Gemini-powered experiences like AI descriptions for Nest camera footage, natural language video search and recommended automations. Nest cameras will understand what’s happening in real-time video feeds (e.g., when a dog’s digging in the garden), while the companion Google Home app will surface videos and create device automations given a description (e.g., “Did the kids leave their bikes in the driveway?,” “Have my Nest thermostat turn on the heating when I get home from work every Tuesday”).Gemini will soon be able to summarize security camera footage from Nest devices.Image Credits: GoogleAlso later this year, Google Assistant will get a few upgrades on Nest-branded and other smart home devices to make conversations feel more natural. Improved voices are on the way, in addition to the ability to ask follow-up questions and “[more] easily go back and forth.”What can the Gemini models do?Because Gemini models are multimodal, they can perform a range of multimodal tasks, from transcribing speech to captioning images and videos in real time. Many of these capabilities have reached the product stage (as alluded to in the previous section), and Google is promising much more in the not-too-distant future.Of course, it’s a bit hard to take the company at its word. Google seriously underdelivered with the original Bard launch. More recently, it ruffled feathers with a video purporting to show Gemini’s capabilities that was more or less aspirational — not live.Also, Google offers no fix for some of the underlying problems with generative AI tech today, like its encoded biases and tendency to make things up (i.e., hallucinate). Neither do its rivals, but it’s something to keep in mind when considering using or paying for Gemini.Assuming for the purposes of this article that Google is being truthful with its recent claims, here’s what the different tiers of Gemini can do now and what they’ll be able to do once they reach their full potential:What you can do with Gemini UltraGoogle says that Gemini Ultra — thanks to its multimodality — can be used to help with things like physics homework, solving problems step-by-step on a worksheet, and pointing out possible mistakes in already filled-in answers.Ultra can also be applied to tasks such as identifying scientific papers relevant to a problem, Google says. The model can extract information from several papers, for instance, and update a chart from one by generating the formulas necessary to re-create the chart with more timely data.Gemini Ultra technically supports image generation. But that capability hasn’t made its way into the productized version of the model yet — perhaps because the mechanism is more complex than how apps such as ChatGPT generate images. Rather than feed prompts to an image generator (like DALL-E 3, in ChatGPT’s case), Gemini outputs images “natively,” without an intermediary step.Ultra is available as an API through Vertex AI, Google’s fully managed AI dev platform, and AI Studio, Google’s web-based tool for app and platform developers.Gemini Pro’s capabilitiesGoogle says that Gemini Pro is an improvement over LaMDA in its reasoning, planning, and understanding capabilities. The latest version, Gemini 1.5 Pro — which powers the Gemini apps for Gemini Advanced subscribers — exceeds even Ultra’s performance in some areas.Gemini 1.5 Pro is improved in a number of areas compared with its predecessor, Gemini 1.0 Pro, perhaps most obviously in the amount of data that it can process. Gemini 1.5 Pro can take in up to 1.4 million words, two hours of video, or 22 hours of audio and can reason across or answer questions about that data (more or less).Gemini 1.5 Pro became generally available on Vertex AI and AI Studio in June alongside a feature called code execution, which aims to reduce bugs in code that the model generates by iteratively refining that code over several steps. (Code execution also supports Gemini Flash.)Within Vertex AI, developers can customize Gemini Pro to specific contexts and use cases via a fine-tuning or “grounding” process. For example, Pro (along with other Gemini models) can be instructed to use data from third-party providers like Moody’s, Thomson Reuters, ZoomInfo and MSCI, or source information from corporate datasets or Google Search instead of its wider knowledge bank. Gemini Pro can also be connected to external, third-party APIs to perform particular actions, like automating a back-office workflow.AI Studio offers templates for creating structured chat prompts with Pro. Developers can control the model’s creative range and provide examples to give tone and style instructions — and also tune Pro’s safety settings.Vertex AI Agent Builder lets people build Gemini-powered “agents” within Vertex AI. For example, a company could create an agent that analyzes previous marketing campaigns to understand a brand style and then apply that knowledge to help generate new ideas consistent with the style. Gemini Flash is for less demanding workFor less demanding applications, there’s Gemini Flash. The newest version is 1.5 Flash; Gemini app users not subscribed to Gemini Advanced get access to this. An offshoot of Gemini Pro that’s small and efficient, built for narrow, high-frequency generative AI workloads, Flash is multimodal like Gemini Pro, meaning it can analyze audio, video, images, and text (but it can only generate text). Google says that Flash is particularly well-suited for tasks like summarization and chat apps, plus image and video captioning and data extraction from long documents and tables.Devs using Flash and Pro can optionally leverage context caching, which lets them store large amounts of information (e.g., a knowledge base or database of research papers) in a cache that Gemini models can quickly and relatively cheaply access. Context caching is an additional fee on top of other Gemini model usage fees, however.Gemini Nano can run on your phoneGemini Nano is a much smaller version of the Gemini Pro and Ultra models, and it’s efficient enough to run directly on (some) devices instead of sending the task to a server somewhere. So far, Nano powers a couple of features on the Pixel 8 Pro, Pixel 8, Pixel 9 Pro, Pixel 9 and Samsung Galaxy S24, including Summarize in Recorder and Smart Reply in Gboard.The Recorder app, which lets users push a button to record and transcribe audio, includes a Gemini-powered summary of recorded conversations, interviews, presentations, and other audio snippets. Users get summaries even if they don’t have a signal or Wi-Fi connection — and in a nod to privacy, no data leaves their phone in process.Image Credits: GoogleNano is also in Gboard, Google’s keyboard replacement. There, it powers a feature called Smart Reply, which helps to suggest the next thing you’ll want to say when having a conversation in a messaging app such as WhatsApp.In the Google Messages app on supported devices, Nano drives Magic Compose, which can craft messages in styles like “excited,” “formal,” and “lyrical.”Google says that a future version of Android will tap Nano to alert users to potential scams during calls. The new weather app on Pixel phones uses Gemini Nano to generate tailored weather reports. And TalkBack, Google’s accessibility service, employs Nano to create aural descriptions of objects for low-vision and blind users.How much do the Gemini models cost?Gemini 1.0 Pro (the first version of Gemini Pro), 1.5 Pro, and Flash are available through Google’s Gemini API for building apps and services — all with free options. But the free options impose usage limits and leave out certain features, like context caching and batching.Gemini models are otherwise pay-as-you-go. Here’s the base pricing — not including add-ons like context caching — as of September 2024:Gemini 1.0 Pro: 50 cents per 1 million input tokens, $1.50 per 1 million output tokensGemini 1.5 Pro: $3.50 per 1 million input tokens (for prompts up to 128K tokens) or $7 per 1 million input tokens (for prompts longer than 128K tokens); $10.50 per 1 million output tokens (for prompts up to 128K tokens) or $21.00 per 1 million output tokens (for prompts longer than 128K tokens)Gemini 1.5 Flash: 7.5 cents per 1 million input tokens (for prompts up to 128K tokens), 15 cents per 1 million input tokens (for prompts longer than 128K tokens), 30 cents per 1 million output tokens (for prompts up to 128K tokens), 60 cents per 1 million output tokens (for prompts longer than 128K tokens)Tokens are subdivided bits of raw data, like the syllables “fan,” “tas,” and “tic” in the word “fantastic”; 1 million tokens is equivalent to about 700,000 words. Input refers to tokens fed into the model, while output refers to tokens that the model generates.Ultra pricing has yet to be announced, and Nano is still in early access.Is Gemini coming to the iPhone?It might. Apple has said that it’s in talks to put Gemini and other third-party models to use for a number of features in its Apple Intelligence suite. Following a keynote presentation at WWDC 2024, Apple SVP Craig Federighi confirmed plans to work with models, including Gemini, but he didn’t divulge any additional details.This post was originally published February 16, 2024, and has since been updated to include new information about Gemini and Google’s plans for it.","AI, Apps, Enterprise, evergreens, gemini, Gemini Pro, Generative AI, Google, google gemini",,,,33
"iPhone 16, Apple Intelligence, AirPods 4 and more: Everything revealed at Apple Event 2024","Morgan Little",2024-09-10,https://techcrunch.com/2024/09/10/iphone-16-apple-intelligence-airpods-4-and-more-live-updates-on-everything-revealed-at-apple-event-2024/,"Apple’s lineup of announcements echoed many of the anticipated hardware reveals, including the new iPhone 16, AirPods 4, the Apple Watch Series 10 and more.","Apple’s biggest event of the year has arrived, and with it, the iPhone 16 lineup and a slew of AI-related updates for iOS 18. Apple Intelligence was the star of the Apple event this year, like it was at WWDC in June, and Apple’s lineup of announcements echoed many of the anticipated hardware reveals, including the new iPhone 16, AirPods 4, the Apple Watch Series 10 and more. Broadcasting live from its headquarters in Cupertino, Apple’s “Glowtime” event kicked off at 10 a.m. PT, and you can watch the recording of the full Apple event here. Whether Monday’s reveals end up inspiring or delaying a “supercycle” of customers adopting the new iPhone 16 lineup remains to be seen, but Apple’s focus on AI as a core part of its sales pitch moving forward is clear. We’ll keep this post updated as reports emerge from the demo rooms and briefings following the event.iPhone 16Image Credits: AppleAs no surprise, the iPhone 16 “has been designed for Apple Intelligence from the ground up,” in the words of CEO Tim Cook, and the tweaked designs and new colors were revealed at the Apple event. The new iPhone 16 lineup comes with a camera control along the side, which allows for physical interactions to access camera features, along with the new A18 chip that Apple claims makes the iPhone 16 up to 30% faster than the iPhone 15. The iPhone 16 starts at $799 for the 128GB model, with the 16 Plus starting at $899 with the same amount of storage. Catch up on our ongoing iPhone 16 updates here.And for a rundown on what distinguishes the new iPhone 16 lineup, you can head right here, or check out the latest TechCrunch Minute episode breaking down the biggest reveals.Hands-on with the iPhone 16’s camera buttonImage Credits: Brian HeaterIn the words of our editor Brian Heater, Apple is “feeling a lot more bullish about buttons these days.” And after the Apple event broadcast concluded, he got the chance to see that the Camera Control button actually adds to the iPhone experience, at least for a brief demo.“Like any other new feature, Camera Control takes a bit to master. The trickiest part is determining how much pressure to apply in order to toggle between features. That, however, is what makes it unique versus earlier camera buttons. It’s more than just a way to open the camera app and take a shot. It also lets you navigate within the app itself,” he wrote, and you can check out his full hands-on with the iPhone 16’s biggest physical change right here.The Camera Control button has some other functions, with Apple confirming that it can be used to access Google searches, and to prompt responses from OpenAI’s ChatGPT, which is already being added to apps like Siri. The exact details on how the button press will determine whether you use a third party app or Apple’s software remain vague.Apple IntelligenceImage Credits: AppleFirst revealed at WWDC, Apple Intelligence is mostly being presented as a more private large language model operating behind the scenes to improve existing apps and features. Retreading many of its WWDC reveals, Apple touted Intelligence’s ability to survey inboxes, with summaries surfacing for emails, and notifications altered to provide summaries as well with priority notifications elevated to the top of their stacks. Claiming “a new era for Siri,” Apple boasted that its Intelligence upgrades allow Siri to understand requests that are less than eloquently delivered, walk users through specific tasks within the iPhone and gain on-screen awareness of actions taking place on the phone. Apple Intelligence is launching as a beta in the U.S. in the fall, with localized English coming to several markets in December. Additional languages like Chinese, French, Japanese and Spanish are targeted for 2025.Apple also detailed visual search, which is powered by Apple Intelligence, which combines the functions of a reverse image search with text recognition to add the details of an event to your calendar from a photo, or pull information about a restaurant directly from a photo of it. Apple’s claims about Intelligence’s potential to improve user experiences across multiple product lines have prompted two key questions, one being: Is Siri actually useful now? And the second being: Is that it? When you run through the actual use cases demonstrated by Apple during the event, it’s a lot that already exists from writing assistance tools, competing LLMs and existing voice assistants. iOS 18 launching September 16Image Credits: AppleWe already got a first impression of iOS 18 through its beta release earlier this year, though its initial rollout without Apple Intelligence’s features wasn’t particularly impressive. As mentioned above, a lot of the most anticipated AI features will be coming later in 2024, but iOS 18 still has other messaging and control center updates you can run through in detail here ahead of its newly announced launch date of September 16, with all iPhones, including and after the iPhone XR and SE (second gen), eligible for the update. You can get a more detailed rundown on your device’s iOS 18 compatibility here.Camera controls on the iPhone 16Image Credits: AppleOne of the biggest physical updates to the iPhone 16 lineup comes in the form of the camera control button. The camera control responds to clicks and different physical gestures, with light presses showing clean previews while a hard click can take a photo. Trailing a finger along the button lets dials and settings to be changed. Read the full rundown on what the camera control can be used for here.iPhone 16 Pro, Pro MaxImage Credits: AppleApple’s more premium iPhone models come with expected screen changes, with the screen taking up 6.3 inches on the Pro, 6.9 inches on the Pro Max for the biggest screens on an iPhone yet. The iPhone 16 Pro and Pro Max have a new A18 Pro chip, an upgraded camera with faster shutter speeds, the ability to capture 4K video at 120 fps and other changes you can run through here. The iPhone 16 Pro stars at $999 and the 16 Pro Max starts at $1,119 with both up for preorder Friday and launching in stores September 20.Apple Watch Series 10Image Credits: AppleApple kicked things off with reveals on the Watch for the line’s 10th anniversary, rolling out a series of updates within the Apple Watch Series 10 line, including a tweaked design with more rounded corners and an updated aspect ratio, with Apple’s first wide-angle OLED screens. The Series 10’s display is up to 40% brighter when viewed at an angle and is the thinnest Apple Watch yet at 9.7mm and up to 10% lighter than the previous models. Unsurprisingly, AI featured in the Apple Watch Series 10 reveal, with a new photos watch face using AI to curate the photos shown on the display, and translation tools using machine learning to improve output.Apple Watches are also getting an update to detect sleep apnea, which received FDA clearance for the Series 10 and Series 9. The Apple Watch Series 10 will start at $399, and it launches September 20.Read more on the Apple Watch Series 10 here.Apple Watch UltraImage Credits: AppleApple has long touted the Ultra as a device for fitness aficionados, boasting custom workouts, running track detection, bike rides as live activities and so on. And after a lead-up to a reveal, Apple dropped that there won’t be an Apple Watch Ultra 3 yet, instead announcing a new satin black color for the Ultra 2.AirPods 4Image Credits: AppleApple claims the new AirPods 4 are the “most comfortable AirPods ever,” with a new A2 chip under the tweaked design. Personalized Spatial Audio is coming to the AirPods 4, along with the addition of machine learning for Siri to pick up head shakes and nods as responses to prompts. The new AirPods 4 will also be available September 20, starting at $129 with active noise cancellation added for the $179 tier. Get the full rundown on the AirPods updates here.AirPods Pro 2Image Credits: AppleThree points were highlighted for AirPods Pro 2 updates: prevention, awareness and assistance. For prevention, hearing protection will be added and on by default for passive noise reduction, managed through machine learning. For awareness, Apple is adding a “clinically validated” hearing test that owners can take at any time. And then for assistance, hearing aid features are launching for those whose hearing tests identify them as potentially benefiting from hearing assistance features. Apple claims that they expect clearance from the FDA on these features “soon,” with updates expected to come to iOS in the fall.We got the chance to demo a not-yet-final version of the Hearing Test app after the iPhone event, which you can check out here, and it’s worth noting that the test will not be available for the earlier AirPods Pro model.AirPods MaxImage Credits: AppleA series of incremental updates came to AirPods Max during the Apple Event, with USB-C added in, and a series of new colors coming to the updated headphones September 20 for the same price of $549. Get the full rundown here.Cheaper iPhones (in India)Apple readies first retail store in IndiaImage Credits: AppleThe iPhone 16 lineup pricing is familiar for those following Apple in the states, but in India, Apple fans will be able to benefit from a discount from the iPhone 15 lineup of about 15,000 rupees, which is roughly $178, The price comes after India lowered import duties on electronics, and amid Apple’s expansion of local manufacturing, which had earlier spurred a discount for the 15 models in the country.Voice Memos with background musicImage Credits: AppleApple showed off a new feature for the Voice Memos app, which allows vocal tracks to be layered on top of pre-recorded music or instrumentals. Read more here.New macOS Sequoia launching September 16Image Credits: AppleIn an untraditionally swift launch for its macOS updates, Apple announced that the update first showcased at WWDC 2024 will launch in a week, with a series of updates built upon Apple Intelligence that you can run through here.","AI, Apple, Apple event 2024, Apple Watch, Hardware, ios 18, iPhone, iphone 16, TC",,,,34
"Apple punts on AI","Devin Coldewey",2024-09-10,https://techcrunch.com/2024/09/10/apple-punts-on-ai/,"One would have expected that “Apple’s first phone made from the ground up for Apple Intelligence” would justify being so.","It was reasonable to expect that Apple would do with AI what it has done before with so many features and apps: wait, take notes, and then redefine. But though it has filed off some of the sharper edges of the controversial technology, the company seems to have hit the same wall as everyone else: Apple Intelligence, like other AIs, doesn’t really do anything.Well, it does do something. A few things, in fact. But like many AI tools, it seems to be an incredibly computationally demanding shortcut for ordinary tasks. This isn’t necessarily bad, especially as inference — that is, performing the actual text analysis, generation, etc. — becomes efficient enough to move to the device itself.It was billed as much more, however. Tim Cook told us at the outset of Monday’s “Glowtime” event that Apple Intelligence’s “breakthrough capabilities” will have “an incredible impact.” Craig Federighi said it will “transform so much of what you do with your iPhone.”The capabilities:Rephrase snippets of textSummarize emails and messagesGenerate fake emoji and clip artFind pictures of people, locations, and eventsLook up thingsAny of those feel like a breakthrough to you? There are countless writing helpers. Summary capability is inherent to nearly every LLM. Generative art has become synonymous with a lack of effort. You can trivially search your photos this way across any number of services. And our “dumb” voice assistants were looking up Wikipedia entries for us a decade ago.True, there is some improvement. Doing these things locally and privately is definitely preferable; there are some new opportunities for people who can’t easily use a regular touchscreen UI; there is certainly a net increase in convenience.But literally none of it is new or interesting. There don’t appear to be any meaningful changes to these features since they were released in beta after WWDC, beyond the expected bug fixes. (We’ll know more when we’ve had time to test them.)One would have hoped that “Apple’s first phone made from the ground up for Apple Intelligence” would offer much more. As it turns out, the 16 won’t even ship with all the features mentioned; they’ll arrive in a separate update.Is it a failure of imagination or of technology? AI companies are already beginning to reposition their products as yet another enterprise SaaS tool, rather than the “transformative” use cases we heard so much about (it turns out those were mostly just repeating stuff they found on the web). AI models can be extremely valuable in the right place, but that place doesn’t seem to be in your hand.There’s a bizarre mismatch between how commonplace these AI capabilities are becoming and how bombastic the descriptions of them are. Apple has become increasingly prone to the kind of breathless promotion it once showed up with its restraint and innovation. Monday’s event was among the least exciting in recent years, but the language was, if anything, more extravagant than usual.Like the other AI providers, then, Apple is participating in the multi-billion-dollar game of make-believe with the idea that these models are transformative and groundbreaking — even if almost no one finds them to be so. Because who could justify spending as much as these companies have when the result is that you can do the same things you did five years ago?AI models may be legitimately game changing in certain areas of scientific research, on some coding tasks, perhaps in materials and structural design, and likely (though perhaps not for the better) in media.But if we are to trust our eyes and thumbs, rather than Cook and Federighi’s reality distortion hour, it sure looks like the features we’re supposed to be excited about don’t do much that’s new, let alone revolutionary. Ironically, Apple’s announcement has failed to provide AI its “iPhone moment.”","AI, Apple, Apple event 2024, Apple Intelligence",,,,35
"Apple partners with third parties, like Google, on iPhone 16’s visual search","Sarah Perez",2024-09-10,https://techcrunch.com/2024/09/10/apple-partners-with-third-parties-like-google-on-iphone-16s-visual-search/,"Apple’s relationship with Google as its search partner is taking a new turn with Apple’s introduction of visual search, or “Visual Intelligence,” as the iPhone maker dubbed it Monday during…","Apple’s relationship with Google as its search partner is taking a new turn with Apple’s introduction of visual search, or “Visual Intelligence,” as the iPhone maker dubbed it Monday during the company’s “It’s Glowtime” event. Already, Alphabet pays Apple roughly $20 billion per year to make Google the default search engine in its Safari browser. Now, iPhone 16 users will be able to access Google’s search engine — and its visual search capabilities — with a click of the device’s new Camera Control button.OpenAI’s ChatGPT, which is becoming accessible via Siri, was also shown as a third-party partner in a demo where you could aim your phone’s camera at your class notes and get help understanding the concept or problem with a click of a button. With the Camera Control, Apple explained how users can quickly take a photo or record video, and how they’ll be able to slide their finger across the button to frame their shot and adjust options like zoom, exposure, or depth of field in a new camera preview experience. However, the button also provides iPhone 16 users with access to Apple’s new “visual intelligence” search feature, which is where the Google partnership comes in.When first introduced, the iPhone 16’s Camera Control seemed like Apple lingo for “shutter button,” but as the event continued, Apple explained there’s more you can do with this new hardware feature. With Visual Intelligence, there’s more to it than just an easy way to learn about the things in the camera’s view; you now also have another way to access third-party services without having to launch standalone apps.Essentially a visual search feature, similar to Google Lens or Pinterest Lens, Apple described Visual Intelligence as a way to instantly learn about everything you see. Across a few examples, Apple demonstrated how you could click the Camera Control button to pull up information about a restaurant you saw while out and about in town, or how you could use the feature to identify the breed of a dog you saw on your walk. The feature could also transform an event poster tacked on a wall into a calendar entry with all the details included.Apple’s Senior Vice President of Software Engineering Craig Federighi then casually mentioned that the feature could be used to access Google search, too.“The Camera Control is also your gateway to third-party tools, making it super fast and easy to tap into their specific domain expertise. So, if you come across a bike that looks exactly like the kind you’re in the market for, just tap to search Google for where you can buy something similar,” he said. Image Credits: AppleThe demo showed a person tapping the Camera Control button while aiming their iPhone at a bike, then reviewing an array of similar options available for purchase in a pop-up window overlaid on top of the camera’s view. The grid of images and descriptions of the matching bikes was then followed by a smaller onscreen button that read “More results from Google,” indicating you could continue your Google search with another tap. What Apple didn’t explain is how or when a push of the Camera Control button would know to turn to a third-party partner for an answer rather than a built-in Apple service — like Apple Maps, which was shown in the demo about the restaurant. Nor did the company fully explain how users would be able to control or configure this feature. Instead, Federighi said, somewhat vaguely, “Of course, you’re always in control of when third-party tools are used.” Reached for comment, a Google spokesperson said the company didn’t have anything to share on its partnership at this stage. Apple didn’t respond to a request for comment. However, we understand the deal is a part of the two companies’ existing relationship and does not involve Google’s Gemini AI. What’s interesting about this feature is that it presents a new paradigm for interacting with software and services beyond those that Apple ships with the iPhone. And it arrives at a time when the concept of an App Store has begun to feel dated. With AI technology, users can ask questions, perform productivity tasks, be creative with images and video, and more. Those are things consumers used to turn to apps to do, but can now do from a new interface of talking and texting with an AI assistant. Instead of rushing to build its own competitor to ChatGPT, Apple is presenting itself as the platform to reach third-party services, including AI technologies, search services, and likely other providers in the future. What’s more, it can make these connections by way of behind-the-scenes deals with partners — like its partnership with OpenAI on select AI features — instead of tapping into transactions taking place inside the apps as a means of generating revenue. It also smartly keeps Apple’s reputation from taking a hit when a third party, like ChatGPT, gets things wrong (as AIs tend to do) or when a Google Search doesn’t yield helpful results.Edited, 1:15 p.m. ET; reversed Apple and Alphabet in the intro section about payments. This was corrected.","AI, Apple, Apple event 2024, Apps, ChatGPT, Google, iphone 16, visual search",,,,36
"Smartcat secures $43M for its AI-powered translation platform","Kyle Wiggers",2024-09-10,https://techcrunch.com/2024/09/10/smartcat-secures-43m-for-its-ai-powered-translation-platform/,"Smartcat, founded in 2016, is among the vendors providing automated translation tools geared toward enterprises, and its co-founder and CEO, Ivan Smolnikov, says business is good.","Can AI ever fully replace translators? Not likely. AI translations tend to lack the lexical richness of their human-translated counterparts, mainly because AI models make choices based on probability — not lived experience. Certainly, AI can produce “accurate” translations, but the translations lack the spice of life, like a textbook version of the source text.For many companies, accuracy is all that’s required, making the AI translation sector an attractive one. Smartcat, founded in 2016, is among the vendors providing automated translation tools geared toward enterprises, and its co-founder and CEO, Ivan Smolnikov, says business is good.“We have over 1,000 corporate customers, including 20% of the Fortune 500,” he told TechCrunch. “While most of Smartcat’s clients are large global enterprises, we also count many local and international government entities among them.”Before founding Smartcat, Smolnikov was a physicist at the Russian Academy of Sciences, where he researched fiber optics materials. After two years in the lab, Smolnikov decided to try his hand at entrepreneurship, founding the language services company ABBYY LS. It’s at ABBYY where Smolnikov incubated Smartcat, in fact, which spun out as an independent entity in 2016. Smolnikov left ABBYY, where he was a board member at the time, the same year.“I founded Smartcat to reinvent the traditional translation agency model, which is based on a time-consuming, manually operated, long supply chain, built on human services,” Smolnikov said. “Our AI platform supports a wide range of use cases for enterprise customers dealing with multilingual content.”At a high level, Boston-based Smartcat offers tools, apps, and managed services to help companies translate written and spoken content — think e-learning courses, websites, files, and software — into around 280 languages. Smartcat doesn’t necessarily train AI translation models itself, but rather runs content through a “matching engine” that determines which third-party model might be appropriate for the content and target output language.Smartcat says it does fine-tune translation models — including in-house models customers themselves have trained — where there it makes sense, like in cases where a company has a large database of commonly translated phrases they want a model to “memorize.”In an acknowledgement that AI makes mistakes sometimes, Smartcat also provides access to a network of translators and copy editors who can assist with review for a fee. “Customers can choose different translation options, such as AI translation, human translation, or a combination — automatic translation with professional editing,” Smolnikov explained.As of a few years ago, some translators on Reddit suggested that Smartcat had a problem with dishonest — and non-paying — clients. Smolnikov assured me this has been cleared up, though, and that translators can charge whatever they wish minus Smartcat’s 2% to 8% per-payment fee. (The exact fee depends on the volume of jobs processed and the customer’s and translators’ countries of residence.)While there’s a plentiful supply of companies selling AI translation services, including human-aided ones (see: EasyTranslate, D-ID, DeepL, Lilt, Lengoo, etc.), Smolnikov sees Smartcat primarily competing with old-school translation agencies and in-house orgs. “Traditionally, enterprises relied on outsourcing to agencies,” he said. “Insourcing was another approach, but when done manually, it struggled with scalability … Smartcat’s focus on language AI quality provides a practical [alternative].”Investors seem to be in agreement. Smartcat on Tuesday announced that it raised $43 million in a Series C funding round led by Left Lane Capital. This brings the company’s total raised to $70 million; Smolnikov says that the new cash will be put toward expanding its 200-person team, product development, and various ongoing marketing and sales efforts.Vinny Pujji, managing partner at Left Lane Capital, had this to say in a canned statement: “As an early market mover, Smartcat has a broad portfolio of customers and is uniquely positioned to compound the depth and quality of their product offering, continuing to lock in competitive advantages over time.”Those “advantages” could translate (no pun intended) into a substantial payday, should the rosiest projections about the AI translation sector come true. According to Grand View Research, the global market for machine translation solutions — which was worth $978.2 million in 2022 — could grow at a 13.5% compound annual growth rate from from 2023 to 2030.","AI, AI, Enterprise, Exclusive, Funding, Fundraising, language, Left Lane Capital, smartcat, startup, Startups, Translation",,,,37
"Heart disease is the world’s biggest killer — this Cambridge Uni spinout is using AI to find new treatments","Paul Sawers",2024-09-09,https://techcrunch.com/2024/09/09/heart-disease-is-the-worlds-biggest-killer-this-cambridge-uni-spinout-is-using-ai-to-find-new-treatments/,"Cambridge University spinout CardiaTec is striving to tackle cardiovascular diseases, one of the world’s leading causes of death, with AI.","While artificial intelligence (AI) promises to transform all manner of industries, the biggest game-changing breakthroughs in this new era of data-infused machine intelligence arguably lies in the field of drug discovery. By analyzing vast amounts of biological data, AI can help researchers predict how different chemical compounds will interact with specific targets in the body, accelerating the discovery of promising drug candidates.It’s against this backdrop that Cambridge University spinout CardiaTec is striving to tackle cardiovascular diseases (CVD). To bolster its efforts, the company today said it has raised $6.5 million in a seed round of funding.CVD is the preeminent cause of death globally, resulting in 17.9 million deaths each year, according to the World Health Organization (WHO). At the top of the list is ischemic heart disease (coronary heart disease), responsible for 13% of the world’s total deaths.Founded in 2021, CardiaTec is the handiwork of biotech and bioengineering graduates Raphael Peralta (CEO) and Thelma Zablocki (COO). They’re supported by their third co-founder and CTO, Namshik Han, a lecturer in AI drug discovery at the University of Cambridge, where Peralta and Zablocki studied for a Master of Philosophy in Bioscience Enterprise. Han, who has a background in machine learning, computational biology, cancer genomics, and cancer epigenomics, is also head of AI at the university’s Milner Therapeutics Institute, which forges close ties with industry, including pharmaceutical companies.“He [Han] is an academic who sits on the border with industry, so he understands that translational perspective,” Peralta told TechCrunch in an interview. “We came together with the opportunity to use Namshik’s work, but within the cardiovascular space.”CardiaTec is tackling the crux of the problem: The average expense of progressing a drug candidate from discovery through launch is around $2.2 billion, and that cost is driven substantively by the fact that 90% of potential candidates fail in the process, according to Deloitte. CardiaTec is setting out to “decode” the biology of CVD.To do this, the company has struck partnerships with 65 hospitals across the U.K. and the U.S., which are providing human heart tissue as part of the company’s broader data collection efforts, which will help it build what it calls the “largest human heart tissue-multi-omics dataset,” spanning a broad gamut of biological information from across molecular biology. By doing this, CardiaTec hopes to identify novel, targeted therapeutics.“Historically, it’s been very difficult to access human tissue, especially those of deceased people because of matters related to consent, ethics, and logistics,” Peralta said. “Now the infrastructure in hospitals is much more embedded, and we can actually begin to get access to these human tissues and generate data.”In the context of cardiovascular disease, this means that CardiaTec can compare healthy artery tissue with that of an artery where plaque buildup has led to a heart attack, and generate the data its computational models need further downstream. Such computational approaches, involving a vast amount of different “multi-omics” data types, are capable of aggregating and analyzing data at a scale humans simply can’t match. “We can now look not just in genetics, but we can look at genetics, epigenetics, gene expression, protein function, all in a single model,” Peralta said. “So we have a much more in-depth understanding of the mechanisms that are driving disease.”CardiaTec co-founder and CEO Raphael PeraltaImage Credits: CardiaTecHeart of the problemWhile drugs made with help from AI have yet to make it to market, the early promise has created a wave of excitement and a swathe of startups have raised bucketloads of cash in the process. In the past few months alone, we’ve seen the likes of Xaira emerge from stealth with $1 billion in funding, while Sam Altman-backed Formation Bio raised $372 million. In the U.K., meanwhile, Healx has nabbed $47 million to identify new drugs for rare diseases.Heavily VC-backed pharmaceutical startup Insilico Medicine recently claimed a world’s first when it announced that it had identified a new drug candidate for a rare lung disease called idiopathic pulmonary fibrosis. AI played a pivotal role not only in designing the drug’s chemical structure, but also in figuring out which part of a cell it should be targeting. The drug was initially tested in animals and is currently in “Phase II” trials in the U.S. and China, where it’s hoped it will generate the evidence needed to establish its efficacy in treating humans.Elsewhere, AI is being used to help discover everything from new antibiotics for tackling superbugs to drugs for treating obsessive compulsive order (OCD).Citing data from peer-reviewed journal Nature Reviews Drug Discovery, Peralta said one of CardiaTec’s main differentiators is that its focus lies squarely on cardiovascular disease, which only 3% of active AI-first companies are targeting.“The majority of companies who are applying AI in therapeutic discovery are in oncology, followed by central nervous systems and neurogenic diseases, respiratory and infectious diseases, and then way at the bottom of the list is cardiovascular diseases,” Peralta said. “Cardiovascular disease is the world’s leading global cause of death — not a lot of people know that, but there’s a big unmet need that hasn’t been captured in pharma.”CardiaTec had previously raised $1.8 million in pre-seed funding, and with this fresh $6.5 million in cash, the company is well-financed to extend its proprietary data-gathering efforts, wet lab validation of its therapeutic targets model, and bolster its eight-person team in Cambridge. The next step is to start identifying and testing actual drug candidates, which — in the grand scheme of drug R&D — is likely to be several years away.CardiaTec’s seed round was led by Montage Ventures, with participation from Continuum Health Ventures, Laidlaw Ventures, Apex Ventures, and a number of angel investors.","AI, AI drug discovery, Biotech & Health, CardiaTec, Fundraising, heart disease, Startups",,,,38
"Apple upgrades watchOS with AI-powered features, including translation","Kyle Wiggers",2024-09-09,https://techcrunch.com/2024/09/09/apple-upgrades-watchos-with-ai-powered-features-including-translation/,"Apple has announced new features for the latest version of watchOS, watchOS 11, including translation and an upgraded Smart Stack.","Apple’s watchOS is getting a few AI-powered upgrades, the company revealed at its Apple Event 2024 on Monday. Most were revealed at the company’s Worldwide Developers Conference (WWDC) in June, but Apple shed a bit more light during its keynote this morning.The Translate app is coming to the latest version of watchOS, watchOS 11. Like on other platforms, Translate will leverage AI for speech recognition and translation in a range of different languages.On the Apple Watch Series 9, Apple Watch Series 10 and Apple Watch Ultra, Translate can work without a phone connection. Apple says that they’re the only Apple Watch models with enough storage to download the necessary language models; you can download up to 20 models at a time.Image Credits: AppleAI is also improving Smart Stack, the watchOS feature that uses contextual information to show relevant widgets. Smart Stack will soon automatically add new widgets “when you need them,” Apple says — presumably based on factors like the time of day and your location.In one last AI-powered enhancement, watchOS 11 has a new “photos” watch face that’ll use machine learning to identify and curate photos from your library.Updated September 7, 4:47 p.m. Pacific with details about offline translation.","AI, AI, Apple, Apple event 2024, Apple Watch, Hardware, watchOS",,,,39
"Audible recruits voice actors to train audiobook-generating AI","Kyle Wiggers",2024-09-09,https://techcrunch.com/2024/09/09/audible-recruits-voice-actors-to-train-audiobook-generating-ai/,"Audible, Amazon’s audiobook business, on Monday announced that it’ll use AI trained on professional narrators’ voices to generate new audiobook recordings. A select, U.S.-based cohort of audiobook narrators will be…","Audible, Amazon’s audiobook business, on Monday announced that it’ll use AI trained on professional narrators’ voices to generate new audiobook recordings.A select, U.S.-based cohort of audiobook narrators will be invited to train AI on their voices starting this week, Audible said. The trained AI will be used to make recordings, and narrators will have the chance to approve their synthetic voice for specific works as well as edit the pronunciation and pacing. Audible says narrators who participate in the program will be compensated for any audiobooks created using their AI voices on a title-by-title, royalty-sharing basis.","AI, AI, Amazon, Audible, audiobooks, Generative AI, In Brief, Media & Entertainment",,,,40
"What is Apple Intelligence, when is it coming and who will get it?","Brian Heater",2024-09-09,https://techcrunch.com/2024/09/09/what-is-apple-intelligence-when-is-coming-and-who-will-get-it/,"Apple Intelligence was designed to leverage things that generative AI already does well, like text and image generation, to improve upon existing features.","After months of speculation, Apple Intelligence took center stage at WWDC 2024 in June. The platform was announced in the wake of a torrent of generative AI news from companies like Google and Open AI, causing concern that the famously tight-lipped tech giant had missed the boat on the latest tech craze.Contrary to such speculation, however, Apple had a team in place, working on what proved to be a very Apple approach to artificial intelligence. There was still pizzazz amid the demos — Apple always loves to put on a show — but Apple Intelligence is ultimately a very pragmatic take on the category.Apple Intelligence (yes, AI for short) isn’t a standalone feature. Rather, it’s about integrating into existing offerings. While it is a branding exercise in a very real sense, the large language model (LLM) driven technology will operate behind the scenes. As far as the consumer is concerned, the technology will mostly present itself in the form of new features for existing apps.We learned more during the Apple’s iPhone 16 event, which was held on September 9. During the event, Apple touted a number of AI-powered features coming to their devices, from translation on the Apple Watch Series 10, visual search on iPhones and a number of tweaks to Siri’s capabilities. Apple also revealed that Intelligence would launch in beta this fall in the U.S. in English, with a wider international rollout with additional languages planned through the end of this year into 2025.What is Apple Intelligence?Image Credits: AppleCupertino marketing executives have branded Apple Intelligence: “AI for the rest of us.” The platform is designed to leverage the things that generative AI already does well, like text and image generation, to improve upon existing features. Like other platforms including ChatGPT and Google Gemini, Apple Intelligence was trained on large information models. These systems use deep learning to form connections, whether it be text, images, video or music.The text offering, powered by LLM, presents itself as Writing Tools. The feature is available across various Apple apps, including Mail, Messages, Pages and Notifications. It can be used to provide summaries of long text, proofread and even write messages for you, using content and tone prompts.Image generation has been integrated as well, in similar fashion — albeit a bit less seamlessly. Users can prompt Apple Intelligence to generate custom emojis (Genmojis) in an Apple house style. Image Playground, meanwhile, is a standalone image generation app that utilizes prompts to create visual content than can be used in Messages, Keynote or shared via social media.Apple Intelligence also marks a long-awaited face-lift for Siri. The smart assistant was early to the game, but has mostly been neglected for the past several years. Siri is integrated much more deeply into Apple’s operating systems; for instance, instead of the familiar icon, users will see a glowing light around the edge of their iPhone screen when it’s doing its thing.More important, new Siri works across apps. That means, for example, that you can ask Siri to edit a photo and then insert it directly into a text message. It’s a frictionless experience the assistant had previously lacked. Onscreen awareness means Siri uses the context of the content you’re currently engaged with to provide an appropriate answer.Who gets Apple Intelligence and when?Image Credits: Darrell EtheringtonIt’s too early to speak to the efficacy of any of the above features. While the latest batch of Apple operating systems hit public beta in July, Apple Intelligence isn’t yet fully baked. It’s clear, however, that Apple was pressed to talk it up in June both to bely concern that it didn’t have a generative AI plan and to offer a head start for developers.While we saw demos at WWDC, we’re going to have to wait until the fall to get our hands on a beta of Apple Intelligence. The first release will come in October in the U.S., solely with support for English. In December, localized English in Australia, Canada, New Zealand, South Africa and the U.K. will launch, and sometime in 2025 Apple planns to roll out Chinese, French, Japanese and Spanish language compatibility. As it happens, fall is also when the public versions of iOS/iPadOS 18 and Mac Sequoia will hit the App Store. The offering will be free to use, so long as you have one of the following pieces of hardware:iPhone 15 Pro Max (A17 Pro)iPhone 15 Pro (A17 Pro)iPad Pro (M1 and later)iPad Air (M1 and later)MacBook Air (M1 and later)MacBook Pro (M1 and later)iMac (M1 and later)Mac mini (M1 and later)Mac Studio (M1 Max and later)Mac Pro (M2 Ultra)Notably, only the Pro versions of the iPhone 15 are getting access, owing to shortcomings on the standard model’s chipset. Presumably, however, the whole iPhone 16 line will be able to run Apple Intelligence when it arrives.Private Cloud ComputeImage Credits: AppleApple has taken a small-model, bespoke approach to training. Rather than relying on the kind of kitchen sink approach that fuels platforms like GPT and Gemini, the company has compiled datasets in-house for specific tasks like, say, composing an email. The biggest benefit of this approach is that many of these tasks become far less resource intensive and can be performed on-device.That doesn’t apply to everything, however. More complex queries will utilize the new Private Cloud Compute offering. The company now operates remote servers running on Apple Silicon, which it claims allows it to offer the same level of privacy as its consumer devices. Whether an action is being performed locally or via the cloud will be invisible to the user, unless their device is offline, at which point remote queries will toss up an error.Apple Intelligence with third-party appsImage Credits: Didem Mente/Anadolu Agency / Getty ImagesA lot was made about Apple’s pending partnership with OpenAI ahead of WWDC. Ultimately, however, it turned out that the deal was less about powering Apple Intelligence and more about offering an alternative platform for those things it’s not really built for. It’s a tacit acknowledgement that building a small-model system has its limitation.Apple Intelligence is free. So, too, is access to ChatGPT. However, those with paid accounts to the latter will have access to premium features free users don’t. This will, presumably, be a big driver to the already thriving generative AI platform.We know for sure that Apple plans to partner with additional generative AI services. The company all but said that Google Gemini is next on that list.","AI, Apple, Apple Intelligence, Apps, evergreens, siri",,,,41
"Here’s the full list of 35 US AI startups that have raised $100M or more in 2024","Rebecca Szkutak",2024-09-09,https://techcrunch.com/2024/09/09/heres-the-full-list-of-28-us-ai-startups-that-have-raised-100m-or-more-in-2024/,"In the first half of 2024 alone, more than $35.5 billion was invested into AI startups globally.","For some, AI fatigue is real — but clearly venture investors haven’t grown tired of the category.In the first half of 2024 alone, more than $35.5 billion was invested into AI startups globally, recent Crunchbase data found. Five of the six venture rounds of more than $1 billion raised in the first half of 2024 were raised by AI companies. Since the end of June, another 10 mega-round deals have occurred, with these companies raising over $3 billion; $1 billion of that total went to one company, the new one launched by OpenAI’s co-founder Ilya Sutskever.Here are the U.S.-based AI companies that raised $100 million or more so far in 2024.SeptemberSafe Superintelligence, an AI research lab founded by former OpenAI co-founder Ilya Sutskever and AI investor Daniel Gross. It announced a $1 billion raise at a $4 billion valuation on September 4. Andreessen Horowitz, Sequoia and DST Global participated in the round, among others.AugustAI coding startup Magic raised its second mega-round of the year on August 29. The San Francisco-based company raised $320 million in a Series C round. CapitalG, Sequoia and Jane Street Capital participated in the round, among others. The company last raised a $117 million Series B in February.General Catalyst led the $150 million Series C round into Codeium, an AI-powered coding platform, that closed on August 29. The round also included Kleiner Perkins and Greenoaks and valued Codeium at $1.2 billion.DevRev, which makes AI support agents, garnered a $1.1 billion valuation after its sizable early-stage raise. The Silicon Valley-based company raised a $100 million Series A round that included investors like Khosla Ventures, Mayfield and Param Hansa Values. The company was founded in 2020.San Francisco-based Abnormal Security raised $250 million for its AI-driven email security company. This funding round was led by Wellington Management with participation from Menlo Ventures, Greylock and Insight Partners. The company is valued at more than $5 billion.Groq — not to be confused with Grok — announced a $640 million Series D round on August 5 led by BlackRock. The AI chip startup also received investment from Type One Ventures, Verdure Capital Management and Neuberger Berman, among others. The company is valued at more than $3 billion.JulyRenowned AI researcher Fei-Fei Li’s startup World Labs raised a $100 million round in July, sources told TechCrunch. The startup is already valued at more than $1 billion according to the Financial Times. World Labs is looking to build AI models that can accurately estimate the three-dimensional physicality of real-world objects.Legal tech company Harvey announced a $100 million Series C round on July 23. The round was led by Google Ventures, with participation from OpenAI, Kleiner Perkins and Sequoia. This round values the San Francisco-based company at $1.5 billion.Hebbia, $130 million: Andreessen Horowitz led the round for Hebbia that closed July 8. The startup, which uses generative AI to search large documents, also raised money from Peter Thiel, Index Ventures and Google Ventures and garnered a $700 million valuation.Skild AI, $300 million: Pittsburgh-based Skild AI announced a $300 million Series A round on July 9 that valued the company at $1.5 billion. The round was led by Lightspeed Venture Partners, Coatue and Jeff Bezos’ Bezos Expeditions with participation from Sequoia, Menlo Ventures and General Catalyst, among others. Skild AI builds tech to power robots.JuneBright Machines, $106 million: BlackRock led a $106 million Series C round into Bright Machines that closed on June 25. Nvidia, Microsoft and Eclipse Ventures, among others, also participated. The startup makes both smart robotics and AI-driven software and has raised more than $437 million in total funding.Etched.ai, $120 million: San Francisco-based Etched.ai raised a $120 million Series A round on June 25. The round was led by Primary Venture Partners and Positive Sum with participation from Two Sigma Ventures, Peter Thiel and Kyle Vogt, among others. Etched.ai is working to make chips that can run AI models faster and cheaper than GPUs.EvolutionaryScale, $142 million: New York-based EvolutionaryScale is developing biological AI models for therapeutic design. It raised a $142 million seed round that closed on June 25. The round was led by Lux Capital, former GitHub CEO Nat Friedman and Daniel Gross, an angel investor and former head of AI at Y Combinator. The company was founded in 2023.AKASA, $120 million: Healthcare revenue cycle automation platform Akasa announced a $120 million round on June 18. The San Francisco-based startup has collected $205 million in total funding and has raised from investors, including Andreessen Horowitz, Costanoa Ventures and Bond in prior rounds.AlphaSense, $650 million: New York-based AlphaSense raised a $650 million Series F round that was announced on June 11. The round was led by Viking Global Investors and BDT & MSD Partners with participation from CapitalG, SoftBank Vision Fund and Goldman Sachs, among others. AlphaSense is a market intelligence platform founded in 2008. The company has raised more than $1.4 billion in venture funding and was most recently valued at $4 billion.MayxAI, $6 billion: Elon Musk’s xAI raised a jaw-dropping $6 billion Series B round on May 31 from investors, including Sequoia, Valor Equity Partners and Fidelity, among others. The startup is building an AI platform that will “accelerate human scientific discovery” and is valued at an equally stunning $24 billion.Scale AI, $1 billion: Scale AI, a startup that provides data-labeling services to companies for training AI models, raised $1 billion in May. The Series F round was led by Accel with participation from Tiger Global, Spark Capital and Amazon, among others. San Francisco-based Scale AI has raised more than $1.6 billion in total and is currently valued at nearly $14 billion.Suno, $125 million: AI-music creation platform Suno raised $125 million in a Series B round that closed on May 21. The round values the Cambridge, Massachusetts, startup at $500 million. Founder Collective, Lightspeed Venture Partners and Matrix participated in the round in addition to former GitHub CEO Nat Friedman and former head of AI at Y Combinator Daniel Gross.Weka, $140 million: Silicon Valley-based Weka created an AI-native data platform and raised $140 million in a Series E round that closed on May 13. The funding was led by Valor Equity Partners with participation from Qualcomm Ventures, Nvidia and Hitachi Ventures, among others. The startup was valued at $1.6 billion.CoreWeave, $1.1 billion: New Jersey-based GPU infrastructure provider CoreWeave raised $1.1 billion in a Series C round that closed on May 1. Coatue led the round with participation from Fidelity, Altimeter Capital and Magnetar Capital, among others. CoreWeave was launched in 2017 and is valued at $19 billion.AprilBlaize, $106 million: AI computing platform company Blaize raised $106 million in a Series D round that was announced on April 29. The round had participation from investors, including Temasek, Franklin Templeton and Bess Ventures, among others. The company was founded in 2010 and has raised $242 million.Augment, $227 million: Palo Alto-based Augment raised $227 million for its AI coding assistance startup. The startup’s Series B round was announced on April 24. Lightspeed Venture Partners, Index Ventures and Sutter Hill Ventures participated in the round, which valued the startup just shy of $1 billion.Cognition, $175 million: Founders Fund led applied AI lab startup Cognition’s $175 million round that closed on April 24. This round came just about a month after the firm raised a $21 million Series A round in March from Founders Fund and numerous other investors, including Ramp co-founder Eric Glyman, Stripe co-founders Patrick and John Collison, and DoorDash co-founder Tony Xu. The company was founded in November 2023 and is already valued at nearly $2 billion.Xaira Therapeutics, $1 billion: San Francisco-based AI drug discovery startup Xaira Therapeutics raised a $1 billion Series A round. Foresite Capital and ARCH Venture Partners led the round that was announced on April 23. Sequoia, NEA and Lux Capital participated in the round, among many others.Cyera, $300 million: Coatue led the recent $300 million Series C round into AI-powered data security platform Cyera that closed on April 9. The round valued New York-based startup at $1.4 billion. Sequoia, Redpoint and Accel also participated in the round, among others.MarchCelestial AI, $175 million: Celestial AI, founded in 2020, is building an optical interconnect technology platform for data centers and AI solutions and raised a $175 million Series C round on March 27, which brought its total funding amount to $338 million. The round was led by Thomas Tull’s US Innovative Technology Fund with participation from M Ventures, Temasek and Tyche Partners, among others.FundGuard, $100 million: FundGuard is a New York-based startup offering an AI-powered investment accounting operating system that raised $100 million at a $400 million valuation. The Series C round closed on March 25 and was led by Key1 Capital with participation from Hamilton Lane, Blumberg Capital and Team8, among others.Together AI, $106 million: Salesforce Ventures led Together AI’s $106 million Series A round that valued the company at $1.2 billion. Together AI is a platform designed to help create infrastructure and open source generative AI for developing AI models. NEA, Kleiner Perkins and Lux Capital also participated in the round, among others. The round was announced on March 13.Zephyr AI, $111 million: Fairfax Station, Virginia-based Zephyr AI raised a $111 million Series A round that closed on March 13. Revolution Growth, Eli Lilly and Company Foundation, EPIQ Capital Group and investor Jeff Skoll all participated in the round. The startup, founded in 2020, uses AI to enhance drug discovery and precision medicine. It has raised $129.5 million total so far.FebruaryGlean, $203 million: AI-driven enterprise search startup Glean raised $203 million in a February 27 round that valued the startup at $2.2 billion. The Series D round was led by Lightspeed Venture Partners and Kleiner Perkins with participation from Sequoia and Databricks Ventures, among others. The Silicon Valley-based startup has raised more than $350 million in venture funding and its founder, Arvind Jain, was recently interviewed on TechCrunch’s Found podcast.Figure, $675 million: Silicon Valley-based AI robotics startup Figure raised a $675 million Series B round that closed on February 24. The round valued the startup at nearly $2.7 billion. Nvidia, OpenAI and Microsoft participated in the round, among others. The startup was founded in 2022 and has raised more than $850 million.Abridge, $150 million: Pittsburgh-based Abridge, which uses AI to transcribe medical conversations, raised a $150 million Series C round that closed on February 23. The round was led by Redpoint and Lightspeed Venture Partners with participation from USV, IVP and Spark Capital, among others. This round brings the six-year-old company’s valuation to $850 million.Recogni, $102 million: The company designs high-output but low-power AI interface solutions, and it raised a $102 million Series C round on February 20. The round was led by GreatPoint Ventures and Celesta Capital. Pledge Ventures, Mayfield and DNS Capital also contributed to the round.Lambda, $320 million: San Francisco-based deep learning infrastructure company Lambda raised $320 million in a Series C round that was announced on February 15. The round was led by Thomas Tull’s US Innovative Technology Fund with participation from Gradient Ventures, Mercato Partners and T. Rowe Price, among others. Lambda has raised more than $900 million in venture capital and was most recently valued at $1.5 billion.Magic, $117 million: AI coding startup Magic raised a $117 million Series B round that closed on February 12. The round was led by NFDG Ventures with participation from CapitalG and angel investor Elad Gil. The San Francisco-based company has raised more than $145 million in total capital.JanuaryKore.ai, $150 million: A startup building conversational AI for enterprises, Kore.ai raised a $150 million Series D round that was announced on January 30. FTV Capital led the round into the Orlando, Florida-based company. Nvidia, Vistara Growth, and NextEquity Partners participated as well, among others. Kore.ai was founded in 2013 and has raised more than $223 million in funding.This piece was originally published on July 13, 2024, and was updated on September 9, 2024, to include more deals. This piece has been updated to correct Glean’s current valuation.","AI, AI startups, Artificial Intelligence (AI), evergreens, fundraising, megarounds, North America, Startups, United States, Venture, venture capital",,,,42
"With Apple Intelligence, iPhone users will finally get a better Siri","Sarah Perez",2024-09-09,https://techcrunch.com/2024/09/09/with-apple-intelligence-iphone-users-will-finally-get-a-better-siri/,"While consumers won’t get the full impact of the Siri upgrade until Apple Intelligence launches, Apple promises it will upend the user experience","Will Siri finally become useful? That’s the promise Apple laid out today at its “Glowtime” event, where the company introduced its iPhone 16 lineup — its first new iPhones to ship with AI-powered functionality, courtesy of Apple Intelligence and, later, a partnership with ChatGPT maker OpenAI.While consumers won’t get the full impact of the Siri upgrade until Apple Intelligence launches, Apple promises it will upend the user experience by making the iPhone not just a small computer that fits in your pocket, but also a small personal assistant powered by AI.In the near term, Siri will see more immediate improvements, including the ability to type questions to Siri instead of speaking and to engage in more natural conversations — including the occasional stumble — thanks to its richer language understanding. You’ll also be able to change the wake word for Siri through a new accessibility feature.Developers are gaining access to SiriKit, which allows them to integrate Apple Intelligence-powered features into their own apps, the way that Apple has integrated Siri with first-party apps like Calendar, Mail, Notes, Safari, Files, Contacts, Voice Memos, Photos, Books, Freeform, Files and others. Even Apple’s AirPods are getting an upgraded Siri experience, as users will be able to nod or shake their heads in response to Siri announcements.To showcase its new AI functionality, Siri will receive a cosmetic makeover in iOS 18. Instead of a glowing orb at the bottom of the screen when activated, Siri will light up the edges of the iPhone in an eye-catching illumination. This will appear when Siri is active on the iPhone, iPad, or CarPlay. Unlike new iPhones, Apple Intelligence — meaning the best of Siri’s upgrade — will be a slower rollout. Apple says the first set of features will be available in beta next month, with more features rolling out in the coming months. U.S. English will initially be supported, followed by localized English for Australia, Canada, New Zealand, South Africa and the U.K. Sometime next year, it will reach users who speak Chinese, French, Japanese and Spanish before expanding to others.Other Apple Intelligence features like Writing Tools, Mail and Notifications summaries, and a Clean Up tool in Photos will also arrive in beta starting next month across iOS 18.1, iPadOS 18.1, and macOS Sequoia 15.1.Apple Intelligence will superpower SiriWhen Apple Intelligence arrives, Siri will be able to help with questions and commands that deal with its understanding of you and your needs. It will gain a better understanding of your personal context, allowing you to reference things like a song you streamed, an email you reviewed, a calendar appointment, or a text, for instance, instead of only responding to simple commands like “call Mom.” That means you’ll be able to ask Siri about your meeting and what the weather will be like at the meeting’s location, too, or do something like instructing it to send an email you had drafted.Image Credits: Apple“With Siri’s personal context, understanding and action capabilities, you’ll be able to simply say, ‘Send Erica the photos from Saturday’s barbecue,’ and Siri will dig up the photos and send them right off with new ways to express yourself and read them memories, along with tools to help you prioritize and focus so you can get more done,” noted Apple SVP of Software Engineering, Craig Federighi, at today’s iPhone announcement. “Apple intelligence is going to transform so much of what you do with iPhone. Apple Intelligence will be available as a free software update,” he said.Siri will also be able to offer tech support, as its understanding of your Apple products, features, and functionality will be improved. Image Credits: AppleIt will be able to help you in other ways an assistant could, too, by way of its on-screen awareness.For instance, you’ll be able to tell Siri to add a friend’s address to their contact card after they text it to you, or ask it to edit a photo with a filter or drop that photo into another app. If a friend texts you about a new album, you can say “play that.” You could also add a set of photos to an album using Siri, or send them to a friend. And you can have Siri summarize a transcript of a recording.Image Credits: Apple (screenshot)On iPhone 16 Pro models, Apple suggests that Siri’s new capabilities will be great for photographers, who will be able to ask Siri to pull up a specific shot from their library and then apply the Edit to the photo in an app like Darkroom, or even use Siri to quickly get suggestions on “how to enhance the space and achieve their vision,” the company said on Monday.Image Credits: AppleThe bigger Siri upgrade, however, may not come directly from Apple, but from OpenAI, announced earlier this year at Apple’s Worldwide Developers Conference.With the arrival of Apple Intelligence, Siri users will have the option to pose their questions related to “world knowledge” to ChatGPT instead of being frustratingly directed to the web for those questions it can’t answer.Image Credits: AppleThe partnership with OpenAI helps Apple get ahead in the AI race, where it’s perceived to have fallen behind, but without taking on the responsibility or the reputational hit that comes from when AI gets things wrong or hallucinates an answer. In time, Apple is expected to announce more AI partners as well.","AI, Apple, Apple event 2024, Apps, siri",,,,43
"AI-powered visual search comes to the iPhone","Kyle Wiggers",2024-09-09,https://techcrunch.com/2024/09/09/ai-powered-visual-search-comes-to-the-iphone/,"Visual intelligence will launch along with other Apple Intelligence features in beta in October for U.S. English language users.","Visual search is coming to the iPhone, powered by Apple Intelligence, Apple’s suite of AI capabilities, the company announced at Monday’s Apple Event 2024.The Camera Control, the new button on the iPhone 16 and 16 Plus, can launch what Apple calls “visual intelligence” — basically a reverse image search combined with some text recognition.If you use visual intelligence to search for a restaurant, for example, it’ll pull up restaurant hours, ratings and options to check out the menu or make a reservation, Apple says. Or, if you come across a flier for an event, you can use visual intelligence to quickly add the title, time, date and location to your calendar.Search info will be sourced from Google Search. Apple says the feature will respect your privacy, and that its services will never store your images.Through Apple’s partnership with OpenAI, you’ll also be able to use the new Camera Control button on iPhone 16 models to send the query off to ChatGPT instead. Apple suggests the feature could be used when stuck on a homework assignment, as one example.Visual intelligence will launch along with other Apple Intelligence features in beta in October for U.S. English language users. Users in other countries can expect to get it in December and early 2025.","AI, AI, Apple, Apple event 2024, Apple Intelligence, Generative AI, Hardware, visual intelligence",,,,44
"Apple says AirPods Pro 2 can be used as ‘clinical-grade’ hearing aids","Kyle Wiggers",2024-09-09,https://techcrunch.com/2024/09/09/apple-says-airpods-pro-2-can-be-used-as-clinical-grade-hearing-aids/,"Both the hearing aid feature for AirPods Pro 2 and the hearing test for iOS 18 will launch this fall via a software update in over 100 countries and regions.","Apple says that the AirPods Pro 2, its latest flagship wireless earbuds, can be used as “clinical-grade” hearing aids. The feature hasn’t been FDA-cleared, however, although the company says that it expects approval “soon.” The new AirPods were announced at the Apple “It’s Glowtime” event.The hearing aid feature, when enabled, boosts specific sounds in real time, like parts of speech or elements of an environment. It also applies a personalized hearing profile (more on that below) to music, movies and phone calls across devices. Apple says this will allow wearers to better hear their surroundings and engage in conversations.Image Credits: AppleIn a related announcement, Apple previewed a five-minute certified hearing test coming to iOS 18 and AirPods Pro 2 that’ll allow users to check their current hearing health. The test, which has users tap on their smartphone’s screen after they hear a series of tones at different volumes and frequencies, builds on learnings from Apple’s hearing studies, and was developed using “large-scale real-world data,” Apple says.After taking a hearing test, you’ll get results in a personalized hearing profile (which the aforementioned hearing aid feature uses). The results will be stored in Apple’s Health app, where they can optionally be shared with a healthcare provider.The hearing profile can be applied in tandem with a feature called Media Assist to boost certain parts of speech on a phone call or instruments within a soundtrack. Apple claims that users with little-to-no hearing loss can still benefit from the adjustments at individual frequencies.Both the hearing aid feature for AirPods Pro 2 and the hearing test for iOS 18 will launch this fall via a software update in over 100 countries and regions.","AI, airpods 2, AirPods Pro 2, Apple, Apple event 2024, Biotech & Health, Hardware, hearing aids, hearing test",,,,45
"US, China and other nations convene in Seoul for summit on AI use in military","Kyle Wiggers",2024-09-09,https://techcrunch.com/2024/09/09/u-s-china-and-other-nations-convene-in-seoul-for-summit-on-ai-use-in-military/,"More than 90 nations, including the U.S. and China, will convene at a two-day summit in Seoul starting Monday to attempt to establish a blueprint for the use of AI…","More than 90 nations, including the U.S. and China, will convene at a two-day summit in Seoul starting Monday to attempt to establish a blueprint for the use of AI in the military.As Reuters reports, participants hope to establish minimum guardrails and suggest principles for “responsible” AI deployment aligned with NATO principles.The summit is the second such event of its kind, following a gathering in Amsterdam in 2023 where countries committed to a “call to action” on military AI use. The topic has taken on new urgency as nations like Ukraine show an eagerness to adopt AI-powered drones and other autonomous weaponry.Some countries have shown a willingness to consider international limits on AI that could do harm. Last week, the U.S., Britain and the EU signed the world’s first international AI treaty, which focuses on the defense of human rights of people affected by AI.","AI, AI, government, Government & Policy, In Brief, military, policy, Seoul",,,,46
"Apple Event 2024: iPhone 16, Apple Intelligence and all the other expected ‘Glowtime’ reveals","Brian Heater",2024-09-09,https://techcrunch.com/2024/09/09/apple-event-2024-iphone-16-apple-intelligence-and-all-the-other-expected-glowtime-reveals/,"Apple’s Glowtime iPhone event will include the iPhone 16, but may also feature new AirPods, a new Apple Watch and possibly even new Macs.","As ever, additional rumors have popped up in the days leading up to the event. Among the more interesting of recent vintage (all Apple Watch-related): The Apple Watch Series 10’s blood pressure monitoring is not coming to the Watch Ultra 2, and there are limited Apple Intelligence features for the Watch, though it will be baked into a future fitness coach-style feature. Both models are reportedly getting that sleep apnea feature, though it likely won’t be available at launch.Apple will reveal the iPhone 16 at its September 9 “It’s Glowtime” event; this much we can tell you for certain. But Apple doesn’t invite us to fly across the country for a single product — not to mention booking a hotel room on the 49ers opening day. Football aside, the timing of the annual event is important, as it’s one last major opportunity to announce a bunch of hardware ahead of the holidays.The livestream kicks off on Monday at 10 a.m. PT. The invites dropped last week with the “Glowtime” tagline and a color scheme to match. Apple loves to sprinkle small hints into these graphics, and this one appears more on the nose than most.Apple Intelligence and SiriBack at WWDC in June, Apple finally revealed its approach to generative AI. The offering is an extremely Apple approach, right down to the name — Apple Intelligence — which happily hijacks the familiar AI initialism. The “small model” method is emblematic of the company in the sense that it’s trained on limited data relevant to improving the user experience.That’s a marked difference between it and much larger “black box” models like OpenAI’s and Google’s Gemini. The efficacy of the approach remains to be seen, as we wait for Apple Intelligence’s wider release. It will almost certainly be a work in progress, as — at the very least — all generative AI is, at the end of the day.The answer to how this all ties into “Glowtime” can be found in Siri. In June, Apple announced a much-needed glow-up for the O.G. smart assistant. Along with generative AI models and better app integration, the company revealed an updated interface. Gone is the familiar colorful Siri circle, swapped out for a glowing border that surrounds the display when Siri is listening/processing.Out of every iPhone ever launched, two models will be able to run Apple Intelligence: the iPhone 15 Pro and iPhone 15 Pro Max. According to the company, that’s due to limitations with older chips. Given that non-Pro iPhone 15 models are effectively running the iPhone 14 Pro’s chipset, Apple can credibly make the argument that only one of its chips so far was built with Apple Intelligence in mind. You can decide for yourself whether you think the exclusion of the iPhone 15 is entirely a hardware matter.With all of this in mind, the event is the perfect chance to announce that Apple Intelligence will be available across the new iPhone line. But Bloomberg’s Mark Gurman warns that Apple Intelligence delays could affect the iPhone 16’s bottom line.iPhone 16, 16 Pro and 16 Pro MaxImage Credits: Stanislav Kogiku / SOPA Images / LightRocket / Getty ImagesThe iPhone 16 Pro Max is expected to feature the thinnest bezels on a smartphone 🔥 pic.twitter.com/rK9LEugcb1— Apple Hub (@theapplehub) September 1, 2024We’re heading toward the promise of true edge-to-edge displays millimeter by millimeter. According to one recent leak, the iPhone 16 Pro Max may get an even larger display, courtesy of smaller bezels, moving from 1.5mm to 1.4mm. So, what’s a few fractions of a millimeter between friends? A lot when you’re talking about a total size of under 2mm, turns out.That will reportedly bump the Pro Max’s screen size from 6.69 to 6.86 inches, without increasing the device’s overall footprint by some unwieldy amount. The iPhone 15 Pro Max is already a big phone. The iPhone 16 Pro, meanwhile, is said to be making the leap from 6.12 to 6.27 inches.Camera improvements are a no-brainer for annual updates. The most interesting of the bunch is a new glass molded lens that is thinner and lighter, while dramatically increasing optical zoom capabilities. Optical zoom capabilities are worth paying attention to, as they don’t suffer from the same sort of image degradation issues as their digital counterpart.pic.twitter.com/GiIWNkXcI8— Sonny Dickson (@SonnyDickson) April 4, 2024Leaked dummy models from early in the year give us a rough idea of each model’s design. Most notable on the 16 and 16 Plus is the shift from a diagonal to a vertical camera setup. The models, which are designed for third parties to get a jumpstart on accessories, feature the addition of a new “Capture” button across the line. The new feature is designed to provide quick access to different camera capabilities.The most welcome change, however, may be bigger batteries. Screen and camera improvements are all well and good, but battery life remains a struggle. This particular report could use more substantiating, so take that with an even larger grain of salt than usual. Additional reports, meanwhile, have pointed to Apple making battery replacements more accessible for users. Given that the company has begun offering home repair options as more governments and localities pass right-to-repair laws, this one certainly tracks.The Pro models are also expected to gain Wi-Fi 7, which would be a big boon for the latest wireless standard.Apple Watch Series 10/Ultra 3Image Credits: AppleAs hard as it is to believe, the Apple Watch turns 10 this year. They grow up so quickly. Apple made a big splash with the iPhone X, so it follows that it’d have something similar planned for the Apple Watch Series 10 (Series X?). Earlier rumors pointing to a significant redesign have cooled in recent months, making way for a familiar design with a larger display, bumping up to 45mm and 49mm models. The new watch should also be slimmer than its predecessor — something especially important when discussing a watch.Like the iPhone 16, the Apple Watch Series 10 and Ultra 3 should get a new processor — the S10, one imagines. That could mean that additional AI functionality isn’t far out. A glucose monitor is the most exciting rumored addition. Sleep apnea detection is also rumored for the device, but as Bloomberg notes, Apple’s legal woes with Masimo may well trip up that feature.A long-awaited update to the budget Apple Watch SE with a plastic body could also appear.AirPods 4Image Credits: AppleStay with me on this one. Apple is reportedly announcing two versions of the AirPods 4. The cheaper model will replace the still-available AirPods 2, and the more premium version will replace the AirPods 3. Still with me? The more premium model is set to blur the line between it and the AirPods Pro, by adding Active Noise Cancelation and Find My features. All of the models should also finally ditch Lightning for USB-C, as the company transitions its products to comply with EU mandates.So, how will Apple maintain a clear line between the mid-tier and Pro pods? We’ll have to wait on the answer to that one, as we’re not expecting new AirPods Pro. We may, however, finally get the over-ear AirPods Max 2, four years after the original.New MacsImage Credits: Brian HeaterThis one is a big maybe. Recent reporting suggests that Apple will hold off on announcing M4 macs until November. Supply chain issues have been dictating the Mac’s release calendar ever since the pandemic. A big, USB-A-less version of the Mac Mini is said to be arriving before the end of the year, along with a new iMac and MacBook Pro.Glow with the flowImage Credits: AppleHere’s what we can say for sure: Apple’s Glowtime event is scheduled for Monday, September 9 at 10 a.m. PT. As always, we’ll be there, bringing it to you live.Updated with further information on September 9.","AI, Apple, Apple event 2024, Apple Intelligence, apple iphone 16 event, apple watch series 10, Hardware, iphone 16, iPhone Event 2024",,,,47
"Miami-based AI bookkeeping startup Finally has raised another big round: $200M in equity and debt","Mary Ann Azevedo",2024-09-09,https://techcrunch.com/2024/09/09/miami-based-ai-bookkeeping-startup-finally-has-raised-another-big-round-200m-in-equity-and-debt/,"The SMB-focused bookkeeping, accounting and finance startup Finally has raised $50 million in a Series B round of funding and secured a $150 million credit line, TechCrunch is the first…","The SMB-focused bookkeeping, accounting and finance startup Finally has raised $50 million in a Series B round of funding and secured a $150 million credit line, TechCrunch is the first to report.The financing comes just seven months after the fintech company announced it had raised $10 million in funding, and brings Miami-based Finally’s total raised since its 2018 inception to $305 million in debt ($235 million in credit facilities) and equity ($74 million).Felix Rodriguez came up with the idea for Finally after seeing his Dominican Republican-born family start their own businesses in the United States. He’d also experienced his own challenges firsthand when starting his own companies, and concluded that not all small businesses were on a level playing field when it came to bookkeeping and working capital. So in 2018, after also having worked as a network engineer, Rodriguez and his wife, Glennys Rodriguez, began helping small and mid-sized businesses manage their finances. The couple then teamed up with Edwin Mejia to start Finally. The company’s offering has evolved over time and today, finally offers AI-powered bookkeeping as well as accounting and financial services. It also offers a corporate card with insights into spending and last year, it added an artificial intelligence-powered ledger that offered business banking functions. In some respects, Finally competes with the likes of Brex and Ramp as it offers expense management and a corporate card. But the company maintains it’s “a multi-product platform” that, for example, also offers payroll processing.“Finally is especially useful for SMB owners that don’t have time to learn 20 different apps for their bookkeeping and finance functions,” Felix Rodriguez said. “SMB owners have many priorities and often limited time. But one of the most important parts of running a business is understanding financial metrics, including cash burn and cash flow.”Since announcing its $95 million Series A in March of 2022, Finally says it has seen annual revenue growth of 300%, although it declined to reveal hard figures. The company serves over 1,500 business in the United States, and makes money through a combination of SaaS subscription fees, interchange fees and interest income. Finally also declined to share its valuation, saying only the Series B was “an up round.”PeakSpan provided the equity portion of the raise while Encina is offering the $150 million credit facility. The company plans to deepen its investment in sales and marketing and add new features such as a module for global hiring in its hiring product and more support for payments on the finance side.It also plans to keep hiring. Presently, Finally has more than 220 employees, up from 95 this time last year. Among its hires this year was the appointment of Roy Duvall, former CTO at Calendly, to serve as its chief technology officer.Jack Freeman, partner at PeakSpan Capital, said his firm had been evaluating the bookkeeping automation space for “several years” prior to meeting Rodriguez. The firm also provided capital in Finally’s $10 million raise earlier this year.“We immediately fell in love with his ‘all-in-one’ vision,” he told TechCrunch. “While other spend management software providers are focused on building out software features, Finally understands intuitively that software is only as valuable as the data you can feed it.”Finally, he said, ingests data, integrates with other software and offers embedded credit products alongside software products in an effort to serve as a “one-stop shop” for an SMB.Finally is not the only startup in this space to raise a significant amount as of late. In June, AccountsIQ, a Dublin-founded accounting technology company, raised €60 million (about $65 million) to build “the finance function of the future” for midsized companies: cloud-based, automated services boosted by AI to help accounting departments work faster and more intelligently. And Pennylane, another accounting startup that focuses on the SMB market, raised $40 million at a valuation of over $1 billion in February.Want more fintech news in your inbox? Sign up for TechCrunch Fintech here.Want to reach out with a tip? Email me at maryann@techcrunch.com or send me a message on Signal at 408.204.3036. You can also send a note to the whole TechCrunch crew at tips@techcrunch.com. For more secure communications, click here to contact us, which includes SecureDrop and links to encrypted messaging apps.","AI, bookkeeping, Exclusive, Finally, Fintech, fintech software, North America, PeakSpan Capital, Startups",,,,48
"Apple Intelligence delays could impede iPhone 16 ‘supercycle’","Brian Heater",2024-09-08,https://techcrunch.com/2024/09/08/apple-intelligence-delays-could-impede-iphone-16-supercycle/,"When Apple unveiled its AI plans at WWDC in June, analysts suggested the feature could put the iPhone 16 on track for another “supercycle.” Like the addition of 5G before…","When Apple unveiled its AI plans at WWDC in June, analysts suggested the feature could put the iPhone 16 on track for another “supercycle.” Like the addition of 5G before it, industry watchers believed that Apple Intelligence’s arrival might convince holdouts to bite the bullet and upgrade their device.We’ll have a much better picture when the company reveals the iPhone 16 at tomorrow’s “It’s Glowtime” event in Cupertino. In the meantime, however, it’s believed that Apple Intelligence’s slow rollout could significantly hamper supercycle potential.In June, Apple showed the world a take on AI firmly in-line with its mission statement of prioritizing user experience. Trained on small models — instead of the massive black boxes behind services like Google Gemini and OpenAI’s ChatGPT — Apple’s play is centered around improving existing experiences through generative AI.As Bloomberg notes today, however, delays could impact the iPhone 16’s bottom line. WWDC offered a lot of big promises, but we’re unlikely to see many delivered until 2025. Regional limitations present key roadblocks as well, including in the EU and China — the latter of which can make or break Apple financials in any given quarter. ChatGPT integration, meanwhile, is also unlikely for launch.In the lead up to WWDC, the industry wondered whether Apple would be able to become a major player with the generative AI competition. But while the developer conference wowed observers with impressive demos, there’s still a lot of catching up to do.At the time of writing, iPhone 15 Pro/Pro Max are the only devices approved to run Apple Intelligence. Tomorrow’s event is set to change that, especially as further rumors point to increased uniformity across the iPhone 16 line. The base models are expected to get A18 chips, with the Pros, fittingly, getting an A18 Pros.While sales are incredibly important to Apple and its shareholders, Apple Intelligence is a massive, multi-faceted undertaking, and rushing it out too early could have a longer term adverse impact on the company’s bottom line than a staggered rollout.","AI, Apple, Apple event 2024, Apple Intelligence, Gadgets, Hardware, iphone 16",,,,49
"Elon Musk says Tesla has ‘no need’ to license xAI models","Anthony Ha",2024-09-08,https://techcrunch.com/2024/09/08/elon-musk-says-tesla-has-no-need-to-license-xai-models/,"Elon Musk has denied a report that one of his companies, Tesla, has discussed sharing revenue with another of his companies, xAI, so that it can use the startup’s AI…","Elon Musk has denied a report that one of his companies, Tesla, has discussed sharing revenue with another of his companies, xAI, so that it can use the startup’s AI models.The Wall Street Journal wrote that under a proposed agreement described to investors, Tesla would use xAI models in its driver-assistance software (known as Full Self-Driving or FSD). The AI startup would also help develop features such as a voice assistant in Tesla vehicles and software for Tesla’s humanoid robot Optimus.Writing on his social media platform X (formerly Twitter), Musk said he hadn’t read the WSJ story, but he described a post summarizing the report as “not accurate.”“Tesla has learned a lot from discussions with engineers at xAI that have helped accelerate achieving unsupervised FSD, but there is no need to license anything from xAI,” he wrote. “The xAI models are gigantic, containing, in compressed form, most of human knowledge, and couldn’t possibly run on the Tesla vehicle inference computer, nor would we want them to.”Musk founded xAI as a competitor to OpenAI (which he co-founded but eventually left). TechCrunch reported earlier this year that as part of the pitch for xAI’s $6 billion funding round, the startup outlined a vision where its models would be trained on data from Musk’s various companies (Tesla, SpaceX, The Boring Company, Neuralink and X), and its models could then improve technology across those companies.Tesla shareholders have sued Musk over the decision to start xAI, arguing that Musk has diverted talent and resources from Tesla to what is essentially a competing company.Haven’t read the article, but the above is not accurate. Tesla has learned a lot from discussions with engineers at xAI that have helped accelerate achieving unsupervised FSD, but there is no need to license anything from xAI.The xAI models are gigantic, containing, in…— Elon Musk (@elonmusk) September 8, 2024","AI, Elon Musk, Robotics, Startups, TC, Tesla, Transportation, xAI",,,,50
"Meta Llama: Everything you need to know about the open generative AI model","Kyle Wiggers",2024-09-08,https://techcrunch.com/2024/09/08/meta-llama-everything-you-need-to-know-about-the-open-generative-ai-model/,"Like other generative AI models, Llama can perform a range of different assistive tasks, like coding and answering basic math questions, as well as summarizing documents in eight languages.","Like every Big Tech company these days, Meta has its own flagship generative AI model, called Llama. Llama is somewhat unique among major models in that it’s “open,” meaning developers can download and use it however they please (with certain limitations). That’s in contrast to models like Anthropic’s Claude, OpenAI’s GPT-4o (which powers ChatGPT) and Google’s Gemini, which can only be accessed via APIs.In the interest of giving developers choice, however, Meta has also partnered with vendors, including AWS, Google Cloud and Microsoft Azure, to make cloud-hosted versions of Llama available. In addition, the company has released tools designed to make it easier to fine-tune and customize the model.Here’s everything you need to know about Llama, from its capabilities and editions to where you can use it. We’ll keep this post updated as Meta releases upgrades and introduces new dev tools to support the model’s use.What is Llama? Llama is a family of models — not just one:Llama 8BLlama 70BLlama 405BThe latest versions are Llama 3.1 8B, Llama 3.1 70B and Llama 3.1 405B, which was released in July 2024. They’re trained on web pages in a variety of languages, public code and files on the web, and synthetic data (i.e., data generated by other AI models).Llama 3.1 8B and Llama 3.1 70B are small, compact models meant to run on devices ranging from laptops to servers. Llama 3.1 405B, on the other hand, is a large-scale model requiring (absent some modifications) data center hardware. Llama 3.1 8B and Llama 3.1 70B are less capable than Llama 3.1 405B, but faster. They’re “distilled” versions of 405B, in point of fact, optimized for low storage overhead and latency.All the Llama models have 128,000-token context windows. (In data science, tokens are subdivided bits of raw data, like the syllables “fan,” “tas” and “tic” in the word “fantastic.”) A model’s context, or context window, refers to input data (e.g., text) that the model considers before generating output (e.g., additional text). Long context can prevent models from “forgetting” the content of recent docs and data, and from veering off topic and extrapolating wrongly.Those 128,000 tokens translate to around 100,000 words or 300 pages, which for reference is around the length of “Wuthering Heights,” “Gulliver’s Travels” and “Harry Potter and the Prisoner of Azkaban.”What can Llama do? Like other generative AI models, Llama can perform a range of different assistive tasks, like coding and answering basic math questions, as well as summarizing documents in eight languages (English, German, French, Italian, Portuguese, Hindi, Spanish and Thai). Most text-based workloads — think analyzing files like PDFs and spreadsheets — are within its purview; none of the Llama models can process or generate images, although that may change in the near future.All the latest Llama models can be configured to leverage third-party apps, tools and APIs to complete tasks. They’re trained out of the box to use Brave Search to answer questions about recent events, the Wolfram Alpha API for math- and science-related queries, and a Python interpreter for validating code. In addition, Meta says the Llama 3.1 models can use certain tools they haven’t seen before (but whether they can reliably use those tools is another matter).Where can I use Llama?If you’re looking to simply chat with Llama, it’s powering the Meta AI chatbot experience on Facebook Messenger, WhatsApp, Instagram, Oculus and Meta.ai.Developers building with Llama can download, use or fine-tune the model across most of the popular cloud platforms. Meta claims it has over 25 partners hosting Llama, including Nvidia, Databricks, Groq, Dell and Snowflake. Some of these partners have built additional tools and services on top of Llama, including tools that let the models reference proprietary data and enable them to run at lower latencies.Meta suggests using its smaller models, Llama 8B and Llama 70B, for general-purpose applications like powering chatbots and generating code. Llama 405B, the company says, is better reserved for model distillation — the process of transferring knowledge from a large model to a smaller, more efficient model — and generating synthetic data to train (or fine-tune) alternative models.Importantly, the Llama license constrains how developers can deploy the model: App developers with more than 700 million monthly users must request a special license from Meta that the company will grant on its discretion.What tools does Meta offer for Llama?Alongside Llama, Meta provides tools intended to make the model “safer” to use: Llama Guard, a moderation frameworkPrompt Guard, a tool to protect against prompt injection attacksCyberSecEval, a cybersecurity risk assessment suiteLlama Guard tries to detect potentially problematic content either fed into — or generated — by a Llama model, including content relating to criminal activity, child exploitation, copyright violations, hate, self-harm and sexual abuse. Developers can customize the categories of blocked content and apply the blocks to all the languages Llama supports out of the box.Like Llama Guard, Prompt Guard can block text intended for Llama, but only text meant to “attack” the model and get it to behave in undesirable ways. Meta claims that Llama Guard can defend against explicitly malicious prompts (i.e., jailbreaks that attempt to get around Llama’s built-in safety filters) in addition to prompts that contain “injected inputs.”As for CyberSecEval, it’s less a tool than a collection of benchmarks to measure model security. CyberSecEval can assess the risk a Llama model poses (at least according to Meta’s criteria) to app developers and end users in areas like “automated social engineering” and “scaling offensive cyber operations.”Llama’s limitationsLlama comes with certain risks and limitations, like all generative AI models. For instance, it’s unclear whether Meta trained Llama on copyrighted content. If it did, users might be liable for infringement if they end up unwittingly using a copyrighted snippet that the model regurgitated.Meta at one point used copyrighted e-books for AI training despite its own lawyers’ warnings, according to recent reporting by Reuters. The company controversially trains its AI on Instagram and Facebook posts, photos and captions, and makes it difficult for users to opt out. What’s more, Meta, along with OpenAI, is the subject of an ongoing lawsuit brought by authors, including comedian Sarah Silverman, over the companies’ alleged unauthorized use of copyrighted data for model training.Programming is another area where it’s wise to tread lightly when using Llama. That’s because Llama might — like its generative AI counterparts — produce buggy or insecure code.As always, it’s best to have a human expert review any AI-generated code before incorporating it into a service or software.","AI, AI, Apps, Enterprise, evergreens, Explainer, Generative AI, Llama, Meta, meta ai, model, Social",,,,51
"How a viral AI image catapulted a Mexican startup to a major Adidas contract","Mary Ann Azevedo",2024-09-07,https://techcrunch.com/2024/09/07/how-a-viral-ai-image-catapulted-a-mexican-startup-to-a-major-adidas-contract/,"Antonio Nuño, Fatima Alvarez, and Enrique Rodriguez have been friends since they were five years old. As teenagers, they became volunteers helping indigenous communities — first in Mexico, then in other countries — and saw that many of the women were artisans.  The trio came to realize that these artists…","Antonio Nuño, Fatima Alvarez, and Enrique Rodriguez have been friends since they were five years old. As teenagers, they became volunteers helping indigenous communities — first in Mexico, then in other countries — and saw that many of the women were artisans. The trio came to realize that these artists “made very beautiful things in a very sustainable way,” Nuño recalls, and by the time they were 25, the idea for a business had germinated. They imagined connecting these artists, “their techniques and their stories with the supply chains of global companies looking for more sustainable ways to create products.”So in 2016, Someone Somewhere was born. Today the Mexico City-based startup works with hundreds of rural artisans in seven of Mexico’s poorest states to apply traditional handcrafts on clothing and accessories, with the mission of creating “quality, on-trend products.” Someone Somewhere helps artisan groups organize as cooperatives or small businesses, formalize, access a bank account, and build communitary savings accounts. The artisans are paid for each product they make. The startup supplies the materials, and pays 50% in advance and 50% once they finish each product.A viral postIn its first few years, Someone Somewhere landed contracts with some larger companies such as Ben & Frank (the Warby Parker of Latin America) and Rappi. But in 2023, the trio realized they could use AI — particularly Stable Diffusion’s text to images model — to help the company scale even further.They fed their databases all the various materials and techniques the artisans used into Stable Diffusion’s model and began designing AI-assisted concepts, produced as images, of well-known products. The idea was to “show companies how some of their most iconic items could look if they were made with artisans from different regions.”They posted the concepts on LinkedIn, tagging the companies. For example, they created images for Red Bull and Trader Joe’s. But it was when they posted their concept of an Adidas-branded Mexican National Team soccer jersey on LinkedIn in March that their business changed forever. That post went viral, ultimately receiving more than 1 million views, with people tagging Adidas employees for visibility.In the post, Nuño estimated that each shirt would “generate six months of fair work for more than 3,000 artisans” and “allow more than 15,000 people, including families, to break the cycle of poverty.”He wrote: “We can imagine what would happen if Mexico’s next jersey was made in collaboration with Someone Somewhere, and incorporated elements hand-embroidered by various communities in the country. It would be the first time that a national team launches such an initiative, and it would undoubtedly inspire dozens of other countries to replicate it since crafts are the second largest source of employment in all of Latin America, Africa and Asia.” Image Credits: Someone SomewhereJust one day after the post went up, Nuño says that Adidas reached out and asked for a meeting. Within weeks, his company had an agreement to launch a physical product made available to adiClub members, as well as to Mexican soccer players and content creators.All told, the marketing post reached more than 50 million people, and was covered on national TV and over 100 media outlets, according to Nuño. On June 21, the companies announced the new collection of Mexican National Team jerseys, hand-embroidered by women artisans from the Sierra Norte of Puebla, Mexico. Each shirt represented more than 11 hours of hand-embroidery work, symbolically representing the 11 players who proudly represented Mexico in the Copa América.“Through these jerseys, both Adidas and Someone Somewhere seek to honor the work of Mexican artisans and continue embracing the cultural heritage of the country, both its roots and the seeds it leaves for future creative generations,” said Pablo Cavallaro, senior director, Brand Activation at Adidas, in a statement. “This collection is inspired by the communities where the artisans create each of their pieces, the space they call ‘home’.” The shirts available to the public include Someone Somewhere’s signature detail: a QR code so that the user/purchaser can learn more about the artisan who helped create it.“Now we are working on more things with Adidas that we will launch next year,” Nuño said.AI helps create jobsNuño credits advances in AI for his startup’s recent growth.“We found that creating products with AI shows companies the potential so it’s easier to move forward,” Nuño told TechCrunch. “It has allowed us to develop partnerships with a lot of companies, based in the U.S. mostly,” The strategy is working so well that Someone Somewhere went from designing 10 products a month to 5,000.“This has helped us accelerate, and it’s an amazing way of showing that AI can take away jobs but also create them, if used creatively,” he added. “Just in the last 12 months alone, we’ve made more than 10 million products with this model.”Meanwhile, Someone Somewhere’s revenue has grown 36x in the last three years. This year, the 75-person team is working with triple the number of brands than it did last year, in large part thanks to the use of AI to co-create products.The Stable Diffusion model that Someone Somewhere is using came out last year and allows users to fine-tune the concept images it creates.“You can control the silhouettes of products,” Nuño said, adding that this allows his startup to experiment with fabrics and embroideries when developing a concept product. “Before our main bottleneck was showing companies the potential of what we could do together. We had to make physical products, which takes a lot of time. This technology opens doors — they say an image is more than a thousand words. Now we’re able to connect with these big brands and that makes the conversation go way faster,” he said.That’s led Someone Somewhere to deals like a co-branded sustainable accessories line with Gator Cases, and with companies such as Google, Uber, Stripe and Amazon (among others) to make merchandise for their employees, events and marketing campaigns.QR codes land a deal with an Apple supplierAI is not the only thing responsible for Someone Somewhere’s growth.The company also accidentally landed a deal, through its use of those QR codes, that placed some of its products in Apple stores worldwide and online. The products are made through a partnership with a company called Nimble, which makes sustainable electronic accessories. Someone Somewhere sells its products to Nimble, which in turn sells it to Apple.Nimble CEO and co-founder Ross Howe is a Delta One business class customer, and on a flight last year the airline gave him an amenity kit made by Someone Somewhere.“The items were neatly packed in this fabric bag, which immediately caught my attention,” he recounts. “It was very high-quality, and had a QR code to meet the artisan who made it. By the time the plane landed, I learned everything I could about the company behind it, and wanted to explore an opportunity to work with them.”Nimble already had some concepts for new products that included a carrying case but “just needed the right partner to help create it,” Howe said. “Aside from their apparent design capabilities, Someone Somewhere’s mission and status as a fellow Certified B Corp checked so many boxes for what we look for in a partner.”So the company reached out to learn more.Today, its new Apple-exclusive collection features a series of PowerKnit Travel Kits with USB-C charging cables. Each includes a travel case made in collaboration with Someone Somewhere. The pouches are being sold in Apple stores in 30 countries, including the U.S. and most of Europe.“After years of researching potential companies to collaborate on this type of project, we hadn’t come across anything quite like what Someone Somewhere is doing,” Howe said. “We are exploring additional projects for potential future release.”All of this growth has come after raising a total of just $1.7 million in funding from investors such as Impact Ventures PSM, Dila Capital, GBM Ventures, Kalei Ventures, Louis Jordan, Soldiers Field Angels, and Unreasonable Capital, so far. Someone Somewhere has been profitable since 2022, and is in the process of raising a new round “to take advantage of the nearshoring and sustainable procurement trends that are clearly growing,” Nuño said.","Adidas, AI, Exclusive, Mexico, Mexico, Someone Somewhere, Startups",,,,52
"TechCrunch Minute: Canva faces backlash over price hikes","Anthony Ha",2024-09-06,https://techcrunch.com/video/techcrunch-minute-canva-faces-backlash-over-price-hikes/,"Some Canva customers are experiencing serious sticker shock, while the company is pointing to new AI features to justify the price hike. The company has…","Some Canva customers are experiencing serious sticker shock, while the company is pointing to new AI features to justify the price hike.The company has established itself as a simpler, more affordable alternative to legacy design software, but the “more affordable” part of the equation is becoming a little less true, with some Canva Teams subscribers seeing their pricing go from $120 per year to $500 per year — an increase of 300%.There’s a little bit of a cushion there, because Canva says it will apply a 40% discount for the first 12 months, but you’re still going to see the full increase on the horizon. (Also, the increases only apply to Canva Teams accounts, not Pro or Enterprise customers.)A company spokesperson told TechCrunch that some customers had been locked into more affordable plans that Canva already stopped offering, while the company increased prices to “reflect our expanded product experience.”On today’s TechCrunch Minute, we discuss why Canva’s prices have gone up, the broader business pressures the company might be facing and why some customers are upset.","AI, canva, Startups, TechCrunch Minute, the techcrunch minute",,,,53
"The New Data Pipeline: Fivetran, DataStax and NEA are coming to TechCrunch Disrupt 2024","TechCrunch Events",2024-09-06,https://techcrunch.com/2024/09/06/the-new-data-pipeline-fivetran-datastax-and-nea-are-coming-to-techcrunch-disrupt-2024/,"In the world of modern AI, data is more than just a resource — it’s the fundamental core that aligns decision-makers, supports processes and enables innovation. As AI applications become…","In the world of modern AI, data is more than just a resource — it’s the fundamental core that aligns decision-makers, supports processes and enables innovation. As AI applications become more robust and pervasive, the pace of such advancement is only as good as the evolution of the data infrastructure behind it. We are delighted to discuss the data deluge with industry experts George Fraser, CEO of Fivetran; Chet Kapoor, chairman and CEO of DataStax; and Vanessa Larco, partner at NEA, live on the SaaS Stage at TechCrunch Disrupt 2024. The panel will dive deep into the shift from mere data accumulation to meaningful integration, exploring how businesses are building, managing, securing and scaling their data infrastructures. They’ll share insights on what’s on the horizon for data evolution and the strategies companies need to employ to stay ahead in a data-driven world.Meet the AI leaders transforming data into actionable intelligenceGeorge Fraser, CEO of FivetranUnder Fraser’s leadership, Fivetran has revolutionized data integration by making it as simple and reliable as turning on a light switch. Born in Y Combinator, Fivetran now has data connectors that power businesses of all sizes, earning them accolades from Google Cloud and Snowflake. Fraser’s commitment to simplifying data access reflects his vision of a future where data flows seamlessly, enabling innovation across every industry.Chet Kapoor, Chairman and CEO of DataStaxWith deep roots in Silicon Valley’s most influential tech firms, Kapoor leads DataStax in its mission to help enterprises use data to scale AI in real time. From launching Astra DB, a cutting-edge cloud-native database, to advancing generative AI applications with new vector capabilities, Kapoor’s leadership has made DataStax a key player in the data revolution. Vanessa Larco, Partner at NEAA driving force at NEA, Larco brings a unique perspective to her role, believing in the power of passion and focus when building a company and leveraging her experience to invest in next-gen enterprise and consumer tech. She’s been instrumental in backing companies that are now redefining their industries, such as Rewind AI, Cleo and Rocket.Chat. With a background in product team leadership at Box, Disney, Xbox and Twilio, Larco has a hands-on approach and her ability to see the potential in companies and founders makes her a compelling voice on the future of data and tech innovation. Gain industry insights only at Disrupt 2024Join us at Disrupt 2024 to explore how these leaders are pushing the boundaries of what’s possible. You’ll learn why the next generation of AI isn’t just about better algorithms but about the smart, seamless flow of data that fuels them. And you can engage with the very people who are building the tools and frameworks that will power our data-driven future. Don’t miss out — secure your Disrupt 2024 pass today to get a front-row seat into tomorrow’s tech innovation.","AI, Startups, TC, TechCrunch Disrupt 2024",,,,54
"Sign or veto: What’s next for California’s AI disaster bill, SB 1047?","Maxwell Zeff",2024-09-02,https://techcrunch.com/2024/09/02/governor-newsom-must-weigh-the-future-of-californias-ai-industry-with-sb-1047/,"The tech industry has responded with a resounding outcry against SB 1047.","A controversial California bill to prevent AI disasters, SB 1047, has passed final votes in the state’s Senate and now proceeds to Governor Gavin Newsom’s desk. He must weigh the most extreme theoretical risks of AI systems — including their potential role in human deaths — against potentially thwarting California’s AI boom. He has until September 30 to sign SB 1047 into law, or veto it altogether.Introduced by state senator Scott Wiener, SB 1047 aims to prevent the possibility of very large AI models creating catastrophic events, such as loss of life or cyberattacks costing more than $500 million in damages.To be clear, very few AI models exist today that are large enough to be covered by the bill, and AI has never been used for a cyberattack of this scale. But the bill concerns the future of AI models, not problems that exist today.SB 1047 would make AI model developers liable for their harms — like making gun manufacturers liable for mass shootings — and would grant California’s attorney general the power to sue AI companies for hefty penalties if their technology was used in a catastrophic event. In the event that a company is acting recklessly, a court can order them to stop operations; covered models must also have a “kill switch” that lets them be shut down if they are deemed dangerous.The bill could reshape America’s AI industry, and it is a signature away from becoming law. Here is how the future of SB 1047 might play out.Why Newsom might sign itWiener argues that Silicon Valley needs more liability, previously telling TechCrunch that America must learn from its past failures in regulating technology. Newsom could be motivated to act decisively on AI regulation and hold Big Tech to account.A few AI executives have emerged as cautiously optimistic about SB 1047, including Elon Musk.Another cautious optimist on SB 1047 is Microsoft’s former chief AI officer Sophia Velastegui. She told TechCrunch that “SB 1047 is a good compromise,” while admitting the bill is not perfect. “I think we need an office of responsible AI for America, or any country that works on it. It shouldn’t be just Microsoft,” said Velastegui.Anthropic is another cautious proponent of SB 1047, though the company hasn’t taken an official position on the bill. Several of the startup’s suggested changes were added to SB 1047, and CEO Dario Amodei now says the bill’s “benefits likely outweigh its costs” in a letter to California’s governor. Thanks to Anthropic’s amendments, AI companies can only be sued after their AI models cause some catastrophic harm, not before, as a previous version of SB 1047 stated.Why Newsom might veto itGiven the loud industry opposition to the bill, it would not be surprising if Newsom vetoed it. He would be hanging his reputation on SB 1047 if he signs it, but if he vetoes, he could kick the can down the road another year or let Congress handle it.“This [SB 1047] changes the precedent for which we’ve dealt with software policy for 30 years,” argued Andreessen Horowitz general partner Martin Casado in an interview with TechCrunch. “It shifts liability away from applications, and applies it to infrastructure, which we’ve never done.”The tech industry has responded with a resounding outcry against SB 1047. Alongside a16z, Speaker Nancy Pelosi, OpenAI, Big Tech trade groups, and notable AI researchers are also urging Newsom to not sign the bill. They worry that this paradigm shift on liability will have a chilling effect on California’s AI innovation.A chilling effect on the startup economy is the last thing anyone wants. The AI boom has been a huge stimulant for the American economy, and Newsom is facing pressure not to squander that. Even the U.S. Chamber of Commerce has asked Newsom to veto the bill, saying “AI is foundational to America’s economic growth,” in a letter to him.If SB 1047 becomes lawIf Newsom signs the bill, nothing happens on day one, a source involved with drafting SB 1047 tells TechCrunch.By January 1, 2025, tech companies would need to write safety reports for their AI models. At this point, California’s attorney general could request an injunctive order, requiring an AI company to stop training or operating their AI models if a court finds them to be dangerous.In 2026, more of the bill kicks into gear. At that point, the Board of Frontier Models would be created and start collecting safety reports from tech companies. The nine-person board, selected by California’s governor and legislature, would make recommendations to California’s attorney general about which companies do and do not comply.That same year, SB 1047 would also require that AI model developers hire auditors to assess their safety practices, effectively creating a new industry for AI safety compliance. And California’s attorney general would be able to start suing AI model developers if their tools are used in catastrophic events.By 2027, the Board of Frontier Models could start issuing guidance to AI model developers on how to safely and securely train and operate AI models.If SB 1047 gets vetoedIf Newsom vetoes SB 1047, OpenAI’s desires would come true, and federal regulators would likely take the lead on regulating AI models …eventually.On Thursday, OpenAI and Anthropic laid the groundwork for what federal AI regulation would look like. They agreed to give the AI Safety Institute, a federal body, early access to their advanced AI models, according to a press release. At the same time, OpenAI has endorsed a bill that would let the AI Safety Institute set standards for AI models.“For many reasons, we think it’s important that this happens at the national level,” OpenAI CEO Sam Altman wrote in a tweet on Thursday.Reading between the lines, federal agencies typically produce less onerous tech regulation than California does and take considerably longer to do so. But more than that, Silicon Valley has historically been an important tactical and business partner for the United States government.“There actually is a long history of state-of-the-art computer systems working with the feds,” said Casado. “When I worked for the national labs, every time a new supercomputer would come out, the very first version would go to the government. We would do it so the government had capabilities, and I think that’s a better reason than for safety testing.”","AI, AI regulation, california, ChatGPT, Government & Policy, OpenAI, SB 1047",,,,55
"The case against AI art","Anthony Ha",2024-09-01,https://techcrunch.com/2024/09/01/the-case-against-ai-art/,"No matter how powerful generative AI becomes, writer Ted Chiang says it will never create true art. Chiang is one of the most admired science-fiction authors writing today, best known…","No matter how powerful generative AI becomes, writer Ted Chiang says it will never create true art.Chiang is one of the most admired science-fiction authors writing today, best known for the novella “Story of Your Life” (which was adapted into the movie “Arrival”). But he’s also published terrific pieces for The New Yorker that looked at the dangers and shortcomings of AI.You should really read his latest article in its entirety, but briefly: Chiang argues that the potential of large language models remains “largely theoretical” — thus far, generative AI has been most successful at “lowering our expectations, both of the things we read and of ourselves when we write anything for others to read. It is a fundamentally dehumanizing technology because it treats us as less than what we are: creators and apprehenders of meaning.”Even as LLMs improve, Chiang argues that their output will never be art — which he acknowledges is “notoriously hard to define,” but he tries anyway: “Art is something that results from making a lot of choices.” Sure, those choices might not result in a particularly good novel or painting or film, but you’re still “engaged in an act of communication between you and your audience.”“We are all products of what has come before us, but it’s by living our lives in interaction with others that we bring meaning into the world,” Chiang concludes. “That is something that an auto-complete algorithm can never do, and don’t let anyone tell you otherwise.”","AI, In Brief",,,,56
"‘Emotion AI’ may be the next trend for business software, and that could be problematic","Julie Bort",2024-09-01,https://techcrunch.com/2024/09/01/emotion-ai-could-be-the-next-trend-for-business-software-and-that-could-be-problematic/,"As businesses experiment with embedding AI everywhere, one area starting to gain more attention is Emotion AI.","As businesses experiment with embedding AI everywhere, one unexpected trend is companies turning to AI to help its many newfound bots better understand human emotion. It’s an area called “emotion AI,” according to PitchBook’s new Enterprise Saas Emerging Tech Research report that predicts this tech is on the rise. The reasoning goes something like this: If businesses deploy AI assistants to execs and employees, make AI chatbots be front-line salespeople and customer service reps, how can an AI perform well if it doesn’t understand the difference between an angry “What do you mean by that?” and a confused “What do you mean by that?”Emotion AI claims to be the more sophisticated sibling of sentiment analysis, the pre-AI tech that attempts to distill human emotion from text-based interactions, particularly on social media. Emotion AI is what you might call multimodal, employing sensors for visual, audio, and other inputs combined with machine learning and psychology to attempt to detect human emotion during an interaction. Major AI cloud providers offer services that give developers access to emotion AI capabilities such as Microsoft Azure cognitive services’ Emotion API or Amazon Web Services’ Rekognition service. (The latter has had its share of controversy over the years.)While emotion AI, even offered as a cloud service, isn’t new, the sudden rise of bots in the workforce give it more of a future in the business world than it ever had before, according to PitchBook. “With the proliferation of AI assistants and fully automated human-machine interactions, emotion AI promises to enable more human-like interpretations and responses,” writes PitchBook’s Derek Hernandez, senior analyst, emerging technology in the report.“Cameras and microphones are integral parts of the hardware side of emotion AI. These can be on a laptop, phone, or individually located in a physical space. Additionally, wearable hardware will likely provide another avenue to employ emotion AI beyond these devices,” Hernandez tells TechCrunch. (So if that customer service chatbot asks for camera access, this may be why.)To that end, a growing cadre of startups are being launched to make it so. This includes Uniphore (with $610 million total raised, including $400 million in 2022 led by NEA), as well as MorphCast, Voicesense, Superceed, Siena AI, audEERING, and Opsis, each of which also raised modest sums from various VCs, PitchBook estimates.Of course, emotion AI is a very Silicon Valley approach: Use technology to solve a problem caused by using technology with humans. But even if most AI bots will eventually gain some form of automated empathy, that doesn’t mean this solution will really work.In fact, the last time emotion AI became of hot interest in Silicon Valley — around the 2019 time frame when much of the AI/ML world was still focused on computer vision rather than on generative language and art — researchers threw a wrench in the idea. That year, a team of researchers published a meta-review of studies and concluded that human emotion cannot actually be determined by facial movements. In other words, this idea that we can teach an AI to detect a human’s feelings by having it mimic how other humans try to do so (reading faces, body language, tone of voice) is somewhat misguided in its assumption.There’s also the possibility that AI regulation, such as the European Union’s AI Act, which bans computer-vision emotion detection systems for certain uses like education, may nip this idea in the bud. (Some state laws, like Illinois’ BIPA, also prohibit biometric readings from being collected without permission.)All of which gives a broader glimpse into this AI-everywhere future that Silicon Valley is currently madly building. Either these AI bots are going to attempt emotional understanding in order to do jobs like customer service, sales and HR and all the other tasks humans hope to assign them, or maybe they won’t be very good at any task that really requires that capability. Maybe what we’re looking at is an office life filled with AI bots on the level of Siri circa 2023. Compared with a management-required bot guessing at everyone’s feelings in real time during meetings, who’s to say which is worse?","AI, emotion AI, sentiment analysis, Startups",,,,57
"Why do so many home robots still suck?","Brian Heater",2024-09-01,https://techcrunch.com/2024/09/01/why-do-so-many-home-robots-still-suck/,"Home robots’ unfulfilled potential is neither because of lack of demand on the part of consumers nor lack of effort from manufacturers.","“The Jetsons” debuted September 23, 1962. The first episode, titled “Rosey the Robot,” was an origin story of sorts for the titular character, describing how an overworked Jane hired the housekeeper. Sixty-two years after her debut, Rosey remains an important pop cultural touchstone for the unfulfilled promise of home robots.The home of 2024 isn’t necessarily wholly devoid of robots. According to its own figures, iRobot has sold more than 50 million Roombas. That, meanwhile, is a fraction of the overall number of robot vacuums that have been sold around the globe. Robot lawnmowers and pool cleaners have gained traction as well, though those figures pale in comparison to their vacuuming counterparts.Home robots’ unfulfilled potential isn’t because of a lack of consumer demand or lack of effort from manufacturers. It’s more complicated and nuanced than that, though ultimately it’s a matter of pricing, functionality and efficacy. Outside of the aforementioned use cases, today’s home robots don’t do enough or do what they do well enough, and building a robot that can tick both of those boxes would prove prohibitively expensive for those of us who can’t afford our own islands.Vacuums make for good home robotsDuring his long tenure as iRobot CEO, co-founder Colin Angle was fond of saying that he didn’t become a successful roboticist until he became a vacuum salesman. It’s a fun quip that gets to something much deeper about the industry. Before the Roomba came along, the company had experimented with everything from baby dolls to military equipment.iRobot found success when it focused on a simple task: cleaning floors. The earliest models were primitive by today’s standards, but they got the job done well enough to justify their price point. In addition to marking 62 years since Rosey’s TV debut, next month is also the Roomba’s 22nd anniversary. The robot vacuum is old enough to legally buy a case of Sam Adams.In the nearly quarter century since the Roomba launched, much of iRobot’s R&D has gone into making the system smarter, adding sensing, mapping, and AI and integrating with smart assistants. The company has invested into other robotics categories as well, including gutter clearing, pool cleaning and a lawnmower that may never see the light of day, but all have failed to recapture the Roomba’s magic.Work/home balanceYears ago, I appeared on a panel to discuss robots. The moment the conversation ended and the Q&A began, a woman’s hand shot up, front and center. She was eager to tell me about her billion-dollar idea: a drone that vacuums, dusts surfaces and does the laundry. I told her it was a great idea and I would happily buy one from her when she got it up and running.Everything in robotics is easier said than done. It isn’t that no one before her came up with the concept for a furniture-dusting drone; it’s that no one before her figured out how to build a reliable and robust version at scale with a price tag that isn’t higher than my 30-year mortgage.I thought back to that moment when Tesla announced its robot by way of a dancer in a spandex onesie. Elon Musk described a humanoid that would toil away all day at the factory and then pick up your groceries on the way home, before preparing your dinner. Musk has been in the public eye long enough to know precisely how much stock one should put in his timelines.Image Credits: TeslaBefore the fully functioning Roseys of the world arrive, simpler machines are going to have to pave the way. Robots have had a place in manufacturing for decades, but they’ve been built to do one job well over and over again. The more complex the machine, the more expensive it gets and the more potential points of failure emerge. Think about how many ways your Roomba has failed and multiply that by the complexity of a humanoid.Most experts agree that early home robots will be designed for a handful of simple tasks: social robots and those providing caregiving and doing housework. For the foreseeable future, each will be designed with one or two functions in mind.Laying the groundwork for future robotsThere’s a sense of frustration that home systems are nowhere near where expected by this point in time. What regularly gets lost in that conversation, however, is the amount of groundwork that has already been laid. Whoever builds the next great home robot won’t have done so in a vacuum.Their success will be built not only on top of ongoing research, but also on the home robots that came before. Navigating in an environment as unstructured and dynamic as the home likely felt impossible for many before the first Roomba arrived. Again, it was a simple machine by today’s standards, but it laid the foundation for what comes next.One can see reflections of this in the current crop of home robots. Take Hello Robot. As design goes, it’s an extremely simplistic machine. It’s an arm attached to a pole attached to a Roomba-like base. Its simplicity is, in part, because it’s more development platform than product. But systems like this or, say, Matic’s robot vacuum, are continuing the hard work of building foundations, be they mapping, manipulation or navigation.Antisocial social robotsSocial home robots had a rough year in 2019. Anki, Kuri and Jino all fell in quick succession, each for a combination of price, limited functionality and reliability. More recently, Amazon’s Astro has been dead in the water, effectively kneecapped after Amazon’s belt tightening wiped out a significant portion of the company’s consumer hardware headcount. Of course, had the $1,600 robot been a wild success, the retail giant almost certainly wouldn’t have let it die a quiet death.Amazon’s struggles are a friendly reminder that being one of the world’s largest companies doesn’t guarantee success in such a treacherous category. And following the Vision Pro’s lukewarm reception, one has to wonder whether Apple might be walking a similar road with its reported home robot play.A more recent report suggested that the first project out of the group could look less like Amazon’s Astro and more like its Echo Show 10. The potential product has been described as something along the lines of an iPad-like tablet mounted to an arm. These are reports of nascent projects, which could go any number of ways, but as it stands, this sounds more in line with where the company’s robotic ambitions ought to be.Home robots are coming, but when they arrive, they’ll still have a long way to go. That said, Jane won’t bring home Rosey until 2062, so we’ve got time.Update: Amazon tells TechCrunch that reports of Astro’s demise have been greatly exaggerated. The company notes that the robot is still available through its Day One program and “Amazon is still fully committed to our vision of bringing world-class consumer robotics solutions to the home and excited about the in-home experiences we’re inventing for Astro.”","AI, Amazon, Apple, Hardware, home robot, Robotics",,,,58
"Amazon hires the founders of AI robotics startup Covariant","Anthony Ha",2024-08-31,https://techcrunch.com/2024/08/31/amazon-hires-the-founders-of-robotics-ai-startup-covariant/,"Amazon announced Friday evening that it has hired Covariant’s founders — Pieter Abbeel, Peter Chen, and Rocky Duan — along with “about a quarter” of the startup’s employees. It’s also…","Amazon announced Friday evening that it has hired Covariant’s founders — Pieter Abbeel, Peter Chen, and Rocky Duan — along with “about a quarter” of the startup’s employees. It’s also signed a non-exclusive license to use Covariant’s robotic foundation models.Earlier this year, Chen told TechCrunch that Covariant is building “a large language model, but for robot language.” In other words, it’s creating AI models for robots, with an initial focus on robotic arms performing common warehouse tasks like bin picking.“With some of the smartest minds, we will advance fundamental research, marrying our rich expertise to unlock new ways for AI and robots to assist our operations employees,” said Joseph Quinlivan, vice president of Amazon Fulfillment Technologies & Robotics, in a statement. “[Embedding] Covariant’s AI technology into our existing robot fleet will make them more performant and create real-world value for our customers.”The deal sounds similar to Amazon’s hiring of the founders of AI startup Adept back in June — another deal that gave Amazon access to new talent and technology without having to fully acquire an existing startup.At the time, The Verge described this approach as a “reverse acquihire,” where tech giants facing antitrust scrutiny can use hiring and licensing deals to disguise their acquisitions, rather than the other way around. Covariant, meanwhile, said it will continue operating under the leadership of Ted Stinson and Tianhao Zhang, with Stinson — who’d been the startup’s COO — now stepping into the CEO role. The company added that it remains “dedicated to delivering the Covariant Brain into production environments across a broad set of global industries, including apparel, health and beauty, grocery, and pharmaceuticals.”","AI, Amazon.com, covariant, Robotics",,,,59
"Grammy CEO says music industry also has AI concerns","Dominic-Madori Davis",2024-08-31,https://techcrunch.com/2024/08/31/grammy-ceo-says-music-industry-also-has-ai-concerns/,"The rise of AI has consumed the arts, just as it has Silicon Valley. Everyone is pondering: Will AI replace me?","Harvey Mason Jr., CEO of the Recording Academy, caused a stir a few months ago. He announced that the organization’s prestigious Grammy Awards would finally accept music made with artificial intelligence. At first, people were confused, and then Mason came out to clarify that he meant only humans can submit to the awards, but that AI can be used in the creative process. “It’s a bit of a fine line, but that’s going to evolve,” he told TechCrunch about how the Academy is assessing the use of artificial intelligence in music. “My hope is that we can continue to celebrate human creativity at the highest level.” The rise of AI has consumed the arts, just as it has Silicon Valley. Everyone is pondering: Will AI replace me? And within music — what happens to copyright? Royalties? To the hard work I’ve put into my craft? Mason said there are indeed concerns sweeping the industry. Some people are scared and nervous, while others are excited and optimistic. Some artists are sending cease-and-desist letters to get unauthorized deepfakes of themselves taken down, while others are embracing their AI versions — so long as they get paid. “I wholeheartedly believe that AI in music shouldn’t even exist,” musician Devante, the Artist told TechCrunch. “AI should really only be used for simple daily tasks. As an artist, the ‘AI is taking over the world’ take is very real these days. Music is my world and now it’s all too easy for someone to masquerade as something it’s taken my whole life to be.” “I think a lot of musicians, particularly the ones who haven’t ‘made it,’ are taking a glass-half-empty perspective on AI,” a musician who also works for a Big Tech company told TechCrunch. He asked to remain anonymous because he did not have permission from his employer to speak on the matter. “Just as the industrial revolution did not lead to widespread unemployment and in fact quite the opposite, more creatives, especially musicians, should flip their mindset and lean in.” AI is already being used in music, mostly in the process of mastering and equalizing sounds, Mason said. The biggest concerns right now in the industry are making sure people get the right approvals to use an artist’s work, making sure humans are credited separately from AI, and making sure people are getting paid fairly, whether that’s the copyright AI is trained on or the likeness of an artist. There’s also the issue of ensuring these protections across the industry. Mason co-launched the Human Artistry Campaign to address some of these issues and advocate for more guardrails around the use of AI. He was involved with the ELVIS Act, passed in Tennessee, which gives artists more protection over the unauthorized use of their voices. He’s also supporting the No AI Fraud Act and the No FAKES Act, which will protect creators’ likenesses from AI fakes. It’s a pressing matter that is moving faster than the law. This month, Donald Trump found himself in tricky legal water after using unauthorized AI images of Taylor Swift to help promote his presidential campaign. At the time, TechCrunch reported that the ELVIS Act is so new that there is no precedent on how it could be used to protect an artist like Swift in this situation. (Mason declined to comment on the matter then.) The push for more legislation within the music industry is quite interesting given the fact that the topic has caused much debate in Silicon Valley. Some AI purveyors in the U.S. favor a more laissez-faire attitude toward the technology in its early days and believe too many guardrails could hinder innovation. Others are looking at it from a societal standpoint, wanting protections against the impact that unchecked AI could have on people. Governments across the U.S. — and even on a national stage — are battling this out now. Devante, the Artist feels there is a disconnect between what is being done to regulate AI versus what should be done. He wants to see the development of AI slowed down or see innovation that can help protect music, such as a type of filter that can differentiate AI vocals from human ones.“As it comes to our industry and the creative community, there’s still a concern,” Mason said. “There’s uncertainty because there just doesn’t seem to be protections in place.” In 2020, when Mason first became president of the Recording Academy, AI was hardly a topic of discussion. Then, around 2023, everything started to change. A deepfake song featuring trained, unauthorized AI vocals on Drake and the Weeknd went viral. Fans loved it, and the person who created the song spoke of possibly entering the song into the Grammys. The Academy had to act fast, dealing with something it had never dealt with before. “That was the point at which we started having to pay close attention to it,” Mason said. The song was deemed ineligible for the Grammys and was taken down, but its legacy lived on. The highest profile AI situation since then ironically also involved Drake. During the Drake-Kendrick Lamar feud, Drake used unauthorized AI vocals of the late hip-hop icon Tupac in an attempted diss track against Lamar and was immediately threatened with a lawsuit by Tupac’s estate for using his likeness without permission. Meanwhile, producer Metro Boomin, who also has qualms with Drake, created an AI song called “BBL Drizzy,” which fans raved about, even after learning it was AI. Mason said consumers aren’t always going to know when something is AI — nor will they always go through the credits to find out. Mason said that many consumers don’t seem to care much about whether AI is used in music, another reason why protecting creators is so important. “I don’t think people care what they consume,” Devante, the Artist agreed. “It’s almost like a ‘not me, not my problem situation.’” At the same time, Mason believes that humans will just evolve to live with AI, just like they’ve adapted to nearly every other new form of technology. Years ago, artists had to learn how to use synthesizers or how to sample music. The latter especially posed a problem, as some artists would just sample another person’s music without permission. Eventually, the industry went back and figured out a standard way to allocate credit and royalties.“We’ll make great music with the new technology,” Mason said about AI. “But I just want to make sure it’s done in a way that’s fair to the human creators.” This story was updated to clarify the AI song of Drake and the Weeknd submitted to the Grammys.","AI, Artificial Intelligence (AI), grammy awards, Music",,,,60
"Before Midjourney, there was NightCafe — and it’s still kicking","Kyle Wiggers",2024-08-31,https://techcrunch.com/2024/08/31/before-midjourney-there-was-nightcafe-and-its-still-kicking/,"Learn about NightCafe’s origins, some of the challenges the platform faces, and where NighCafe will evolve from here.","Elle Russell, co-founder of NightCafe, which offers a suite of AI-powered art-creating tools, prefers to avoid the spotlight.“I like to remain hidden behind my monitors,” she told me in a recent interview.NightCafe, based in Cairns, Australia, is similarly low profile.The company, which Russell helped her partner, Angus Russell, launch five years ago, doesn’t get the same publicity as some of its rivals, like Midjourney. Yet NightCafe — an entirely bootstrapped venture that’s profitable “most months,” according to Elle — has enormous reach. Its over 25 million users have created nearly a billion images with its tools.To pull back the curtain on one of the web’s oldest generative art marketplaces, I spoke with Elle about NightCafe’s origins, some of the challenges the platform faces, and where she and Angus see it evolving from here.A website for wall artAs NightCafe’s founding story goes, Angus had recently moved into a semi-detached house in Sydney’s Inner West area and hadn’t had a chance to decorate it with much artwork. “You should get some art; the walls are bare,” remarked one guest. And while Angus agreed, he couldn’t find any prints online that spoke to him.So in 2019, Angus, who had a degree in design and who’d co-founded a few design-focused startups, began a side hustle: a website where people could buy and sell AI-generated art. He called it NightCafe, after Vincent Van Gogh’s “The Night Café.”It was an abject failure.People liked creating the art, which NightCafe didn’t charge for. But they didn’t want to pay for wall prints, which was the only way the site made money.Then one fateful week, Angus noticed that his hosting bill was a few hundred dollars higher than usual. Someone had generated thousands of images in just a few days. He implemented a credit system to prevent that from happening again.Soon after, Angus’ inbox was flooded with requests to add an option to buy more credits, which he did. Practically overnight, the site became breakeven.It’s at this point Elle joined NightCafe to run the business side of the operation. “I have two undergraduate bachelor degrees, in business and communications, and I’m also a CPA,” she said. “It made sense.”NightCafe’s viral successNightCafe got its second big break a couple years later, in mid-2021, when OpenAI announced DALL-E.DALL-E, OpenAI’s first image-generating AI model, was state-of-the-art for the time. OpenAI opted not to release it, but it wasn’t long before enthusiasts managed to reverse-engineer some of the methods behind DALL-E and build open source models of their own.Angus, who’d been closely following the developments, quickly worked to get one of the more popular DALL-E alternatives, VQGAN+CLIP, on NightCafe. He shelled out for hundreds of GPUs to scale it up.The investment soon paid for itself.Images created with NightCafe’s VQGAN+CLIP blew up on Reddit; NightCafe made $17,000 in a single day. Angus decided to quit his job at Atlassian to work on the platform full-time.A model marketplaceThe NightCafe of today is quite different from the NightCafe of several years ago.The platform still runs some models on its own servers, including recent versions of Stable Diffusion and Ideogram. But it also integrates APIs from AI vendors that offer them, delivering what amounts to custom interfaces for third-party generators.Selecting a model from NightCafe’s gallery.Image Credits: NightCafeThat is to say, NightCafe layers tools on top of models from elsewhere, including OpenAI, Google and Black Forest Labs. And, as it has since 2019, the site provides printing services for customers who want mugs, T-shirts and prints of any art they generate.“We’re a UI and community company,” Elle said. “NightCafe doesn’t have any internal AI or machine learning capability; we aggregate the available image models and make them fun and accessible to use.”In NightCafe’s chatrooms, users can share their art and collaborate, or kick off “AI art challenges.” The platform also hosts official competitions where people can submit their creations for featured placement.Chatrooms on NightCafe.Image Credits: NightCafeLast year, NightCafe introduced fine-tuning, which allows users to train a model to re-create a specific style, face or object by uploading example images. Fine-tuned models on NightCafe are subject to certain restrictions; for example, they can’t be trained on images showing nudity, celebrities or people under the age of 18, and they must be manually approved by NightCafe’s moderation team. (That’s to mitigate the risk of deepfakes.)The terms users must agree to before submitting a fine-tuned model.Image Credits: NightCafeNightCafe is free to use, but only up to a certain number of images. Packs of image-generation credits can be purchased à la cart, and select features are gated behind a subscription. For fees ranging from $4.79 to $50 per month (undercutting Midjourney and Civitai), users get priority access to more-capable models, the ability to tip creators, the aforementioned fine-tuning capability and a higher image-generation limit.It’s a model that’s worked exceptionally well for NightCafe. A source close to the company tells TechCrunch that NightCafe is raking in $4 million in annualized revenue with a gross margin of nearly 50%, meaning that NightCafe is generating approximately $2 million a year in profit after expenses (inclusive of payroll for its nine staff). Roughly a million people are visiting NightCafe each month, Elle says, and 20,000 have a subscription.“Any AI art generator online is competing for money from the same people, though our users skew older than a lot of the industry,” she said. “We consider our biggest competitors to be other apps that have a strong community: Leonardo, Civitai and Midjourney.”Copyright concerns over AI artBy opting not to train its own AI (and moderating fine-tuning), NightCafe is attempting to steer clear of the legal stand-off that’s ensnared many of the AI vendors whose models it aggregates.Stability AI, Midjourney and a pair of other model providers, DeviantArt and Runway, face a class action lawsuit filed by artists who allege that the vendors engaged in copyright infringement by training their models on art without permission. (The vendors claim a fair use defense.) Some parts of the suit have been struck down. But a federal judge allowed it to move into the discovery stage early this month.NightCafe may be protected by Section 230 of the Communications Decency Act, which holds users, not platforms, liable for illegal content (like copyright-violating artwork) so long as the platforms remove the content upon request. Australia, NightCafe’s home base, has the Broadcasting Services Act, which closely mirrors Section 230 with the exception that it imposes higher additional fees for failing to expeditiously remove “extreme violent material.”Of course, should a court rule that the models NightCafe uses are essentially plagiarism machines, that’d be disruptive to the company’s business. But what about copyright as it pertains to NightCafe’s users and the art they generate?Creating an image with NightCafe.Image Credits: NightCafeAccording to the platform’s terms of service, users retain the copyright for their AI-generated works in countries that recognize these types of works as copyrightable (like the U.S.) — at least as long as there’s permission to use any third-party branding, logos or trademarks within.A post last May on NightCafe’s blog sheds more light on this: “Legitimate creators recognize and acknowledge where the inspiration used to create their images derived from another source. AI art creation tools are also evolving quickly, with systems in development to support the ongoing creative environment while ensuring that users can only access source material with the [consent] of the original artist — in much the same way that a royalty-free photography image may be permitted for use provided the creator is referenced.”In other words, in NightCafe’s view, it’s the users, not NightCafe, who have to cover their bases. And if they don’t, the platform won’t defend them from the wrath of IP holders.But it seems that IP holders don’t intimidate many users.Cursory searches of NightCafe bring up images of Pokémon and Donald Duck, celebrities like Britney Spears, brands such as Coca-Cola and LEGO and artwork in the style of artists like Stanley “Artgerm” Lau. None appears to have been generated with the blessing of the copyright holders.Image Credits: NightCafe“Users can also report content that got through automated filters, and we have a team of human moderators working 24/7 on moderating flagged content,” Elle said when asked about this.Political policies and deepfakesAs my interview with Elle segued to moderation, we dove into NightCafe’s general content guidelines, particularly its policies around politics and deepfakes.Platforms, including Midjourney, have taken the step of banning users from generating images of political figures like Donald Trump and Kamala Harris leading up to the U.S. presidential election. But NightCafe hasn’t — and it doesn’t intend to, according to Elle.“Generating images of Trump and other political and public figures is allowed,” she said. “However, we don’t want NightCafe to be a place for political arguments.”How can NightCafe have it both ways? While the platform won’t prevent users from publishing political images elsewhere, it will flag those images for review if a user tries to post them to NightCafe’s public feeds. That being the case, it’s trivial to find images of Biden in a wheelchair, Trump holding a gun and questionable Harris memes in NightCafe’s public gallery. With polls showing that the majority of Americans are concerned about the spread of AI propaganda and deepfakes, NightCafe certainly hasn’t made enforcement easier on itself.Image Credits: NightCafeAs for what content is or isn’t allowed: It depends.“Political bait,” glorification of divisive figures or purposely unflattering or demeaning images, are no-gos (in spite of what my searches turned up). Most content the average person would find harmful or offensive is also prohibited; NightCafe’s community standards list calls out things like racist and homophobic images, spam, offensive swear words, terrorism themes, images mocking people with disabilities, and depictions of hate groups and symbols.These subjects may technically be disallowed. But type a term like “suicide bomber” into NightCafe’s search bar and there’s a decent chance you’ll come across at least one image that seems to fly in the face of the platform’s rules. Elle tells me that it’s ultimately up to moderators to interpret NightCafe’s guidelines and that repeatedly publishing images in a banned category, or circumventing automated filters, could result in a warning or ban.NightCafe has a rather small moderation team given its size (and the fact that the site’s users generate at least 700 images a day): five paid moderators and 20 volunteer moderators who get compensation in the form of premium NightCafe features. The paid moderators monitor content, while the volunteers handle comments, NightCafe’s chatrooms and the fine-tuned model queue.Considering the poor working conditions content moderators are often subject to, I asked Elle for more information about NightCafe’s moderator recruitment practices. She said that the paid team is run through an outsourcing firm based in Indonesia (she wouldn’t name which) and overseen by an internal NightCafe staff member.A few results for the search term “Coca-Cola.”Image Credits: NightCafeAll paid moderators get a “market wage,” Elle said. (In Jakarta, the minimum wage was around $325 per month as of early 2024.)Similar to Civitai, NightCafe has a policy carve-out for “NSFW” content: short of outright nudity, but permissive of suggestive poses (with “bare breasts and bums”), blood and gore, graphic depictions of war, and images of illegal drug use (e.g., Mickeys smoking blunts). This is somewhat dependent on the model; OpenAI’s DALL-E 2 has a stricter set of filters, for instance.Why allow NSFW images despite the risks and without any form of watermarking (which might soon be legally mandated in California) to prevent abuse? To the first question, Elle says that it would stifle “artistic freedom.”“We do allow mild artistic nudity and adult themes on the site when tagged as NSFW, but not outright porn. We’ve tried our best to ‘draw the line’ for our users in our community standards so that they understand what’s allowed and what’s not,” she added. “We pride ourselves on our community and being the ‘hub’ for all things AI art.”From my few searches, NightCafe doesn’t seem overrun with boundary-crossing objectionable stuff. But I couldn’t help but notice that most of the “sexy” images featured women — an unfortunate pattern on platforms such as these.Where NightCafe goes from hereLike many startups in the AI-powered art-generating space, NightCafe appears to be in a bit of a holding pattern. It’s bringing new models online, including video-generating models like Stable Video Diffusion. But it’s not rocking the boat too much — the unsaid reason being that a single court decision or regulation could force NightCafe to rethink its entire operation.Still, Elle seems to think NightCafe has legs and doesn’t need outside investment.“The majority of our competitors raised money over the last two years while image generation was hot,” Russell said. “Pretty much all of them were, or are, offering image generation at a loss to acquire users. Not all of them can succeed; NightCafe pioneered the intersection of AI and art but also championed the idea that creativity using advanced technology should be accessible for all.”There’s no plans for an enterprise NightCafe offering, despite how lucrative such a product could prove to be (moderation roadblocks aside). Elle says that the focus will remain on building a community and “social hub” atop the latest generative models.“One challenge that the industry faces is that image-generation models are getting so good, they’ll soon be commoditized,” she said. “What do companies compete on then? At NightCafe, we’ve chosen to focus on being an aggregator of the top models to provide the best variety and highest level of technology.”We’ll see how it navigates the choppy waters from here.","AI, AI, Apps, Generative AI, image generation, nightcafe, Startups",,,,61
"AI brings a whole new dimension to the challenge of organizational transformation","Ron Miller",2024-08-31,https://techcrunch.com/2024/08/31/ai-brings-a-whole-new-dimension-to-the-challenge-of-organizational-transformation/,"Organizations are people and people are messy, and you have to look beyond the tech to the end goal: implementing new software that could transform the business.","Let’s start with the premise that change is hard for everyone. It’s even harder at scale for a large organization. As we’ve watched large organizations over the last 15 years try to embrace mobile, Big Data, the cloud and general digital transformation, we have seen many of them struggle again and again to implement these technologies. Today, it’s AI that is forcing companies and their employees to change, whether they like it or not.Part of the problem is technical debt, the notion that an organization’s tech stack has to evolve to take full advantage of the new technologies, rather than using a set of technical capabilities designed for a prior era. It’s not easy to try and change something that is fundamental to running a business without risking messing up what works already. Not too many managers are going to fully embrace that kind of change. Substantive change involves tremendous risk along with enormous potential.Another part of the problem is institutional inertia. It’s just hard to change how people do things. Let me tell you the story of when I was a technical writer many years ago, and we were implementing a computer system at a small town register of deeds. The town’s deeds were on paper and filed in cabinets. It was manual and unwieldy, making tracing deeds a process that could take weeks because people had to manually dig through the paper morass.The computer system was clearly better, but the workers at the front desk who dealt with the public weren’t sold. Part of their job was to stamp completed documents with a rubber stamp, which they did with great gusto, before they were sent away to be filed. For these clerks, who had worked the counter for 20 or 30 years, the stamp represented their identity and sense of power. They didn’t want to give it up.Eventually, the system architect just simply gave in and let them keep their stamp. Even though it was really no longer required for an online system, it got them to buy into the change.Which brings us to the biggest problem of all: change management. The hardest component of implementing new technology isn’t shopping, buying, testing and implementing it. It’s getting people to use it, and you often have to let them keep their stamp or they are going to sabotage even the best intentions of the team implementing the solution.Think about all of that, and then consider the level of change that AI brings, and you see a much more radical adjustment on the horizon around the way we work. The people holding the stamps see their power slipping away, and you have to be careful not to alienate them or you could be flushing money down the drain.In the end, organizations are people and people are messy, and you have to look beyond the tech to the end goal: implementing new software that could transform the business.AI is a whole new way of workingLarge technological shifts inside organizations are nothing new. The advent of the PC in the 1980s and the rise of the spreadsheet and word processor was one such moment. The internet and World Wide Web was another, but AI could be bigger than these previous waves of change.“The internet era lowered the cost of information transmission, and CIOs rode that thing and brought digital technologies inside of their organizations and so forth. But AI is a markedly different type of technology. It’s lowering the cost of expertise,” Karim Lakhani, faculty chair at Harvard’s Digital Data Design Institute, told TechCrunch.Organizational change is hard, and requires top-down buy in.Image Credits: andrewgenn / Getty ImagesBox CEO Aaron Levie takes it one step further, saying this is the first time that a computer is doing the work a person did previously, rather than helping the person do that work more efficiently. “So it’s a new relationship with computers because computers are making judgment decisions. They’re assessing information. They’re working through our data in ways that like a human would,” Levie said, and companies need to start rethinking about the role of computing in the organization.“There’s a whole new set of frameworks and paradigms that we have to evolve as a result of what AI can now do inside of an enterprise context,” he said. That means starting to think about how this technology will affect the organization overall and looking at issues like answer accuracy, data leakage, what data is used to train models and so forth.Of course, Levie thinks his company’s platform has been built to deal with these issues and help customers work through them, but companies are dealing with multiple vendors telling them a similar story, and it tends to make it more difficult to find the ones that can truly help and add value.Is this thing working?One big problem facing organizations is figuring out whether generative AI is really delivering on the promise of increased productivity; there currently isn’t a good way to make a direct connection between GenAI capabilities and increased productivity. That makes it harder to sell this internally to skeptical workers, who might be concerned about their own futures as they implement AI.On the flip side, there will be employees demanding these new tools, and that tension could create further organizational stress as managers work to figure out how to implement AI across a company with a range of opinions about how it will affect work.Some people like Jamin Ball, partner at Altimeter Capital, have written that the technology is so transformative that companies have to take the leap, whether they see the immediate benefits or not. “Right now the world is evolving — AI is a massive platform shift. And by NOT adopting / spending on it, you risk losing market share and slowly becoming irrelevant,” he wrote in his Clouded Judgement newsletter in July.Rita Sallam, a Gartner analyst, says if you look back at the days of the first word processors, the value proposition was never really about saving money by taking out the secretarial pool. It helped create a new way of working — and AI brings a similar value proposition.“Cutting out the secretarial pool probably didn’t justify that cost. But when you think about removing the physical limitation to ideation, of writing your ideas and iterating your ideas, and then giving that to everyone in the organization, my guess is, though we can’t prove it, it unleashed a whole era of potential innovation, and the ability for people now to curate their thoughts in a whole different way,” she said. Those kinds of changes are hard to measure, but they are huge benefits nonetheless.Getting executive buy-in has always been a crucial piece of the digital transformation puzzle. Like PCs before them, the cloud transformed how companies did business.Lakhani says AI is different from the cloud because CEOs can get this by using it. It doesn’t require any real technical explanation to see its power, and that could help drive change inside organizations. “My sense is that I think what’s different and what is accelerating the hype is that the Davos crowd of CEOs and board members and people that influence corporate strategy and so forth now have access to these tools, and can start to see some of their own problems being solved this way,” he said.But that doesn’t mean that vendors can simply pour into organizations and sell their solutions. They have to figure out how to show value.“The hyperscalers and vendors have to do a better job of showing how organizations can actually adopt this stuff,” he said.But getting past the people problem will be an even bigger hurdle. Lakhani says there are three truisms in place as organizations undertake this challenge. First of all, he says, “Machines won’t replace humans, but humans with machines will replace humans without machines.” Secondly, he says, “AI will fail at the front lines if you don’t think about the change mandate as top down, and create the incentives for the ‘stamp makers’ to actually adopt and feel good about what they’re doing.” He says if you try to ram it down their throats, it’s going to fail, so you have to define for everyone how and why to change, and not use the ‘because I said so’ approach.Nobody says this is going to be easy. Organizations have different levels of maturity and different degrees of technological readiness. But people are people, and substantive change doesn’t come easily inside large companies. AI is going to test organizational flexibility more than any other technology has in the past, and it’s not hyperbole to suggest that some companies could live and die on how deftly they handle it.","AI, Change Management, digital transformation, Enterprise, genAI",,,,62
"California’s legislature just passed AI bill SB 1047; here’s why some hope the governor won’t sign it","Maxwell Zeff",2024-08-30,https://techcrunch.com/2024/08/30/california-ai-bill-sb-1047-aims-to-prevent-ai-disasters-but-silicon-valley-warns-it-will-cause-one/,"SB 1047 has drawn the ire of Silicon Valley players large and small, including venture capitalists, big tech trade groups, researchers and startup founders.","Update: California’s Appropriations Committee passed SB 1047 with significant amendments that change the bill on Thursday, August 15. You can read about them here.Outside of sci-fi films, there’s no precedent for AI systems killing people or being used in massive cyberattacks. However, some lawmakers want to implement safeguards before bad actors make that dystopian future a reality. A California bill, known as SB 1047, tries to stop real-world disasters caused by AI systems before they happen. It passed the state’s senate in August, and now awaits an approval or veto from California Governor Gavin Newsom.While this seems like a goal we can all agree on, SB 1047 has drawn the ire of Silicon Valley players large and small, including venture capitalists, big tech trade groups, researchers and startup founders. A lot of AI bills are flying around the country right now, but California’s Safe and Secure Innovation for Frontier Artificial Intelligence Models Act has become one of the most controversial. Here’s why.What would SB 1047 do?SB 1047 tries to prevent large AI models from being used to cause “critical harms” against humanity. The bill gives examples of “critical harms” as a bad actor using an AI model to create a weapon that results in mass casualties, or instructing one to orchestrate a cyberattack causing more than $500 million in damages (for comparison, the CrowdStrike outage is estimated to have caused upwards of $5 billion). The bill makes developers — that is, the companies that develop the models — liable for implementing sufficient safety protocols to prevent outcomes like these.What models and companies are subject to these rules?SB 1047’s rules would only apply to the world’s largest AI models: ones that cost at least $100 million and use 10^26 FLOPS (floating point operations, a way of measuring computation) during training. That’s a huge amount of compute, though OpenAI CEO Sam Altman said GPT-4 cost about this much to train. These thresholds could be raised as needed.Very few companies today have developed public AI products large enough to meet those requirements, but tech giants such as OpenAI, Google, and Microsoft are likely to very soon. AI models — essentially, massive statistical engines that identify and predict patterns in data — have generally become more accurate as they’ve grown larger, a trend many expect to continue. Mark Zuckerberg recently said the next generation of Meta’s Llama will require 10x more compute, which would put it under the authority of SB 1047.When it comes to open source models and their derivatives, the bill determined the original developer is responsible unless another developer spends another $10 million creating a derivative of the original model.The bill also requires a safety protocol to prevent misuses of covered AI products, including an “emergency stop” button that shuts down the entire AI model. Developers must also create testing procedures that address risks posed by AI models, and must hire third-party auditors annually to assess their AI safety practices.The result must be “reasonable assurance” that following these protocols will prevent critical harms — not absolute certainty, which is of course impossible to provide.Who would enforce it, and how?A new California agency, the Board of Frontier Models, would oversee the rules. Every new public AI model that meets SB 1047’s thresholds must be individually certified with a written copy of its safety protocol.The Board of Frontier Models, would be governed by nine people, including representatives from the AI industry, open source community and academia, appointed by California’s governor and legislature. The board will advise California’s attorney general on potential violations of SB 1047, and issue guidance to AI model developers on safety practices.A developer’s chief technology officer must submit an annual certification to the board assessing its AI model’s potential risks, how effective its safety protocol is and a description of how the company is complying with SB 1047. Similar to breach notifications, if an “AI safety incident” occurs, the developer must report it to the FMD within 72 hours of learning about the incident.If a developer’s safety measures are found insufficient, SB 1047 allows California’s attorney general to bring an injunctive order against the developer. That could mean the developer would have to cease operating or training its model.If an AI model is actually found to be used in a catastrophic event, California’s attorney general can sue the company. For a model costing $100 million to train, penalties could reach up to $10 million on the first violation and $30 million on subsequent violations. That penalty rate scales as AI models become more expensive.Lastly, the bill includes whistleblower protections for employees if they try to disclose information about an unsafe AI model to California’s attorney general.What do proponents say?California State Senator Scott Wiener, who authored the bill and represents San Francisco, tells TechCrunch that SB 1047 is an attempt to learn from past policy failures with social media and data privacy, and protect citizens before it’s too late.“We have a history with technology of waiting for harms to happen, and then wringing our hands,” said Wiener. “Let’s not wait for something bad to happen. Let’s just get out ahead of it.”Even if a company trains a $100 million model in Texas, or for that matter France, it will be covered by SB 1047 as long as it does business in California. Wiener says Congress has done “remarkably little legislating around technology over the last quarter century,” so he thinks it’s up to California to set a precedent here.When asked whether he’s met with OpenAI and Meta on SB 1047, Wiener says “we’ve met with all the large labs.” Two AI researchers who are sometimes called the “godfathers of AI,” Geoffrey Hinton and Yoshua Bengio, have thrown their support behind this bill. These two belong to a faction of the AI community concerned about the dangerous, doomsday scenarios that AI technology could cause. These “AI doomers” have existed for a while in the research world, and SB 1047 could codify some of their preferred safeguards into law. Another group sponsoring SB 1047, the Center for AI Safety, wrote an open letter in May 2023 asking the world to prioritize “mitigating the risk of extinction from AI” as seriously as pandemics or nuclear war.“This is in the long-term interest of industry in California and the US more generally because a major safety incident would likely be the biggest roadblock to further advancement,” said director of the Center for AI Safety, Dan Hendrycks, in an email to TechCrunch.Recently, Hendrycks’ own motivations have been called into question. In July, he publicly launched a startup, Gray Swan, which builds “tools to help companies assess the risks of their AI systems,” according to a press release. Following criticisms that Hendrycks’ startup could stand to gain if the bill passes, potentially as one of the auditors SB 1047 requires developers to hire, he divested his equity stake in Gray Swan.“I divested in order to send a clear signal,” said Hendrycks in an email to TechCrunch. “If the billionaire VC opposition to commonsense AI safety wants to show their motives are pure, let them follow suit.”After several of Anthropic’s suggested amendments were added to SB 1047, CEO Dario Amodei issued a letter saying the bill’s “benefits likely outweigh its costs.” It’s not an endorsement, but it’s a lukewarm signal of support. Shortly after that, Elon Musk signaled he was in favor of the bill.What do opponents say?A growing chorus of Silicon Valley players oppose SB 1047. Hendrycks’ “billionaire VC opposition” likely refers to a16z, the venture firm founded by Marc Andreessen and Ben Horowitz, which has strongly opposed SB 1047. In early August, the venture firm’s chief legal officer, Jaikumar Ramaswamy, submitted a letter to Senator Wiener, claiming the bill “will burden startups because of its arbitrary and shifting thresholds,” creating a chilling effect on the AI ecosystem. As AI technology advances, it will get more expensive, meaning that more startups will cross that $100 million threshold and will be covered by SB 1047; a16z says several of their startups already receive that much for training models.Fei-Fei Li, often called the godmother of AI, broke her silence on SB 1047 in early August, writing in a Fortune column that the bill will “harm our budding AI ecosystem.” While Li is a well-regarded pioneer in AI research from Stanford, she also reportedly created an AI startup called World Labs in April, valued at a billion dollars and backed by a16z.She joins influential AI academics such as fellow Stanford researcher Andrew Ng, who called the bill “an assault on open source” during a speech at a Y Combinator event in July. Open source models may create additional risk for their creators, since like any open software, they are more easily modified and deployed to arbitrary and potentially malicious purposes.Meta’s chief AI scientist, Yann LeCun, said SB 1047 would hurt research efforts, and is based on an “illusion of ‘existential risk’ pushed by a handful of delusional think-tanks,” in a post on X. Meta’s Llama LLM is one of the foremost examples of an open source LLM.Startups are also not happy about the bill. Jeremy Nixon, CEO of AI startup Omniscience and founder of AGI House SF, a hub for AI startups in San Francisco, worries that SB 1047 will crush his ecosystem. He argues that bad actors should be punished for causing critical harms, not the AI labs that openly develop and distribute the technology.“There is a deep confusion at the center of the bill, that LLMs can somehow differ in their levels of hazardous capability,” said Nixon. “It’s more than likely, in my mind, that all models have hazardous capabilities as defined by the bill.”OpenAI opposed SB 1047 in late August, noting that national security measures related to AI models should be regulated at the federal level. They’ve supported a federal bill that would do so.But Big Tech, which the bill directly focuses on, is panicked about SB 1047 as well. The Chamber of Progress — a trade group representing Google, Apple, Amazon and other Big Tech giants — issued an open letter opposing the bill saying SB 1047 restrains free speech and “pushes tech innovation out of California.” Last year, Google CEO Sundar Pichai and other tech executives endorsed the idea of federal AI regulation.U.S. Congressman Ro Khanna, who represents Silicon Valley, released a statement opposing SB 1047 in August. He expressed concerns the bill “would be ineffective, punishing of individual entrepreneurs and small businesses, and hurt California’s spirit of innovation.” He’s since been joined by speaker Nancy Pelosi and the United States Chamber of Commerce, who have also said the bill would hurt innovation.Silicon Valley doesn’t traditionally like when California sets broad tech regulation like this. In 2019, Big Tech pulled a similar card when another state privacy bill, California’s Consumer Privacy Act, also threatened to change the tech landscape. Silicon Valley lobbied against that bill, and months before it went into effect, Amazon founder Jeff Bezos and 50 other executives wrote an open letter calling for a federal privacy bill instead.What happens next?SB 1047 currently sits on California Governor Gavin Newsom’s desk where he will ultimately decide whether to sign the bill into law before the end of August. Wiener says he has not spoken to Newsom about the bill, and does not know his position.This bill would not go into effect immediately, as the Board of Frontier Models is set to be formed in 2026. Further, if the bill does pass, it’s very likely to face legal challenges before then, perhaps from some of the same groups that are speaking up about it now.Correction: This story originally referenced a previous draft of SB 1047’s language around who is responsible for fine-tuned models. Currently, SB 1047 says the developer of a derivative model is only responsible for a model if they spend three times as much as the original model developer did on training.","a16z, AI, AI startups, California bill, ChatGPT, evergreens, generative ai regulatory requirements, Government & Policy, sb1047",,,,63
"The org behind the dataset used to train Stable Diffusion claims it has removed CSAM","Kyle Wiggers",2024-08-30,https://techcrunch.com/2024/08/30/the-org-behind-the-data-set-used-to-train-stable-diffusion-claims-it-has-removed-csam/,"LAION, the German research org that created the data used to train Stable Diffusion, among other generative AI models, has released a new dataset that it claims has been “thoroughly…","LAION, the German research org that created the data used to train Stable Diffusion, among other generative AI models, has released a new dataset that it claims has been “thoroughly cleaned of known links to suspected child sexual abuse material (CSAM).”The new dataset, Re-LAION-5B, is actually a re-release of an old dataset, LAION-5B — but with “fixes” implemented with recommendations from the nonprofit Internet Watch Foundation, Human Rights Watch, the Canadian Center for Child Protection and the now-defunct Stanford Internet Observatory. It’s available for download in two versions, Re-LAION-5B Research and Re-LAION-5B Research-Safe (which also removes additional NSFW content), both of which were filtered for thousands of links to known — and “likely” — CSAM, LAION says.“LAION has been committed to removing illegal content from its datasets from the very beginning and has implemented appropriate measures to achieve this from the outset,” LAION wrote in a blog post. “LAION strictly adheres to the principle that illegal content is removed ASAP after it becomes known.”Important to note is that LAION’s datasets don’t — and never did — contain images. Rather, they’re indexes of links to images and image alt text that LAION curated, all of which came from a different dataset — the Common Crawl — of scraped sites and web pages.The release of Re-LAION-5B comes after an investigation in December 2023 by the Stanford Internet Observatory that found that LAION-5B — specifically a subset called LAION-5B 400M — included at least 1,679 links to illegal images scraped from social media posts and popular adult websites. According to the report, 400M also contained links to “a wide range of inappropriate content including pornographic imagery, racist slurs, and harmful social stereotypes.”While the Stanford co-authors of the report noted that it would be difficult to remove the offending content and that the presence of CSAM doesn’t necessarily influence the output of models trained on the dataset, LAION said it would temporarily take LAION-5B offline.The Stanford report recommended that models trained on LAION-5B “should be deprecated and distribution ceased where feasible.” Perhaps relatedly, AI startup Runway recently took down its Stable Diffusion 1.5 model from the AI hosting platform Hugging Face; we’ve reached out to the company for more information. (Runway in 2023 partnered with Stability AI, the company behind Stable Diffusion, to help train the original Stable Diffusion model.)Of the new Re-LAION-5B dataset, which contains around 5.5 billion text-image pairs and was released under an Apache 2.0 license, LAION says that the metadata can be used by third parties to clean existing copies of LAION-5B by removing the matching illegal content.LAION stresses that its datasets are intended for research — not commercial — purposes. But, if history is any indication, that won’t dissuade some organizations. Beyond Stability AI, Google once used LAION datasets to train its image-generating models.“In all, 2,236 links [to suspected CSAM] were removed after matching with the lists of link and image hashes provided by our partners,” LAION continued in the post. “These links also subsume 1008 links found by the Stanford Internet Observatory report in December 2023 … We strongly urge all research labs and organizations who still make use of old LAION-5B to migrate to Re-LAION-5B datasets as soon as possible.”","AI, AI, CSAM, Generative AI, LAION, open source, Stability AI, Stable Diffusion",,,,64
"Google rolls out safeguards for more of its AI products ahead of the US presidential election","Aisha Malik",2024-08-30,https://techcrunch.com/2024/08/30/google-rolls-out-safeguards-for-more-of-its-ai-products-ahead-of-the-us-presidential-election/,"Google is gearing up for the upcoming U.S. presidential election by rolling out safeguards for more of its generative AI products. Although the company already previously announced that it would…","Google is gearing up for the upcoming U.S. presidential election by rolling out safeguards for more of its generative AI products. Although the company already previously announced that it would restrict Gemini queries related to the election, it’s now applying additional restrictions to its other generative AI products.These safeguards will be applied to Search AI Overviews, YouTube AI-generated summaries for Live Chat, Gems and image generation in Gemini. As part of the restrictions, these AI products will not respond to election-related topics.Given that generative AI is a relatively newer technology, Google acknowledges that it’s prone to making mistakes, which is why it’s restricting the features to prevent misinformation around the election.“Particularly for federal and state-wide elections, our users depend on us to provide reliable and up-to-date information on topics like current candidates, voting processes, and election results — and this new technology can make mistakes as it learns or as news breaks,” Google’s vice president of trust and safety, Laurie Richardson, wrote in a blog post. Misinformation was a significant issue during the 2020 presidential election, but with the rise of generative AI, misinformation during the 2024 election is poised to be even more of a problem. With the changes announced on Friday, Google is trying to get ahead of the problem. The company also announced that as with past elections, Google Search is getting a feature that will help people across the country find information about registering to vote. In addition, users will start to see new features on YouTube that will help them find credible information about election candidates and their political parties. As the election nears, the video platform will start to display reminders on where and how to vote.To help people find reliable election information, Google Play has launched a new badge that will be displayed on apps from official government agencies.","AI, Apps, Google, presidential election",,,,65
"TechCrunch Minute: Plaud’s NotePin is a wearable, AI-powered note taker","Anthony Ha",2024-08-30,https://techcrunch.com/video/techcrunch-minute-plauds-notepin-is-a-wearable-ai-powered-notetaker/,"Startups aren’t giving up on the idea of AI-powered pins, with the latest device from Plaud focused on just one task: taking notes. A few…","Startups aren’t giving up on the idea of AI-powered pins, with the latest device from Plaud focused on just one task: taking notes.A few months ago, companies like Humane and Rabbit launched their own gadgets powered by generative AI. It’s probably too early to fully write off any of those companies or products, but Humane’s Ai Pin, in particular, faced scathing reviews. And more broadly, none of these devices have been enough of a hit to prove that this is going to be a new category that most consumers actually care about.So in that context, the fact that Plaud’s NotePin is focused only on note-taking may be a disappointment, or it might make the company’s promises seem more believable. You can wear it as a necklace or a wristband, allowing you to record meetings and dictate notes to yourself, and those recordings are then transcribed using OpenAI’s GPT-4o.On today’s TechCrunch Minute, we talk about the promise of AI pins, the vision for Plaud’s NotePin and the company’s other products.","AI, Gadgets, plaud, Startups, TechCrunch Minute, the techcrunch minute",,,,66
"Former Riot Games employees leverage generative AI to power NPCs in new video game","Lauren Forristal",2024-08-30,https://techcrunch.com/2024/08/30/jam-and-tea-gaming-studio-leveraging-generative-ai-to-power-npcs/,"Jam & Tea Studios is the latest gaming startup implementing generative AI to transform the way players interact with non-playable characters (NPCs) in video games.  Traditionally, video game NPCs are…","Jam & Tea Studios is the latest gaming startup implementing generative AI to transform the way players interact with non-playable characters (NPCs) in video games. Traditionally, video game NPCs are directed by predetermined scripts, which can feel repetitive, unrealistic and boring. It also may restrict the number of potential experiences for players. However, when generative AI is involved, players can engage in casual conversation and interact with NPCs how they want to (within reason).Founded by gaming veterans from Riot Games, Wizards of the Coast and Magic: The Gathering, the company announced on Friday its first game that will leverage generative AI tools to help with gameplay mechanics, content generation, dialogue and item generation. Jam & Tea’s debut game, Retail Mage, is a roleplaying game that allows players to take on the role of a wizard working as a salesperson at a magical furniture store. The main goal of the game is to earn five-star reviews by helping customers. But it’s really up to the players to decide if they actually want to work or cause chaos. With AI NPCs as customers and human players being able to say and do almost whatever they want, the possible outcomes should vary widely.In Retail Mage, players are approached by customers who each have their own requests. Instead of selecting from preset phrases, players can type in the text generator how they’d like to respond. The player can ask the AI to “say something charming,” and it will offer four different dialogue options. Image Credits: Jam & TeaJam & Tea is among several companies competing in the AI-powered NPC space, alongside Artificial Agency, Inworld and Nvidia. Ubisoft’s AI-powered “Ghostwriter” tool writes NPC dialogue for some of its games. The new game also comes at a time when there’s concern among creatives about the potential challenges posed by the prevalence of generative AI. Last month, SAG-AFTRA — the union comprised of voice actors and other talent — initiated a strike against major game publishers over AI concerns.However, Jam & Tea claims it’s taking a balanced approach to the inclusion of AI, and wants to protect artists, writers and other creatives working in game design. “Our philosophy is that we believe creatives are going to be only more essential as we move forward in using this technology and in bringing new experiences to players,” co-founder and chief creative officer M. Yichao, who was the former narrative designer for Guild Wars 2, League of Legends and other titles, told TechCrunch.“AI will generate all this dialogue, and you can talk to characters endlessly… but it’s going to take the creative eye and lens to really add meaning to that and to craft that into an experience that matters into something with impact, depth and emotion that carries through stories. That’s going to become more important than ever,” Yichao added.  He explained that creatives are heavily involved throughout the development process, including when it comes to crafting NPCs, giving them motivation, interests and backstory, as well as providing example lines to help the AI mimic the tone and generate lines in real-time.Limitations of AI NPCsDespite its advantages, generative AI in NPCs has its limitations. One major concern is the issue of AI unpredictability, when the behavior of an NPC becomes excessively erratic, resulting in a frustrating experience for the player. AI can also hallucinate answers, so there’s a possibility that the NPC could say something that’s wrong or doesn’t exist in the world. Continuously improving the AI engine will help mitigate unpredictable NPCs, Yichao believes. Players can also rate the characters’ responses, which provides data to help improve the characters’ behavior. Plus, Jam & Tea claims to have put guardrails in place to prevent inappropriate conversations. Players are still encouraged to be creative, allowing for inventive and spontaneous interactions to occur. For example, instead of helping a customer, players can choose to engage in activities instead, like playing hide and seek — a real scenario that occurred during playtesting.“Our lead engineer was playtesting one night and went up to the NPCs and just said, ‘I’m bored.’ And the NPC responded by saying, ‘Well, why don’t we play a game? Let’s play hide and seek.’ And so the other NPCs heard and said, ‘Oh, we’re playing too,’” shared co-founder and CTO Aaron Farr. The NPCs proceeded to follow the rules of the game, with one seeker walking throughout the store to find all the hiders. “None of that was programmed; all of that was emergent behavior. That is part of the delight of when we have what a player wants to do combined with its experience to modify the experience in real-time,” added Farr, a former engineering leader at Riot Games and Singularity 6. The company has been experimenting with various large language models (LLMs) throughout the testing phase, including OpenAI, Google’s Gemma, Mistral AI and Meta’s Llama, and other open models. It’s currently uncertain which LLM it will ultimately use in the final version of the game, but is fine-tuning the model to train it on how to give better responses that are more “in character.”  Generate items out of thin air Jam & Tea’s AI engine goes beyond dialogue generation. Players can also interact with any object in the game and state their intentions with that object, such as picking it up or dismantling it for parts. They can even create items from scratch. Depending on what they want to do, the game interprets that intention and determines if they’re successful or not. In a demo shown to TechCrunch, Yichao interacted with an NPC named Noreen, who asked for an antelope-shaped plush. He then typed a command into an action box and retrieved a pillow resembling an antelope from a crate. The game recognized his action as successful and added the item to his inventory. Because the item didn’t previously exist in the game, players won’t physically see an antelope-shaped plush appear. All that happens in the game is the item shows up in the player’s inventory as a default image of a pillow. If the player wants to perform an action, like sitting in a chair, a notification appears on the screen indicating that the action was performed. “One of the things that’s really exciting about this technology is it allows for open-ended creative expression. Like, I can take a piece of meat and say, what if I put it in the bowl and I make a delicious fish stew? We might not have a fish stew [image], but one of the things that I’m working with our artists on is coming up with a creative ability to represent that item in a way that’s satisfying in the world and allows the player’s imagination to fill in some of those blanks, and gives players maximum creative freedom to make things that are unexpected,” Yichao said.  AI technology won’t be used for 2D or 3D asset generation. Real artists will create the images.Image Credits: Jam & TeaRetail Mage is a relatively basic game compared to others. At launch, the company promises to provide a more advanced product than the test version we saw during the demo. Jam & Tea states that the game is primarily intended to demonstrate the application of the technology as it continues to experiment. Beyond Retail Mage, the company is also developing another game — currently referred to as “Project Emily” internally — which will showcase their broader ambitions, featuring more environments and a sophisticated storyline.The startup’s scrappy team of eight has a lot of work ahead to reach the level of bigger gaming companies. However, taking action now while there is momentum allows the company to adapt and grow as AI models advance. Jam & Tea raised $3.15 million in seed funding from London Venture Partners with participation from Sisu Game Ventures and 1Up Ventures. It plans to raise another round later this year. As for the business model, Jam & Tea will charge $15 to buy the game and offer extra game packs that players can purchase separately. It’ll launch on PCs initially, but the company aims to enable cross-platform functionality within the next few years.Retail Mage is slated to be released to the public later this fall.","AI, Gaming, Generative AI, Jam & Tea Studios, London Venture Partners, Startups, video games",,,,67
"Plaud takes a crack at a simpler AI pin","Brian Heater",2024-08-28,https://techcrunch.com/2024/08/28/plaud-takes-a-crack-at-a-simpler-ai-pin/,"The NotePin, which hits preorder Wednesday, is $169 and comes with a free starter plan or a Pro Plan, which costs $79 per year.","Successful wearables are largely confined to a few select form factors. The wrist still rules the roost, or perhaps the ears, depending on how broad your definition is. Glasses are having a moment, while the ring gains traction. The pin/necklace never made much headway, though not for lack of trying.Misfit explored the space, and maybe you remember the lifelogging trend exemplified by Narrative and Memoto. The more recent generative AI push has given us Humane and Friend. The jury is still out on one of those, at least.Plaud.AI’s newly announced NotePin has the most in common with the latter two examples, with AI serving as its core competency. One key difference, however, is the simplicity of its core functionality: It’s a note taking device. And that’s pretty much it.Where lifelogging focused on either streaming or still images, NotePin is about conversations. The device utilizes large language model-based text transcriptions. The idea is to provide a more organic method for getting words and ideas down from meetings, school or just life, while the AI does the heavy lifting of digging through the hours of your largely nonsensical ramblings.“NotePin is more than just an AI device,” Plaud co-founder and CEO Nathan Hsu says in a release. “It’s your always-ready business partner, handling mundane, daily tasks so you can concentrate on what truly drives value in your life and career. This small but powerful device is reshaping the professional landscape, allowing users to optimize their day-to-day workflow and focus on what matters most.”That’s a lot of marketing speak, particularly the bit about “reshaping the professional landscape.” Among other things, the product has yet to actually launch. One thing Plaud has going for it versus the competition is an earlier product, the Plaud Note, that has both shipped and sold 200,000 units, according to the company.The GPT-4o-powered Plaud Note generated buzz. The $159 device snaps onto the back of a handset to provide note transcriptions similar to the new product.The NotePin, which hits preorder Wednesday, runs $10 more than its predecessor. The “free starter plan” gives users 300 minutes of transcription time a month. For $79 a year, users get the Pro Plan with 1,200 minutes a month and additional features like speaker labels and audio importing.","AI, Gadgets, Hardware, Humane, plaud.ai",,,,68
"Why AI can’t spell ‘strawberry’","Amanda Silberling",2024-08-27,https://techcrunch.com/2024/08/27/why-ai-cant-spell-strawberry/,"How many times does the letter “r” appear in the word “strawberry”? According to formidable AI products like GPT-4o and Claude, the answer is twice. Large language models (LLMs) can…","How many times does the letter “r” appear in the word “strawberry”? According to formidable AI products like GPT-4o and Claude, the answer is twice.Large language models (LLMs) can write essays and solve equations in seconds. They can synthesize terabytes of data faster than humans can open up a book. Yet, these seemingly omniscient AIs sometimes fail so spectacularly that the mishap turns into a viral meme, and we all rejoice in relief that maybe there’s still time before we must bow down to our new AI overlords.oh pic.twitter.com/K2Lr9iVkjQ— Rob DenBleyker (@RobDenBleyker) August 26, 2024The failure of large language models to understand the concepts of letters and syllables is indicative of a larger truth that we often forget: These things don’t have brains. They do not think like we do. They are not human, nor even particularly humanlike.Most LLMs are built on transformers, a kind of deep learning architecture. Transformer models break text into tokens, which can be full words, syllables, or letters, depending on the model.“LLMs are based on this transformer architecture, which notably is not actually reading text. What happens when you input a prompt is that it’s translated into an encoding,” Matthew Guzdial, an AI researcher and assistant professor at the University of Alberta, told TechCrunch. “When it sees the word ‘the,’ it has this one encoding of what ‘the’ means, but it does not know about ‘T,’ ‘H,’ ‘E.’”This is because the transformers are not able to take in or output actual text efficiently. Instead, the text is converted into numerical representations of itself, which is then contextualized to help the AI come up with a logical response. In other words, the AI might know that the tokens “straw” and “berry” make up “strawberry,” but it may not understand that “strawberry” is composed of the letters “s,” “t,” “r,” “a,” “w,” “b,” “e,” “r,” “r,” and “y,” in that specific order. Thus, it cannot tell you how many letters — let alone how many “r”s — appear in the word “strawberry.” This isn’t an easy issue to fix, since it’s embedded into the very architecture that makes these LLMs work. I thought Dune 2 was the best movie of 2024 until I watched this masterpiece (sound on). pic.twitter.com/W9WRhq9WuW— Peter Yang (@petergyang) March 7, 2024TechCrunch’s Kyle Wiggers dug into this problem last month and spoke to Sheridan Feucht, a PhD student at Northeastern University studying LLM interpretability.“It’s kind of hard to get around the question of what exactly a ‘word’ should be for a language model, and even if we got human experts to agree on a perfect token vocabulary, models would probably still find it useful to ‘chunk’ things even further,” Feucht told TechCrunch. “My guess would be that there’s no such thing as a perfect tokenizer due to this kind of fuzziness.”This problem becomes even more complex as an LLM learns more languages. For example, some tokenization methods might assume that a space in a sentence will always precede a new word, but many languages like Chinese, Japanese, Thai, Lao, Korean, Khmer and others do not use spaces to separate words. Google DeepMind AI researcher Yennie Jun found in a 2023 study that some languages need up to 10 times as many tokens as English to communicate the same meaning.“It’s probably best to let models look at characters directly without imposing tokenization, but right now that’s just computationally infeasible for transformers,” Feucht said.Image generators like Midjourney and DALL-E don’t use the transformer architecture that lies beneath the hood of text generators like ChatGPT. Instead, image generators usually use diffusion models, which reconstruct an image from noise. Diffusion models are trained on large databases of images, and they’re incentivized to try to re-create something like what they learned from training data.Image Credits: Adobe FireflyAsmelash Teka Hadgu, co-founder of Lesan and a fellow at the DAIR Institute, told TechCrunch, “Image generators tend to perform much better on artifacts like cars and people’s faces, and less so on smaller things like fingers and handwriting.”This could be because these smaller details don’t often appear as prominently in training sets as concepts like how trees usually have green leaves. The problems with diffusion models might be easier to fix than the ones plaguing transformers, though. Some image generators have improved at representing hands, for example, by training on more images of real, human hands.“Even just last year, all these models were really bad at fingers, and that’s exactly the same problem as text,” Guzdial explained. “They’re getting really good at it locally, so if you look at a hand with six or seven fingers on it, you could say, ‘Oh wow, that looks like a finger.’ Similarly, with the generated text, you could say, that looks like an ‘H,’ and that looks like a ‘P,’ but they’re really bad at structuring these whole things together.”Image Credits: Microsoft Designer (DALL-E 3)That’s why, if you ask an AI image generator to create a menu for a Mexican restaurant, you might get normal items like “Tacos,” but you’ll be more likely to find offerings like “Tamilos,” “Enchidaa” and “Burhiltos.”As these memes about spelling “strawberry” spill across the internet, OpenAI is working on a new AI product code-named Strawberry, which is supposed to be even more adept at reasoning. The growth of LLMs has been limited by the fact that there simply isn’t enough training data in the world to make products like ChatGPT more accurate. But Strawberry can reportedly generate accurate synthetic data to make OpenAI’s LLMs even better. According to The Information, Strawberry can solve the New York Times’ Connections word puzzles, which require creative thinking and pattern recognition to solve and can solve math equations that it hasn’t seen before.Meanwhile, Google DeepMind recently unveiled AlphaProof and AlphaGeometry 2, AI systems designed for formal math reasoning. Google says these two systems solved four out of six problems from the International Math Olympiad, which would be a good enough performance to earn as silver medal at the prestigious competition.It’s a bit of a troll that memes about AI being unable to spell “strawberry” are circulating at the same time as reports on OpenAI’s Strawberry. But OpenAI CEO Sam Altman jumped at the opportunity to show us that he’s got a pretty impressive berry yield in his garden.","AI, ChatGPT, large language models",,,,69
"Is open source AI possible, let alone the future? Find out at TechCrunch Disrupt 2024","Devin Coldewey",2024-08-27,https://techcrunch.com/2024/08/27/is-open-source-ai-even-possible-let-alone-the-future-find-out-at-disrupt-2024/,"Some believe open source AI is a way to break out of the familiar proprietary software quagmire that the technology has predictably fallen into. Hugging Face’s Irene Solaiman and AI2’s…","Some believe open source AI is a way to break out of the familiar proprietary software quagmire that the technology has predictably fallen into. Hugging Face’s Irene Solaiman and AI2’s Ali Farhadi will discuss this complex issue on a panel at TechCrunch Disrupt 2024 — taking place in San Francisco from October 28-30.AI may be a very new technology in some ways but in other ways, it’s stuck in the past, specifically in that a handful of decades-old companies are pulling the strings and fronting the cash. But unlike a desktop OS or office suite, the resource requirements of AI models make open source alternatives extremely difficult. What will it take to change that?To discuss the possibilities and challenges of defining, creating, and providing access to open AI systems, we have leaders of two champions of openness: Hugging Face, which provides open access to models, leaderboards, and datasets, and AI2 (short for Allen Institute for Artificial Intelligence), a research outfit committed to full transparency in its data, training, and models.Irene Solaiman is Hugging Face’s head of global policy, advocating for and researching safe, open, and responsible AI there and with other tech groups. Ali Farhadi’s AI2 spinoff XNOR was acquired by Apple, after which he returned to lead the organization. Both are proponents of openness and transparency — but both also acknowledge the novel structural barriers facing the embodiment of these principles in AI.It’s certain to be an extremely interesting conversation between these accomplished AI innovators (and their moderator, yours truly), so be sure to get your Disrupt 2024 ticket and join the AI Stage.","AI, Startups, TC, TechCrunch Disrupt 2024",,,,70
"Supio brings generative AI to personal injury cases","Kyle Wiggers",2024-08-27,https://techcrunch.com/2024/08/27/supio-brings-generative-ai-to-personal-injury-cases/,"Supio uses generative AI to automate bulk data collection and aggregation for legal teams. It emerged from stealth Tuesday with a $25 million investment.","Legal work is incredibly labor- and time-intensive, requiring piecing together cases from vast amounts of evidence. That’s driving some firms to pilot AI to streamline certain steps; according to a 2023 survey by the American Bar Association, 35% of law firms now use AI tools in their practice. OpenAI-backed Harvey is among the big winners so far in the burgeoning AI legal tech space, alongside startups such as Leya and Klarity. But there’s room for one more, says Jerry Zhou and Kyle Lam, the co-founders of an AI platform for personal injury law called Supio, which emerged from stealth Tuesday with a $25 million investment led by Sapphire Ventures.Supio uses generative AI to automate bulk data collection and aggregation for legal teams. In addition to summarizing info, the platform can organize and identify files — and snippets within files — that might be useful in outlining, drafting and presenting a case, Zhou said.“After attending numerous conferences and meeting with hundreds of lawyers across the U.S., Lam and I decided to focus on personal injury and mass tort plaintiff law,” said Zhou, who’s also Supio’s CEO. “These are practice areas that require compiling thousands of documents from multiple sources, and analyzing and finding information from the data within them.”Zhou and Lam are childhood friends whose career paths have often intersected. The pair worked at Microsoft, specifically in the Office 365 org, and together again at tax compliance software firm Avalara. The idea for Supio came about after Zhou and Lam left Avalara to pursue building a business that could, in Zhou’s words, “help understand complex data and identify critical connections within certain data.”“We pursued the legal industry because we knew it wasn’t just document-heavy — it was also due for technology innovation,” Zhou said. “[These are] practice areas that require compiling thousands of documents from multiple sources and analyzing and finding information from the data within them.”Personal injury and mass tort cases, or civil suits filed on behalf of victims harmed by negligence, like the sale of defective products, typically unfold across paperwork including medical records, police reports, insurance claims, financial statements, consumer complaints and so on. What Supio does, Zhou explained, is generate demand letters — letters outlining the legal disputes to be resolved — as well as supporting documentation, while letting users search the evidence through a chatbot-type interface.It sounds a lot like EvenUp, a startup that taps AI to generate legal documents to assess injury cases. Companies like Lawyaw and Atrium also apply AI to the task of drafting initial complaints. But Zhou claims that Supio is more complex in its technical approach.“Law is extremely complex and nuanced, and most creators of work productivity tools lack a true understanding of the legal documents lawyers ultimately have to produce, which inhibits the development of accurate [AI] models,” Zhou said. “Supio has hundreds of models running at a given time with different functions to try to understand and classify documents. We then measure this against the work products that are expected and improve these results gradually.”AI like Supio’s is powerful stuff in theory — but also fraught. Given the sensitive nature of most legal disputes, lawyers and law firms might be reluctant to grant (or be prohibited from granting) a tool like Supio access to any case docs.Late last year, the State Bar of California released guidance instructing legal professionals to refrain from putting clients’ information into AI tools that “lack reasonable or adequate security.” (Zhou says that Supio stores client data in its country of origin and has security protocols that adhere to privacy regulations including HIPAA and GDPR.)Another concern with AI legal tech is AI’s perjurious proclivities. Last year, a group of lawyers with the firm Levidow, Levidow & Oberman, P.C. tapped ChatGPT, OpenAI’s AI-powered chatbot, to prepare a personal injury complaint against an airline. The result was disastrous: ChatGPT invented citations, misidentified judges and referred to airlines that don’t exist. The federal judge overseeing the case ultimately imposed a $5,000 fine on the lawyers and their employer.Courts are frantically preparing for a rise in inaccurate filings attributable to the uptake in AI legal research tools.In November 2023, the U.S. Court of Appeals for the Fifth Circuit proposed a rule (since scrapped) requiring that any professional filing legal paperwork drafted with the help of AI certify that a human reviewed the documents for accuracy and approved them. Earlier that same year, a district judge in Texas issued an order banning the use of generative AI to write court filings without a human fact-check. The risks with AI are such that, in a recent survey of more than 300 general counsel and senior legal officers at large corporations, 25% said that they believe their outside counsel shouldn’t use AI. A separate poll by Thomson Reuters found that one in five law firms have issued warnings around the use of AI.Zhou makes the remarkable claim that Supio’s AI performs “better than human levels of accuracy” and “without hallucinations,” i.e. it never fibs.“Supio is providing flexible software featuring AI that can organize unstructured data and produce reliable results because we know timing and accuracy are critical,” he said.It’s not clear what’s meant by “human level;” Zhou didn’t share any test or benchmark results. But I would note that just because AI can achieve feats like passing the bar exam doesn’t mean it has the skills attorneys gain through experience and education. (The National Conference of Bar Examiners argues as much.) As for the “without hallucinations” bit of Zhou’s claim, it’s not backed up by data, either — at least none that Zhou volunteered.Yet some firms believe Supio has promise. According to Zhou, Supio is currently working with around 30 personal injury and mass tort law firms and expects that number to reach 100 firms by the end of the year. The startup’s annual recurring revenue has eclipsed $1 million, meanwhile, with most of the money coming from subscription fees that Supio charges based on case volume. It could be a case of keeping up with the Joneses. In a survey of legal execs published by LexisNexis, nearly all (90%) said that they anticipate their investment in generative AI will increase over the next five years; the same poll found that 43% of firms now have a dedicated budget for generative AI. Gartner predicts that the allure of generative AI will drive the legal tech market to $50 billion in value by 2027, almost double what it was worth in 2022 ($25.6 million).Against this dramatic backdrop, Seattle-based Supio keeps chugging along. The company has 27 employees and expects to double headcount in the next 12 months.Having raised a total of $33 million, Zhou says that Supio aims to expand its customer base in the near term — and eventually to “scale to address other law specialities.”Bonfire Ventures and Foothill Ventures also participated in Supio’s latest tranche (a Series A). Zhou says it was oversubscribed but wouldn’t give the valuation.","AI, AI, Funding, Fundraising, Generative AI, legaltech, Sapphire Ventures, startup, Startups, supio",,,,71
"Google’s AI Overviews in Hindi need a quality upgrade","Ivan Mehta",2024-08-27,https://techcrunch.com/2024/08/27/googles-ai-overviews-in-hindi-need-a-quality-upgrade/,"Given India’s language diversity, digital content companies already face a challenge in trying to show and translate content accurately. Google is facing a similar problem with AI Overviews recently rolled…","Given India’s language diversity, digital content companies already face a challenge in trying to show and translate content accurately. Google is facing a similar problem with AI Overviews recently rolled out in the country.The company introduced Hindi support for AI Overviews in the country earlier in August. Users in India can also switch between Hindi and English without leaving the search page. But the feature is disappointingly inconsistent.One simple example was a result we picked from Google’s blog. The GIF showed an answer for “Cheeni ki jagah chai mai kya daal sakte hai?” which translates to “What is a substitute for sugar in tea?” During testing, we changed up the order of the words to “Chai mai cheeni ke jagah kya daal sakte hai?” and Google simply didn’t show an answer.Another problem we spotted was translating English words literally. When we asked in Hindi, “What kind of food can we eat during summer?” one of the answers was “Chiknai wali cheezien,” which translates to “Sticky things” — and that’s confusing. When I switched over to English, Google showed me “Oily” an an option, which is a very different thing from “sticky” when it comes to food. Either way, it’s kind of a weird suggestion.In another instance, when we asked about YouTube’s ownership, AI Overviews said “Until 16 February 2023, Neal Mohan was Google’s CEO” in Hindi, which is incorrect. The English text had the correct version, saying, “As of 16 February 2023, Neal Mohan is Google CEO.”Image Credits: Google (screenshot)There are also qualitative problems. When we asked, “When is Diwali this year?” instead of getting a simple answer, we got a paragraph on last year’s Diwali, then a carousel of links, and then the actual answer we were looking for.When we asked if one can eat food with spices in both Hindi and English multiple times, we got inconsistent answers through AI Overview.However, there are more concerning results related to other topics like menstruation and pregnancy. For one of our questions, about when someone should think about having kids after marriage, the overview answer’s first paragraph said couples should wait for at least two years, in confusing Hindi.It also mentioned that if someone gets married around the age of 25, they have “three years” — without specifying for what. This paragraph was apparently sourced from a slideshow article in Hindi on an Indian news site, which had written the info based on various opinions on Quora and other blogs.Image Credits: Google (screenshot)When we asked about what food to eat when someone is menstruating, some of the answers suggested “Drinking milk with many things” and lemon for mood swings.Image Credits: Google (screenshot)Google’s AI Overview also misses context. When we asked about food places in Delhi, it suggested that Bangla Sahib Gurudwara, a place of worship for Sikhs, is open round the clock and you can get tea and Indian snacks like Samosa and Kachori. However, this fails to mention something important that the source article did: that you could get these items outside the Gurudwara, an operative word that the AI tool missed while summarizing. The snacks are not in the place of worship.Image Credits: Google (screenshot)Some of the results for similar questions in English are much better than the Hindi ones. This could be partially due to more and better sources available in that language. But some of the problems we highlighted were due to Google systems’ mistakes, such as out-of-context summaries and inaccurate translations. Google has worked on search and language problems in India, and the expectation is that it should have delivered a better outcome at its first go.Google told TechCrunch that its AI Overviews only appear for queries where it has a high confidence in the quality of the output, saying the feature is “rooted in our core search quality systems” and will “only show information that’s backed up by top web results.“Our tests show that the accuracy rate for AI Overviews is on par with other features like Featured Snippets. When issues arise, they may be the result of our systems misinterpreting web content or reflecting inaccuracies on the web — and we use these examples to improve, as we do with all Search features,” a Google spokesperson told TechCrunch. Google can blame the quality of the sources that it is citing. However, it’s Google’s algorithm that decided that the question and sources are worthwhile to be summarized by AI. Not all users will look at the material on source sites and merely point at Google for displaying inaccurate or incomprehensible answers. AI Overviews has been a disappointing endeavor for Google. Earlier this year, the company caught a lot of flack for surfacing answers from Reddit telling a user to add glue to pizza. AI Overviews told another user to eat “one small rock per day,” an answer that was sourced from The Onion. Many of the examples we tested in Hindi simply didn’t provide correct information about the topic.India has more than 830 million internet users, and a good chunk of them use Google for search. If the company wants more folks to use AI Overviews in local languages, it will need to step up its game in terms of language and content accuracy.","AI, AI search, Google, Google India, India",,,,72
"Calendar tool Clockwise adds new AI-powered interface called Prism","Ivan Mehta",2024-08-27,https://techcrunch.com/2024/08/27/calendar-tool-clockwise-launches-new-ai-powered-interface-called-prism/,"Clockwise is changing up its interface with an AI-powered assistant called Prism that lets you manage calendar invites and scheduling with text prompts.","Smart scheduling and calendar tool Clockwise is changing up its interface with an AI-powered assistant called Prism that lets you manage scheduling conflicts, create or clear events in bulk, and turn to-do lists into calendar blocks with text prompts.Like rival startups YC-backed Vimcal and Reclaim, which got acquired by Dropbox this month, Clockwise is aimed at companies and focuses on streamlining schedules for teams — you can still use it as an individual, though.The new AI assistant can turn typed instructions into calendar events — type a query like “Create a link to schedule a meeting with Severian next week,” and you’ll get a link or a text block to share your availability. And if your suggested timing for a meeting conflicts with another event, the tool will suggest an alternative time slot for the meeting.Prism also lets you share a link of suggested meeting times other participants can respond to, and the link will surface potential confilicts, too.But if you are planning an urgent meeting, Prism can look across different team members’ schedules and select an optimal time and automatically reschedule conflicting events.You also get the ability to schedule tasks from a to-do list in your calendar and move them if you happen to get into a meeting. And if you want to schedule similar meetings with a bunch of people, you can type a prompt like, “Schedule 15 minute one-on-ones with Frank, Robin, Nami, and Tony.”Image Credits: ClockwiseYou can also use commands like “Reschedule my afternoon” or “Clear my Monday morning” to swifly reschedule tasks.Matt Martin, CEO of Clockwise, told TechCrunch that the company is using a custom scheduling engine that interfaces with natural language queries and figures out the conflicts and optimal timings.“I’ve seen a lot of startups try to naively connect LLMs directly to Google Calendar APIs. It’s no wonder those tools fall flat on their face when you press beyond anything but the simplest use cases. We’ve spent seven years building the most advanced scheduling engine in the world, and it’s that layer that enables Prism to quickly and reliably make decisions to find the best slots for tasks and meetings,” Martin said. Clockwise is offering Prism for free to all customers, and working on deeper integration with Google Calendar and better support for weekly schedules.","AI, Calendar Apps, Clockwise, scheduling, task management",,,,73
"Elon Musk unexpectedly offers support for California’s AI bill","Devin Coldewey",2024-08-26,https://techcrunch.com/2024/08/26/elon-musk-unexpectedly-offers-support-for-californias-ai-bill/,"Elon Musk has come out in support of California’s SB 1047, a bill that requires makers of very large AI models to create and document safeguards against those models causing…","Elon Musk has come out in support of California’s SB 1047, a bill that requires makers of very large AI models to create and document safeguards against those models causing serious harm.“This is a tough call and will make some people upset, but, all things considered, I think California should probably pass the SB 1047 AI safety bill,” he wrote on X on Monday afternoon. “For over 20 years, I have been an advocate for AI regulation, just as we regulate any product/technology that is a potential risk.”Musk — whose own large AI model company, xAI, would be subject to SB 1047’s requirements despite his pledge to leave California — has warned of the dangers of runaway AI in the past.Meanwhile, rival outfit OpenAI recently announced it opposes the bill, supporting an alternative bill instead.","AI, In Brief",,,,74
"OpenAI, Adobe and Microsoft support California bill requiring watermarks on AI content","Maxwell Zeff",2024-08-26,https://techcrunch.com/2024/08/26/openai-adobe-microsoft-support-california-bill-requiring-watermarks-on-ai-content/,"OpenAI, Adobe and Microsoft have thrown their support behind a California bill requiring tech companies to label AI-generated content, according to letters from the companies viewed by TechCrunch. The bill…","OpenAI, Adobe and Microsoft have thrown their support behind a California bill requiring tech companies to label AI-generated content, according to letters from the companies viewed by TechCrunch. The bill is headed for a final vote in August.AB 3211 requires watermarks in the metadata of AI-generated photos, videos and audio clips. Lots of AI companies already do this, but most people don’t read metadata. AB 3211 also requires large online platforms, like Instagram or X, to label AI-generated content in a way average viewers can understand.OpenAI, Adobe and Microsoft are part of the Coalition for Content Provenance and Authenticity, which helped create C2PA metadata — a widely used standard for marking AI-generated content.A trade group representing Adobe, Microsoft and the nation’s largest software makers previously opposed AB 3211 in April, calling the bill “unworkable” and “overly burdensome” in a letter to California lawmakers. However, amendments to the bill appear to have changed their minds.","AB 3211, AI, AI regulation, ChatGPT, Government & Policy, OpenAI, watermarks",,,,75
"Anthropic publishes the ‘system prompts’ that make Claude tick","Kyle Wiggers",2024-08-26,https://techcrunch.com/2024/08/26/anthropic-publishes-the-system-prompt-that-makes-claude-tick/,"Generative AI models aren’t actually humanlike. They have no intelligence or personality — they’re simply statistical systems predicting the likeliest next words in a sentence. But like interns at a…","Generative AI models aren’t actually humanlike. They have no intelligence or personality — they’re simply statistical systems predicting the likeliest next words in a sentence. But like interns at a tyrannical workplace, they do follow instructions without complaint — including initial “system prompts” that prime the models with their basic qualities and what they should and shouldn’t do.Every generative AI vendor, from OpenAI to Anthropic, uses system prompts to prevent (or at least try to prevent) models from behaving badly, and to steer the general tone and sentiment of the models’ replies. For instance, a prompt might tell a model it should be polite but never apologetic, or to be honest about the fact that it can’t know everything.But vendors usually keep system prompts close to the chest — presumably for competitive reasons, but also perhaps because knowing the system prompt may suggest ways to circumvent it. The only way to expose GPT-4o‘s system prompt, for example, is through a prompt injection attack. And even then, the system’s output can’t be trusted completely.However, Anthropic, in its continued effort to paint itself as a more ethical, transparent AI vendor, has published the system prompts for its latest models (Claude 3 Opus, Claude 3.5 Sonnet and Claude 3 Haiku) in the Claude iOS and Android apps and on the web.Alex Albert, head of Anthropic’s developer relations, said in a post on X that Anthropic plans to make this sort of disclosure a regular thing as it updates and fine-tunes its system prompts.We've added a new system prompts release notes section to our docs. We're going to log changes we make to the default system prompts on Claude dot ai and our mobile apps. (The system prompt does not affect the API.) pic.twitter.com/9mBwv2SgB1— Alex Albert (@alexalbert__) August 26, 2024The latest prompts, dated July 12, outline very clearly what the Claude models can’t do — e.g. “Claude cannot open URLs, links, or videos.” Facial recognition is a big no-no; the system prompt for Claude Opus tells the model to “always respond as if it is completely face blind” and to “avoid identifying or naming any humans in [images].”But the prompts also describe certain personality traits and characteristics — traits and characteristics that Anthropic would have the Claude models exemplify.The prompt for Claude 3 Opus, for instance, says that Claude is to appear as if it “[is] very smart and intellectually curious,” and “enjoys hearing what humans think on an issue and engaging in discussion on a wide variety of topics.” It also instructs Claude to treat controversial topics with impartiality and objectivity, providing “careful thoughts” and “clear information” — and never to begin responses with the words “certainly” or “absolutely.”It’s all a bit strange to this human, these system prompts, which are written like an actor in a stage play might write a character analysis sheet. The prompt for Opus ends with “Claude is now being connected with a human,” which gives the impression that Claude is some sort of consciousness on the other end of the screen whose only purpose is to fulfill the whims of its human conversation partners.But of course that’s an illusion. If the prompts for Claude tell us anything, it’s that without human guidance and hand-holding, these models are frighteningly blank slates.With these new system prompt changelogs — the first of their kind from a major AI vendor — Anthropic is exerting pressure on competitors to publish the same. We’ll have to see if the gambit works.","AI, AI, Anthropic, Claude, Generative AI, prompts, system prompts",,,,76
"Five months after Microsoft hired its founders, Inflection adds usage caps to Pi","Maxwell Zeff",2024-08-26,https://techcrunch.com/2024/08/26/five-months-after-microsoft-hired-its-founders-inflection-adds-usage-caps-to-pi/,"Inflection will cap free access to its AI chatbot Pi in the coming months, the startup tells TechCrunch. Users can also now export their conversations off the AI chatbot, as…","Inflection will cap free access to its AI chatbot Pi in the coming months, the startup tells TechCrunch. Users can also now export their conversations off the AI chatbot, as the new CEO shifts the company’s focus toward enterprise products.The usage caps come just a year after Inflection raised $1.3 billion to build out the “emotionally intelligent” AI chatbot. One of the lead investors in that deal, Microsoft, hired away Inflection’s founders and most of its staff five months ago, paying $650 million to license its AI model and repay investors. At that time, Inflection said Pi had millions of weekly users.That deal has drawn attention from antitrust regulators in the U.S. and U.K., who are now investigating whether Microsoft was anticompetitive when it effectively ate Inflection alive. Since then, CEO Sean White has steered the gutted startup through this difficult post-acqui-hire phase.Two weeks ago, the company was planning to sunset Pi, an Inflection spokesperson told TechCrunch at the time, which is understandable considering Inflection is more resource constrained than it once was.“We have to very carefully apply our resources,” White told TechCrunch.Those plans have since changed, and White now says the company is committed to keeping consumer Pi afloat. However, Inflection aims to reduce the strain on its GPU resources with usage caps on the free chatbot, which Inflection says will mostly affect power users. As to the details of those caps, a spokesperson told TechCrunch that the “exact limits are still being determined.”Inflection is also giving users a chance to move any important conversations with Pi off the chatbot. It’s partnering with the Data Transfers Initiative to allow users to export their conversations off of Pi, or theoretically import conversations from other chatbots.White sees Inflection as setting a new standard for the AI industry in data mobility and transferability, hoping other companies will follow suit. Because Inflection is the first to make such a move, users can’t actually import their conversations with Pi to ChatGPT or any other chatbots; they can just take them off of Pi.The path forward for Inflection may be in licensing AI models for companies to build into their own systems. White said 13,000 organizations have filled out an application showing interest in gaining API access to Pi.“Honestly, we don’t have all the resources to deal with 13,000 requests, and so we’ve had to be fairly selective in who we start to work with,” said White.He added that the company has held meetings with large banks, insurers and several Fortune 500 companies about potentially using its enterprise products. White claims Inflection’s fine-tuning infrastructure allows it to customize AI models to specific organizations better than competitors. He hopes to announce the first enterprise products and partnerships in the fall.","acqui-hires, AI, AI chatbot, inflection, Microsoft, Startups",,,,77
"Viggle makes controllable AI characters for memes and visualizing ideas","Maxwell Zeff",2024-08-26,https://techcrunch.com/2024/08/26/viggle-makes-controllable-ai-characters-for-memes-and-visualizing-ideas/,"You might not know Viggle AI, but you’ve likely seen the viral memes it created. The Canadian AI startup is responsible for dozens of videos remixing the rapper Lil Yachty…","You might not know Viggle AI, but you’ve likely seen the viral memes it created. The Canadian AI startup is responsible for dozens of videos remixing the rapper Lil Yachty bouncing onstage at a summer music festival. In one video, Lil Yachty is replaced by Joaquin Phoenix’s Joker. In another, Jesus seemed to be hyping the crowd up. Users made countless versions of this video, but one AI startup was fueling the memes. And Viggle’s CEO says YouTube videos fuel its AI models.Viggle trained a 3D-video foundation model, JST-1, to have a “genuine understanding of physics,” as the company claims in its press release. Viggle CEO Hang Chu says the key difference between Viggle and other AI video models is that Viggle allows users to specify the motion they want characters to take on. Other AI video models will often create unrealistic character motions that don’t abide by the laws of physics, but Chu claims Viggle’s models are different.“We are essentially building a new type of graphics engine, but purely with neural networks,” said Chu in an interview. “The model itself is quite different from existing video generators, which are mainly pixel based, and don’t really understand structure and properties of physics. Our model is designed to have such understanding, and that’s why it’s been significantly better in terms of controllability and efficiency of generation.”To create the video of the Joker as Lil Yachty, for instance, just upload the original video (Lil Yachty dancing onstage) and an image of the character (the Joker) to take on that motion. Alternatively, users can upload images of characters alongside text prompts with instructions on how to animate them. As a third option, Viggle allows users to create animated characters from scratch with text prompts alone.But the memes are only a small percent of Viggle’s users; Chu says the model has seen wide adoption as a visualization tool for creatives. The videos are far from perfect — they’re shaky and the faces are expressionless — but Chu says it’s proven effective for filmmakers, animators and video game designers to turn their ideas into something visual. Right now, Viggle’s models only create characters, but Chu hopes to enable more complex videos later on.Viggle currently offers a free, limited version of its AI model on Discord and its web app. The company also offers a $9.99 subscription for increased capacity, and gives some creators special access through a creator program. The CEO says Viggle is talking with film and video game studios about licensing the technology, but he also is seeing adoption amongst independent animators and content creators.On Monday, Viggle announced it had raised a $19 million Series A led by Andreessen Horowitz, with participation from Two Small Fish. The startup says this round will help Viggle scale, accelerate product development and expand its team. Viggle tells TechCrunch that it partners with Google Cloud, among other cloud providers, to train and run its AI models. Those Google Cloud partnerships often include access to GPU and TPU clusters, but typically not YouTube videos to train AI models on.Training dataDuring TechCrunch’s interview with Chu, we asked what data Viggle’s AI video models were trained on.“So far we’ve been relying on data that has been publicly available,” said Chu, relaying a similar line to what OpenAI’s CTO Mira Murati answered about Sora’s training data.Asked if Viggle’s training dataset included YouTube videos, Chu responded plainly: “Yeah.”That might be a problem. In April, YouTube CEO Neal Mohan told Bloomberg that using YouTube videos to train an AI text-to-video generator would be a “clear violation” of the platform’s terms of service. The comments were in the context of OpenAI potentially having used YouTube videos to train Sora.Mohan clarified that Google, which owns YouTube, may have contracts with certain creators to use their videos in training datasets for Google DeepMind’s Gemini. However, harvesting video from the platform is not allowed, according to Mohan and YouTube’s terms of service, without obtaining permission from the company.Following TechCrunch’s interview with Viggle’s CEO, a spokesperson for Viggle emailed to backtrack on Chu’s statement, telling TechCrunch the CEO “spoke too soon in regards to if Viggle uses YouTube data as training. In truth, Hang/Viggle is unable to share details of their training data.”After pointing out that Chu’s earlier comments were on the record and asking for a clear statement on the matter,  Viggle’s spokesperson confirmed in their reply that the AI startup trains on YouTube videos:Viggle leverages a variety of public sources, including YouTube, to generate AI content. Our training data has been carefully curated and refined, ensuring compliance with all terms of service throughout the process. We prioritize maintaining strong relationships with platforms like YouTube, and we are committed to respecting their terms by avoiding massive amounts of downloads and any other actions that would involve unauthorized video downloads.We reached out to spokespeople for YouTube and Google, but have yet to hear back.The startup joins others using YouTube as training data and thus operating in a gray area. It’s been reported that lots of AI model developers — including Nvidia, Apple and Anthropic — use YouTube video transcriptions or clips for training. It’s the dirty secret in Silicon Valley that’s not so secret: everybody is likely doing it. What’s actually rare is saying it out loud.","a16z, AI, Exclusive, generative AI videos, Memes, Startups, tech startups",,,,78
"In 2024, it really is better to run a startup in San Francisco, according to data and founders who’ve relocated","Julie Bort",2024-08-25,https://techcrunch.com/2024/08/25/in-2024-it-really-is-better-to-run-a-startup-in-san-francisco-according-to-data-and-founders-whove-relocated/,"San Francisco’s AI startup boom is so big, even international founders who don’t run AI startups are relocating there to help their companies grow, according to several founders who recently…","San Francisco’s AI startup boom is so big, even international founders who don’t run AI startups are relocating there to help their companies grow, according to several founders who recently moved. This is largely because the tech talent and investor money is still overwhelmingly concentrated there, according to new data that VC firm SignalFire exclusively shared with TechCrunch.The SF Bay Area remains by far the largest share of all tech employees in the U.S., with 49% of all Big Tech engineers and 27% of startup engineers, data from SignalFire’s Beacon platform shows. SignalFire, which prides itself on big data-driven analysis, also sees that the Bay Area’s share of tech engineers has been increasing since 2022 (not declining) and its share of this talent pool is more than 4x those of runner-up Seattle. The area is home to 12% of all the biggest VC-backed founders and 52% of startup employees, more than any other region.The analysis by SignalFire partner (and former TechCrunch reporter) Josh Constine led him to declare in a recent blog post, “We found that anecdotes about the decline of tech in San Francisco are overstated. SF still dominates all other U.S. cities when it comes to concentrations of tech talent and capital, and its lead is even larger when it comes to the recent AI boom.”Unify’s founder relocated from Berlin after raising $8 millionTake London native Daniel Lenton, founder of Unify, originally based in Berlin. Unify, a Y Combinator W23 grad, is building a neural router that automatically sends individual prompts to the best LLM for the task. It says it helps companies control costs while using models from multiple AI sources. Lenton, who has raised $8 million for Unify from SignalFire, Microsoft’s M12 Capital, and Ronny Conway’s A.Capital Ventures, had no trouble meeting with Silicon Valley investors when he was in Berlin, he said. He even talked with the giant firms.“It wasn’t a massive challenge for me to be having conversations with the likes of Andreessen and Sequoia and Accel,” he said. “You’re not locked out of the investment market when you’re not there. You can do a lot of things remotely, even getting introductions to people.”But he found himself returning to San Francisco after his YC experience, and each time he met clients, potential clients, partners, and collaborators. The clincher for relocating was a month’s visit in June. “In just one week, every day that week, I was having lunch at different offices” of other larger AI tech startups, he says. “On the whiteboard, brainstorming together.” There are the countless other, more formal events. That’s not just due to “Cerebral” Valley, the San Francisco neighborhood with a collection of AI startups and a burgeoning social scene for the many young 20-somethings who work for them, although that’s part of the draw. It’s also investor dinners and events, such as a recent Andreessen Horowitz event for AI founders that Lenton attended. “It’s just very, very useful.”While Lenton has relocated himself and made San Francisco the official headquarters for his startup, he hasn’t required his eight-person team, who all live in different cities, to come with him.Lago moved to SF instead of New YorkAnh-Tho Chuong, co-founder and CEO of open source billing platform Lago, has a similar opinion. She’s relocating herself and her company headquarters from Paris to San Francisco — even though Paris is a European hub of AI startup activity with breakout startups like Mistral. Because Lago is also a YC grad (S21) and incorporated in the U.S., moving to the U.S. was always her plan, she says. But the plan was to go to New York, for ease-of-travel and time-zone reasons. “A year ago, everybody was moving from SF to New York and they were saying SF was dead,” she told TechCrunch. But then she spent the month of May in San Francisco for business, “and I see everybody is back.” She’s not the only one noticing and saying this. Jason Lemkin, founder of SaaStr, a community for business software startups known for its events, this week posted on X, “So I’m back full time-ish to the SF Bay Area. As, often quietly, are so many leaders and execs I’ve known for years.”Lemkin explains that the area is “clearly the center of the AI boom even if many are based outside of it, in Paris and elsewhere.” Like others, he credits YC and other accelerators for bringing startups to town. “The SF Bay Area is back.”For Chuong, the choice of San Francisco came down to just how much easier it was for her to build her company there. Lago is not an AI company, but it counts AI companies as customers. It offers what it’s calling an open source alternative to Stripe and is focused on metering and usage-based billing. Lago has raised $22 million total so far, she says, from a host of angels and VCs like SignalFire and FirstMark.Lago’s customers are largely cloud startups, including many AI startups. She’s been growing the company through word of mouth and inbound requests, much of them from Bay Area companies. As she looks for her first marketing hires, “we feel like the talent pool is better. Also the customer pool is better” in San Francisco than anywhere else, she said.Manufactured luckChuong also credited YC for making San Francisco such a hub, specifically for hosting an ongoing array of events from alumni gatherings to AI founder happy hours. That’s in addition to the formal events it has with current cohorts and its alumni-only social network, Bookface.But every city has plenty of events, meetups, and hireable people. Both these founders, and the SignalFire data, point to something else that the Bay Area — especially San Francisco — offers: serendipitous connections. When so many people in the same industry are concentrated in tighter confines, bumping into someone useful becomes the norm, not the rarity. Chuong says she met three other YC founders working on similar companies in the SoMa San Francisco neighborhood building where she was temporarily living. “We just started collaborating on what we’re building, on our challenges, and everything was super organic. And I felt like there’s so much of a support system here that it makes no sense to go to New York.”This is not to say that startups built elsewhere in the country or world can’t succeed. Many do. But as Y Combinator partner Diana Hu described it on a recent podcast, people choose to relocate because they feel that “San Francisco is the place in the world where you can manufacture luck.”","AI, San Francisco, Startups",,,,79
"Stephen Wolfram thinks we need philosophers working on big questions around AI","Ron Miller",2024-08-25,https://techcrunch.com/2024/08/25/stephen-wolfram-thinks-we-need-philosophers-working-on-big-questions-around-ai/,"As AI developers and others start to think more deeply about how computers and people intersect, Stephan Wolfram says it is becoming a much more of a philosophical exercise","Mathematician and scientist Stephen Wolfram grew up in a household where his mother was a philosophy professor at Oxford University. As such, his younger self didn’t want anything to do with the subject, but an older and perhaps wiser Wolfram sees value in thinking deeply about things. Now he wants to bring some of that deep philosophical rigor to AI research to help us better understand the issues we encounter as AI becomes more capable.Wolfram was something of a child prodigy, publishing his first scientific paper at 15 and graduating from Caltech with a doctorate at 20. His impressive body of work crosses science, math and computing: He developed Mathematica, Wolfram Alpha and the Wolfram Language, a powerful computational programming language.“My main life work, along with basic science, has been building our Wolfram language computational language for the purpose of having a way to express things computationally that’s useful to both humans and computers,” Wolfram told TechCrunch.As AI developers and others start to think more deeply about how computers and people intersect, Wolfram says it is becoming much more of a philosophical exercise, involving thinking in the pure sense about the implications this kind of technology may have on humanity. That kind of complex thinking is linked to classical philosophy. “The question is what do you think about, and that’s a different kind of question, and it’s a question that’s found more in traditional philosophy than it is in the traditional STEM,” he said.For example, when you start talking about how to put guardrails on AI, these are essentially philosophical questions. “Sometimes in the tech industry, when people talk about how we should set up this or that thing with AI, some may say, ‘Well, let’s just get AI to do the right thing.’ And that leads to, ‘Well, what is the right thing?’” And determining moral choices is a philosophical exercise.He says he has had “horrifying discussions” with companies that are putting AI out into the world, clearly without thinking about this. “The attempted Socratic discussion about how you think about these kinds of issues, you would be shocked at the extent to which people are not thinking clearly about these issues. Now, I don’t know how to resolve these issues. That’s the challenge, but it’s a place where these kinds of philosophical questions, I think, are of current importance.”He says scientists in general have a hard time thinking about things in philosophical terms. “One thing I’ve noticed that’s really kind of striking is that when you talk to scientists, and you talk about big, new ideas, they find that kind of disorienting because in science, that is not typically what happens,” he said. “Science is an incremental field where you’re not expecting that you’re going to be confronted with a major different way of thinking about things.”If the main work of philosophy is to answer big existential questions, he sees us coming into a golden age of philosophy due to the growing influence of AI and all of the questions that it’s raising. In his view, a lot of the questions that we’re now being confronted with by AI are actually at their core of traditional philosophical questions.“I find that the groups of philosophers that I talk to are actually much more agile when they think paradigmatically about different kinds of things,” he said.One such meeting on his journey was with a group of masters’ philosophy students at Ralston College in Savannah, Georgia. Wolfram spoke to students there about the coming collision of liberal arts and philosophy with technology. In fact, Wolfram says he has reread Plato’s “Republic” because he wants to return to the roots of Western philosophy in his own thinking.“And this question of ‘if the AIs run the world, how do we want them to do that? How do we think about that process? What’s the kind of modernization of political philosophy in the time of AI?’ These kinds of things, this goes right back to foundational questions that Plato talked about,” he told students.Rumi Allbert, a student in the Ralston program, who has spent his career working in data science and also participated in Wolfram Summer School, an annual program designed to help students understand Wolfram’s approach to applying science to business ideas, was fascinated with Wolfram’s thinking.“It’s very, very interesting that a guy like Dr. Wolfram has such an interest in philosophy, and I think that speaks to the volume of importance of philosophy and the humanistic approach to life. Because it seems to me, he has gotten so developed in his own field, [it has evolved] to more of a philosophical question,” Allbert said.That Wolfram, who has been involved on the forefront of computer science for a half century, is seeing the connections between philosophy and technology, could be a signal that it’s time to start addressing these questions around AI usage in a much broader way than purely as a math problem. And perhaps bringing philosophers into the discussion is a good way to achieve that.","AI, philosophy, Stephen Wolfram",,,,80
"VCs are so eager for AI startups, they’re buying into each others’ SPVs at high prices","Rebecca Szkutak",2024-08-24,https://techcrunch.com/2024/08/24/vcs-are-so-eager-for-ai-startups-theyre-buying-into-each-others-spvs-at-high-prices/,"VCs are increasingly buying shares of late-stage startups on the secondary market as they try to get pieces of the hottest ones — especially AI companies. But they are also increasingly doing so through financial instruments called special purpose vehicles (SVPs). Some of those SPVs are becoming such hot commodities…","VCs are increasingly buying shares of late-stage startups on the secondary market as they try to get pieces of the hottest ones — especially AI companies. But they are also increasingly doing so through financial instruments called special purpose vehicles (SVPs). Some of those SPVs are becoming such hot commodities that they are commanding premium prices.While that’s good for the VC selling an SPV, it’s a riskier choice for the buyers. And all of this is another sign that AI startups are brewing a bubble.The secondary market is where existing shareholders, such as startup employees or VCs who bought shares directly from a startup in a fundraising round, can sell some of their shares to others. But because private companies like startups have a say in who can own their shares, many VCs are locked out. The VCs that do have access are setting up SPVs and selling access to their shares to other VCs or investors of their choosing, such as high-net-worth individuals who are accredited investors.Yet, buying into a VC’s SPV is not buying the startup’s actual stock. It’s buying shares of the SPV vehicle that controls a certain number of the startup’s shares.“Buying units of the SPV means [VCs] won’t own shares in the actual company; they’ll technically be an investor in another investor’s fund,” Javier Avalos, the co-founder and CEO of secondary deal tracking platform Caplight, told TechCrunch.Some sell for 30% higher pricesWhile SPVs are nothing new, VCs selling shares of them at a premium is an emerging trend worth paying attention to, Avalos said. For example, he’s seen instances where SPVs that hold shares of Anthropic or xAI are marking up prices 30% higher than what the shares sold for in the last fundraising round or tender offer, he said.That kind of buying frenzy is a way for investors lucky enough to own actual shares to make a fast profit. “If you are an institutional investor and get access to one of these companies, you could make 30% instantly just by putting a higher price on the SPV,” he points out.Buying into SPVs, even at high prices, could also allow smaller VC firms to potentially reap future rewards if these companies succeed. Smaller VC firms typically don’t have deep enough pockets to get a chance to buy shares directly from the company in a fundraising event.Risks of high-priced SPVsBut owning the SPV versus owning the actual shares is a distinction that makes a big difference.SPV owners, for instance, get less insight into the financial health of the company than actual shareholders. They aren’t direct investors so would not have access to communications the startup has with its investors. They also don’t have direct voting rights over the shares, meaning they don’t have the same kind of influence over the company. On top of that, the startup did not agree to deal terms with them individually. Direct investor VCs negotiate terms that range from the ability to buy more shares to veto power over IPOs or acquisitions. SPV owners don’t have such terms directly with the startup.The startup will have to grow greatly in value for an investor who paid a 30% premium to make a profit. And if investors with voting rights agree to an acquisition that is profitable for them, but not profitable for those who paid more for their share of an SPV, the SPV backers would get burned.On top of all that, the whole point of buying shares on a secondary market is to buy them at a discount to their current valuation, VC Brian Borton, a partner at secondaries specialist firm StepStone told TechCrunch in June.The investors buying high-priced shares in SPVs know this, of course, but are betting that these companies will perform strongly enough to be worth it.Maybe they will. But considering AI is seeing lofty valuations despite nascent use cases and revenue, that’s a pretty big risk.","AI, Artificial Intelligence (AI), Fundraising, North America, SPVs, Startups, United States, Venture, venture capital, venture secondaries",,,,81
"The top AI deals in Europe this year","Ingrid Lunden",2024-08-24,https://techcrunch.com/2024/08/24/the-top-ai-deals-in-europe-this-year/,"Cumulatively, there have been more than 1,700 funding rounds for AI startups in Europe so far in 2024.","Startups overall are still facing strong headwinds when it comes to raising venture capital funding. Q2 was only a modest improvement on the low points of the previous two quarters, according to Crunchbase.But there is one category that still seems to be opening doors — and checkbooks: AI.In the U.S., artificial intelligence accounted for nearly 30 deals of over $100 million so far in 2024, making it the global leader at the moment. Europe, however, is not too far behind: Our research shows that as of August, Europe has seen 14 investments valued at $100 million or more for AI companies, with one company snagging two investments.AI is driving the European long-tail startup ecosystem in a big way. Cumulatively, PitchBook data shows that there have been more than 1,700 funding rounds for AI startups in the region so far in 2024.The biggest AI startups, those building foundational models, continue to exert the most gravitational pull when it comes to funding, in part because AI remains a costly area for development. Sources tell us that Mistral AI, which already has netted investments of more than $1 billion this year, is apparently fundraising again.Mistral is headquartered in Paris, a city that has really established itself as the center of AI development in Europe, specifically in the category of generative AI. When you consider how some promising emerging markets like India are seeing only a fraction of the AI funding that more developed markets are getting, it will be interesting to see if Paris can sustain that leadership and capitalize on it — or alternatively how the balance of power (and money) might shift.Whether it’s self-driving tech, LLM startups or players that also have hardware components, there are four main reasons why AI is commanding big investments:The compute power it takes to train and run queries through AI models is immense. AI startups are racing to recruit talent. In some cases, AI companies will need money to pay out royalties on all the content IP they’re using to train and run their models. Investors grappling with giant funds for growth investments (and pressure from LPs to deploy) need to find places to put their money; watching what Big Tech hyperscalers are doing, investors see outsized AI companies as big and potentially lucrative bets to make.Here’s a rundown of the biggest rounds in European AI this year, which reads like a who’s who of the biggest categories in AI right now:Wayve: $1 billion Going head-to-head with the likes of Tesla, GM, Intel and Alphabet takes very big money, and that is what Wayve has been raising. In May, the Cambridge, England-based startup closed on a cool $1.05 billion to double down on its autonomous driver technology, making it the largest single round for an AI company to date in the region. Similar to Intel’s Mobileye, Wayve sells its AI technology to a variety of carmakers and OEMs, rather than making the vehicles itself, which theoretically will give it a wider business funnel, as well as more operational focus for the startup.But unlike a number of other self-driving companies, Wayve has “steered away” from having a primary reliance on costly lidar technology. The company is already rolling out services; one customer is U.K. grocery chain Asda. “Seven years ago, we started the company to go build an embodied AI,” Wayve co-founder and CEO Alex Kendall told TechCrunch. “We have been heads down building technology. What happened last year was everything really started to work.” Its investors include SoftBank, Nvidia, Microsoft and Meta’s head of AI, Yann LeCun.Mistral: $650 million and $431 millionMistral has shaped up to be one of the major players building large language models — the foundational block for generative AI applications — not just in Europe but globally. One of its unique selling points has been its embrace of open source, which theoretically makes its tech more customizable and thus enterprise- and developer-friendly.So far, Mistral’s funding story has been a very “blustery” one: It launched with a $113 million seed round announcement barely a year ago. This year it’s collectively raised more than $1 billion, first in a tranche of $431 million and then a second round of $650 million (final close values), from an illustrious set of VC and tech and financial backers such as DST, Andreessen Horowitz, Lightspeed Venture Partners, Microsoft, Salesforce, BNP Paribas, CMA CGM and General Catalyst. Combining those rounds, it’s raised the most of any startup in AI so far this year in Europe. And if our sources are correct, it’s now working on raising even more.Helsing: $484 millionDefense was one of the very earliest applications for AI back in the day, and now geopolitical events have put defense tech AI startups right back into the spotlight. Helsing was founded in Germany, and its European roots have been pivotal to its development. It’s seen as a “home grown” solution, its existence representing more resilience in the European defense economy, helping countries in the region be less reliant on third parties outside of it. It’s announced a number of deals with specific nations, including Estonia and Germany, and it has a number more that it does not disclose.Up to now, Helsing has focused primarily on software, one of its key missions being to build AI services that can link up and work with legacy infrastructure to improve defense systems, boost weapons capabilities, and provide better battle analytics for decision-making. Ukraine, and specifically the threat from Russia, has been a major fillip in its growth.“Ukraine has used technology for its defense against the full-scale Russian invasion, and I think us being able to help there and deploy our technology and execute the mission we had set out three and a half years ago, to use AI to protect our democracies, has been a big driver for us,” Gundbert Scherf, Helsing’s co-chief executive officer, said in an interview with TechCrunch. With the $487 million it raised in July, it’s likely also to move into hardware, too. Its investors include General Catalyst, Prima Materia, Elad Gil, Accel, Saab, Lightspeed, Plural and Greenoaks.Poolside: $400 millionPoolside’s focus first and foremost is on developers, specifically on building AI tools to help them speed up software development. While there are certainly a lot of startups also courting coders, investors are betting the founders here will have a special knack for product-market fit. CEO Jason Warner was the CTO of GitHub and led engineering for Heroku and Canonical. The other co-founder, CTO Eiso Kant, previously founded Athenian, which built a series of tools for developers to help them optimize how they build and work. Like a number of other AI startups in Europe, Poolside is based out of Paris, and early backers included BCV; early-stage specialists like London’s Air Street, Abstraction and Scribble Ventures; New Wave and Frst from France; as well as Bpifrance, Felicis, Point Nine and Redpoint. This latest round of $400 million (that may be yet to close, or at least be disclosed) is reportedly being co-led by BCV and DST.DeepL: $320 millionThere are a number of companies — startups as well as major platform players like Google and Microsoft — that offer text translation and writing tools, but Germany-based DeepL thinks that its AI-based approach is simply better. It’s also taking a slightly different tack by focusing not on consumers but on the B2B/enterprise opportunity in the market.It currently has around 100,000 business customers, and it announced a $320 million round in May of this year on a bet that it can scale that number. Its investors include ICONIQ Growth, Teachers’ Venture Growth, IVP, Atomico and WiL.H: $220 millionH is for “heady,” which is what the AI market is these days. It is also the name of one of the companies proving out that statement. This startup, which used to be known as Holistic AI before it took a cryptic direction and shortened its name to H, raised this $220 million as a seed round in May.It has yet to launch any products, but when it does, it sounds like its focus will be one of the other very popular applications for AI at the moment: AI agents. Specifically, it’s focused on “frontier action models to boost the productivity of workers,” according to its site. “Outrageous AI capabilities for task automation & decision-making.” No word yet on which verticals, which models, when it might launch, or what it might handle, nor what roles it’s looking to fill. Further, three of the outfit’s five co-founders have already left the company. Heady, indeed.Flo Health: $200 millionBased out of London, Flo Health describes itself as the first “purely digital” (no hardware/wearable component) women’s health tracking app to have passed a $1 billion valuation when it raised $200 million earlier this year from General Atlantic. Its focus is currently around fertility and period tracking, but it has ambitions to extend that to older and younger users and to more categories of health. The company claims to have been utilized by a cumulative 380 million users to date, with 70 million monthly active users.Pigment: $145 millionAnother Parisian startup! Pigment is squarely in the area of enterprise software — specifically enterprise resource planning for finance teams. Like Flo Health, it’s not an AI startup per se, but it does lean on it for its functionality. As such, it’s part of the widening pool of AI applications that prove out the prediction that AI will eventually be part and parcel of all our digital services. Its $145 million round earlier this year, which came less than a year after its previous raise, gave Pigment a valuation of over $780 million.","AI, Artificial Intelligence (AI), deals, evergreens, Venture",,,,82
"These 74 robotics companies are hiring","Brian Heater",2024-08-24,https://techcrunch.com/2024/08/24/these-74-robotics-companies-are-hiring/,"From the looks of things, companies in the category — including Agility Robotics and Formlogic — can’t hire quickly enough.","It’s been just over two months since we published our last robotics jobs post. The world of automation continues to excite and surprise, as the rise of generative AI opens new avenues for human-robot collaboration.From the looks of things, companies in the category can’t hire quickly enough. That’s a good problem for you, the robotics job seeker. If this is the living you chose, pat yourself on the back: Someone out there wants to hire you.As ever, the most fascinating part of compiling this list is the breadth of subject matters covered by robotics and automation. Getting a gig in robotics could land you in the restaurant game, pet care, climate or space.1X Technologies (33 roles)Aescape (6 roles)Aethon (4 roles)Agility Robotics (12 roles)AGOT (1 role)Agtonomy (11 roles)Allvision (2 roles)Anduril (400 roles)Arin Technologies (1 role)Ascento (5 roles)Astrobotic (13 roles)Aurora (140 roles)BEA Sensors (5 roles)Botsync Technologies (2 roles)Capsen Robotics (4 roles)Cell X Technologies (1 role)Chef Robotics (7 roles)Collaborative Robotics (15 roles)Cubiq (10 roles)Deeplocal (1 role)Dexory (22 roles)Digital Dream Labs (4 roles)dolaGon Autonomous (1 role)Duality Robotics (2 roles)Edge Case Research (3 roles)ESTAT (2 roles)Exotec (112 roles)Eyebot (3 roles)Formic (7 roles)Formlogic (8 roles)Four Growers (4 roles)Gather.AI (6 roles)Gecko Robotics (23 roles)Glacier (4 roles)Hellbender (6 roles)Humotech (7 roles)Identified Technologies (5 roles)Innovation Works (1 role)KEF Robotics (3 roles)Latitude AI (21 roles)Leaficient (1 role)Machina Labs (9 roles)Matic Robotics (10 roles)Mine Vision Systems (4 roles)National Robotics Engineering (4 Roles)Near Earth Autonomy (3 roles)Neuraville (8 roles)Onward Robotics (2 roles)Outrider (32 roles)Plus Robotics (2 roles)Point One Navigation (1 role)Roboto AI (2 roles)Sanctuary AI (13 roles)Scythe Robotics (5 roles)Shift Robotics (9 roles)Slip Robotics (5 roles)SmyanSoft (2 roles)Stack AV (10 roles)Symbotic (117 roles)Tangram Vision (1 roles)TDK (3 roles)The AI Institute (25 roles)Titan Robotics (2 roles)Vayu Robotics (4 roles)Vecna Robotics (3 roles)Vention (31 roles)Whisker (36 roles)","AI, automation technology, evergreens, job seeker, Robotics",,,,83
"‘Disappointed but not surprised’: Former employees speak on OpenAI’s opposition to SB 1047","Maxwell Zeff",2024-08-23,https://techcrunch.com/2024/08/23/disappointed-but-not-surprised-former-employees-speak-on-openais-opposition-to-sb-1047/,"Two former OpenAI researchers who resigned this year over safety concerns say they are disappointed but not surprised by OpenAI’s decision to oppose California’s bill to prevent AI disasters, SB…","Two former OpenAI researchers who resigned this year over safety concerns say they are disappointed but not surprised by OpenAI’s decision to oppose California’s bill to prevent AI disasters, SB 1047. Daniel Kokotajlo and William Saunders previously warned that OpenAI is in a “reckless” race for dominance.“Sam Altman, our former boss, has repeatedly called for AI regulation,” they wrote in a letter that was shared with Politico and that urges California governor Gavin Newsom to sign the bill. “Now, when actual regulation is on the table, he opposes it.” The two add that, “With appropriate regulation, we hope OpenAI may yet live up to its mission statement of building AGI safely.”Responding to the former employees, an OpenAI spokesperson said the startup “strongly disagrees with the mischaracterization of our position on SB 1047,” in a statement to TechCrunch. The spokesperson pointed to AI bills in Congress that OpenAI has endorsed, noting that “frontier AI safety regulations should be implemented at the federal level because of their implications for national security and competitiveness.”OpenAI rival Anthropic has expressed support for the bill while presenting specific concerns and asking for amendments. Several have since been incorporated, and on Thursday, CEO Dario Amodei wrote to Newsom, saying the current bill’s “benefits likely outweigh its costs,” while not fully endorsing the bill.","AI, AI regulation, ai safety, california, Government & Policy, In Brief, OpenAI, SB 1047",,,,84
"Andrew Ng steps back at Landing AI after announcing new fund","Devin Coldewey",2024-08-23,https://techcrunch.com/2024/08/23/andrew-ng-steps-back-at-landing-ai-after-announcing-new-fund/,"Andrew Ng is stepping down from his role as CEO at Landing AI, the computer vision platform he founded in 2017. Dan Maloney, formerly the COO, will take the reins…","Andrew Ng is stepping down from his role as CEO at Landing AI, the computer vision platform he founded in 2017. Dan Maloney, formerly the COO, will take the reins as Ng transitions to executive chairman to “continue to help drive” the tech and collaborate on “key decisions.”Formerly of Google Brain, Coursera, and Baidu, Ng has seldom stayed put for long, and it’s probably not a coincidence that his AI Fund just announced plans to raise another $120 million. Chances are Ng — who was appointed to Amazon’s board in April — is simply choosing to focus on investing for now. At the same time, these executive reshufflings often precede other, bigger news, so we’ll be watching for more news from Ng over the coming months.","AI, andrew ng, In Brief, landing ai",,,,85
"Piramidal’s foundation model for brain waves could supercharge EEGs","Devin Coldewey",2024-08-23,https://techcrunch.com/2024/08/23/piramidals-foundation-model-for-brainwaves-could-supercharge-eegs/,"AI models are being applied to every dataset under the sun but are inconsistent in their outcomes. This is as true in the medical world as anywhere else, but a…","AI models are being applied to every dataset under the sun but are inconsistent in their outcomes. This is as true in the medical world as anywhere else, but a startup called Piramidal believes it has a sure thing with a foundational model for analyzing brain scan data.Co-founders Dimitris Sakellariou and Kris Pahuja have observed that electroencephalography (EEG) technology, while used in practically every hospital, is fragmented among many types of machines and requires specialized knowledge to interpret. A piece of software that can consistently flag worrisome patterns, regardless of time, location, or equipment type, could improve outcomes for folks with brain disorders, while taking some of the load off overworked nurses and doctors.“In the neural ICU, there are nurses actually monitoring the patient and looking for signs on the EEG. But sometimes they have to leave the room, and these are acute conditions,” said Pahuja. An abnormal reading or alarm could mean an epileptic episode, or a stroke, or something else — nurses don’t have that training, and even specialist doctors may recognize one but not the other.The two started the company after working for years on the feasibility of computational tools in neurology. They found there is absolutely a way to automate analysis of EEG data that is beneficial for care but that there’s no simple way to deploy that technology where it’s needed.“I have experience with this, and I mean I’ve been sitting next to neurologists in the operating room to understand exactly why these brain waves are useful, and how we can build computational systems to identify them,” said Sakellariou. “They’re helpful in many contexts, but every time you use an EEG device, you have to rebuild the whole system for that specific problem. You need to get new data, you need to have humans annotate the data from scratch.”That would be hard enough if every EEG system, hospital IT setup, and data format were the same, but they vary widely in the most basic elements, like how many electrodes are on the machine and where they’re placed.Co-founders Dimitris Sakellariou (left) and Kris Pahuja.Image Credits: PiramidalPiramidal’s founders believe — and claim to know, though this culmination of their work is not yet published — that a foundational model for EEG readings could make lifesaving brain wave pattern detection work out-of-the-box rather than after months of studies.To be clear, it’s not meant to be a do-it-all medical platform — a closer analogue may be Meta’s Llama series of (relatively) open models, which foot the initial expense of creating the foundational capability of language understanding. Whether you build a customer service chatbot or a digital friend is up to you, but neither works without the fundamental ability to understand human language.But AI models aren’t limited to language — they can be trained to work in fluid dynamics, music, chemistry, and more. For Piramidal, the “language” is brain activity, as read by EEGs, and the resulting model would notionally be capable of understanding and interpreting signals from any setup, any number of electrodes or model of machine, and any patient. No one has yet built one — at least, not publicly.Although they were careful not to overstate their current progress, Sakellariou and Pahuja did say, “We have built the foundational model, we have run our experiments on it, and now we are in the process of productionizing the code base so it is ready to be scaled to billions of parameters. It’s not about research — from day one it’s been about building the model.”The first production version of this model will be deployed in hospitals early next year, Pahuja said. “We’re working on four pilots starting in Q1; all four of them will test in the ICU, and all four want to co-develop with us.” This will be a valuable proof of concept that the model works in the diverse circumstances presented by any care unit. (Of course, Piramidal’s tech will be over and above any monitoring the patients would normally be provided.)The foundation model will still need to be fine-tuned for certain applications, work that Pahuja said they will do themselves at first; unlike many other AI companies, they don’t plan to build a foundation model and then rake in fees from API usage. But they were clear that it’s still incredibly valuable as is.“There’s no world where a model trained from scratch will do better than a pretrained model like ours; having a warm start can only improve things,” Sakellariou said. “It’s still the biggest EEG model that has ever existed, infinitely larger than anything else out there.”To move forward, Piramidal needs the two things essential to every AI company: money and data. The first they have a start on, with a $6 million seed round co-led by Adverb Ventures and Lionheart Ventures, with participation by Y Combinator and angel investors. That money will go toward compute costs (huge for training models) and staffing up.As far as data goes, they have enough to get their first production model trained. “It turns out there’s a lot of open source data — but a lot of open source siloed data. So we’ve been in the process of aggregating and harmonizing that into a big integrated data store.”The partnerships with the hospitals should provide valuable and voluminous training data, though — thousands of hours of it. This and other sources could help elevate the next version of the model beyond human capability.Right now, Sakellariou said, “We can address confidently this set of defined patterns doctors look out for. But a bigger model will let us pick out patterns smaller than the human eye can consistently and empirically tell exist.”That’s still a ways off, but superhuman capability is not a prerequisite to improving the quality of care. The ICU pilots should allow the tech to be evaluated and documented much more rigorously, both in scientific literature and likely in investors’ meeting rooms.","AI, Biotech & Health, eeg, Exclusive, piramidal, Startups",,,,86
"Meta and Spotify CEOs criticize AI regulation in the EU","Sarah Perez",2024-08-23,https://techcrunch.com/2024/08/23/meta-and-spotify-ceos-criticize-ai-regulation-in-the-eu/,"Meta and Spotify are once again teaming up — this time, on the matter of open source (or to be precise, open-weight) AI which the companies claim are being hampered…","Meta and Spotify are once again teaming up — this time, on the matter of open source (or to be precise, open-weight) AI which the companies claim are being hampered by regulations. In joint statements published to both companies’ respective websites on Friday, Meta CEO Mark Zuckerberg and Spotify CEO Daniel Ek complain that EU privacy regulations around AI are holding back innovation. Meta, for instance, points out that it has been prevented from being able to train its AI models on public data across Facebook and Instagram because regulators haven’t crafted legislation to address how this should be handled as of yet.“In the short term, delaying the use of data that is routinely used in other regions means the most powerful AI models won’t reflect the collective knowledge, culture, and languages of Europe—and Europeans won’t get to use the latest AI products,” Meta’s blog post warns. It also stresses that Europeans won’t be able to access the latest open source technology and instead will be left with AI “built for someone else.”The post additionally confirmed previous reports that Meta would withhold its next multimodel AI model from customers in the European Union due to a lack of clarity from regulators. Notes Meta, it will not be able to release upcoming AI models like Llama multimodel, which has the ability to understand images because of this.Meanwhile, Spotify points to its early investment in AI technology as a reason its streaming service became so successful in the first place, as it developed a personalized experience for each individual user.“As we look to the future of streaming, we see tremendous potential to use open-source AI to benefit the industry. This is especially important when it comes to how AI can help more artists get discovered. A simplified regulatory structure would not only accelerate the growth of open-source AI but also provide crucial support to European developers and the broader creator ecosystem that contributes to and thrives on these innovations,” its post reads.Reading between the lines, it’s not a stretch to assume that Spotify would like to use Meta’s AI technology to improve its products but is similarly impacted by the lack of clarity around AI regulations in the EU. Of course, neither of these companies are against regulation when it works to their advantage. For instance, the two share a common enemy in Apple — specifically, its App Store monopoly, which saw EU regulators dubbing the iPhone maker a Big Tech “gatekeeper” before forcing it to open up to alternative app stores, app distribution methods and payment systems, among other things. Meta and Spotify didn’t criticize the regulation itself, only how Apple had responded. In this case, Zuckerberg joined Ek in criticizing Apple’s new business rules for EU developers under the region’s Digital Markets Act (DMA) — as being so onerous that he doubted any developer would opt in. Spotify had also called Apple’s compliance plan “extortion” and a “complete and total farce.”Meta and Spotify have a history of working together in recent years, having earlier teamed up on music initiatives that included a miniplayer on Facebook that streamed Spotify directly from the app.","AI, Europe, Government & Policy, Meta, Privacy, Spotify",,,,87
"AI talent managers, technocapitalist college towns and a rise in defense tech acquisitions","Devin Coldewey",2024-08-23,https://techcrunch.com/podcast/ai-talent-managers-technocapitalist-college-towns-and-a-rise-in-defense-tech-acquisitions/,"This week on Equity are some deals that are unusual for a few reasons — some good, some… well, we’ll find out. First up is…","This week on Equity are some deals that are unusual for a few reasons — some good, some… well, we’ll find out.First up is the $80 million round for Story, which is trying to apply that ol’ web3 magic to AI and talent management. As one investor puts it, “What Bitcoin did for money and finance, Story is doing for content and IP.” That may well be true, but perhaps not in the way he means it.Next, Mary Ann attempts to untangle the knotty, weird term sheet for Bolt: $450 million. But is that real money or “marketing credits”? The latter, at least in significant part. And the actual money, is it from regular investors, or through multiple private equity shell companies operating through the Caymans and UAE? Well, the second one. But at least Ryan Breslow is coming back — that should simplify things!A new face (and voice) on Equity, Margaux MacColl over in DC, explained Balaji Srinivasan’s private island “technocapitalist college town” where “those with a fondness for the current world order need not apply.” I said it sounds like a cult, and look, cults can be fine in moderation, but I’m worried about this one.Not wanting to stop talking, I went on to get into two AI companies I covered this week that aren’t enterprise LLM stuff. Reliant AI is focused on researchers (especially in pharma) who need to analyze thousands of papers at once, and it seems like it could be super useful to data scientists. And BeyondMath is working with Formula 1 companies to create a “digital wind tunnel” that does high-accuracy physics-based computational fluid dynamics simulations in near real time. When was the last time ChatGPT made a race car faster?Margaux wrapped us up with the increasing activity level in defense tech acquisitions. Investors are seeing this once-taboo market in a different light (now that it’s making money) recently, but that doesn’t mean you can expect an AI-type bubble — this is a different world with different definitions of success and reasonable exits. But with more than $100 billion invested since 2021, no one can afford to ignore it any longer.Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Monday, Wednesday and Friday. Subscribe to us on Apple Podcasts, Overcast, Spotify and all the casts.You also can follow Equity on X and Threads, at @EquityPod. For the full episode transcript, for those who prefer reading over listening, check out our full archive of episodes over at Simplecast.","AI, Equity podcast, Startups, Venture",,,,88
"DeepMind workers sign letter in protest of Google’s defense contracts","Kyle Wiggers",2024-08-22,https://techcrunch.com/2024/08/22/deepmind-workers-sign-letter-in-protest-of-googles-defense-contracts/,"At least 200 workers at DeepMind, Google’s AI R&D division, are displeased with Google’s reported defense contracts — and according to Time, they circulated a letter internally back in May…","At least 200 workers at DeepMind, Google’s AI R&D division, are displeased with Google’s reported defense contracts — and according to Time, they circulated a letter internally back in May to say as much. The letter, dated May 16, says the undersigned are concerned by “Google’s contracts with military organizations,” citing articles about the tech giant’s contracts to supply AI and cloud computing services to the Israeli military.“Any involvement with military and weapon manufacturing impacts our position as leaders in ethical and responsible AI, and goes against our mission statement and stated AI Principles,” the letter adds. While a relatively small portion of the org’s overall staff, the memo hints at a culture clash between Google and DeepMind, which Google acquired in 2014 and whose tech Google pledged in 2018 would never be used for military or surveillance purposes.","AI, AI, DeepMind, defense, Google, letter, military",,,,89
"Waymo wants to chauffeur your kids","Kyle Wiggers",2024-08-22,https://techcrunch.com/2024/08/22/waymo-wants-to-chauffeur-your-kids/,"Soon, parents in range of Waymo robotaxis might not have to worry about picking up their kids from after-school activities — or any time, really. The San Francisco Standard reports…","Soon, parents in range of Waymo robotaxis might not have to worry about picking up their kids from after-school activities — or any time, really.The San Francisco Standard reports that Waymo, the Alphabet subsidiary, is considering a subscription program that would let teens hail one of its cars solo and send pickup and drop-off alerts to their parents. In a survey, Waymo referred to the program as “Waymo Teen,” and floated prices ranging from $150 to $250 per month for up to 16 rides.“We have been exploring the potential for authorized teenagers to access [Waymo] under their guardians’ supervision and have received promising feedback from our research in this area,” a Waymo spokesperson told TechCrunch. Waymo isn’t the only ride-hailing company looking to teens to boost profits. Last year, Uber began matching teens ages 13 through 17 with highly rated drivers in its network. Consent is required from a child’s legal guardians, who then receive notifications about their child’s whereabouts during rides.","AI, AI, driverless, In Brief, kids, self-driving, Teens, Transportation, Waymo, waymo kids, waymo teens",,,,90
"AI sales rep startups are booming. So why are VCs wary?","Marina Temkin",2024-08-22,https://techcrunch.com/2024/08/22/ai-sdr-startups-are-booming-so-why-are-vcs-wary/,"When you really probe venture capitalists about investing in AI startups, they’ll tell you that businesses are experimenting wildly but are very slow to add AI solutions into their ongoing…","When you really probe venture capitalists about investing in AI startups, they’ll tell you that businesses are experimenting wildly but are very slow to add AI solutions into their ongoing business processes. But there are some exceptions. And one of them appears to be an area known as AI sales development representatives, or AI SDRs. These use LLMs and voice technology to craft personalized outreach emails and place automated calls to potential customers. “In some markets, we’re seeing five to 10 companies all have success in a pretty short period of time,” Shardul Shah, a partner at Index Ventures, said of the AI SDR boom.While it’s certainly not uncommon for multiple startups to target the same problem, it’s rare to see all of them experience rapid growth. But that’s apparently the case for startups that automate content creation for sales teams, investors say.“When one studies any of [these startups] individually, it’s like ‘wow, that’s stunning product market fit’,” Shah said. “When all 10 of them have stunning product market fit, it’s hard to answer ‘how is that going to play out?’”Index has yet to invest in any of these companies, many of which are less than a year old. Even though the whole category is on fire and customers are using them, it’s still too early to know whether their growth will continue over the long term or they be discarded like so many other AI pilot projects once the wow factor fades, because they don’t prove to be more effective than human outreach.Small businesses love AI sales LLMsArjun Pillai, founder of Docket, a startup that builds AI sales engineers, is convinced that AI SDR adoption is high because small and medium-size businesses can easily experiment with these tools. Before Docket, Pillai was the former chief data officer at sales lead generation platform ZoomInfo.“Over the last two years, the reply rate on cold emails fell at least 50%,” Pillai said. “Now that there are a bunch of companies that claim they can improve this rate, everyone is willing to try their service.”The best-known AI SDR startups include Regie.ai, AiSDR, Artisan and 11x.ai, but ZoomInfo, an incumbent, also released a copilot that competes with these and other virtual sales agent startups.While these companies are experiencing rapid revenue growth, it’s unclear if they’re actually helping businesses sell more effectively.“The question is how many companies have been paying for more than six months?” Pillai asked. To create a truly personalized outreach message, an AI SDR needs to have very specific data about each prospective customer. But what’s known about each prospect is limited and all of these companies have access to the same public information, he said. Chris Farmer, partner and CEO at venture firm SignalFire, said he believes that AI applied to sales and marketing is a large opportunity, but without access to differentiated data, AI SDR startups risk being overtaken by incumbents like Salesforce, HubSpot and ZoomInfo. Those companies’ main products are the keepers of their customers’ data. So if they offered bots that let their customers tap into their own data, such bots could be more effective. Will the incumbents squash them?Another venture capitalist that looked at this market but hasn’t yet invested said her firm looked at several AI SDR startups and that they all had $1 million in ARR within less than a year. The startups’ impressive growth was attractive, she said, but like Farmer she was concerned their solutions could eventually be offered as a free feature by established competitors. Jasper, a copywriting startup that was last valued at $1.5 billion, but ran into speed bumps and had to lay off 30% of its staff after ChatGPT was introduced, serves as a cautionary tale for some investors. Investors are not surprised by the rapid adoption of AI SDRs; they are just doubting that adoption is sticky.","AI, HubSpot, Index Ventures, Jasper, Salesforce, signalfire, Startups, Venture, Zoominfo",,,,91
"Former Alphabet X spinout Mineral sells technology to John Deere","Brian Heater",2024-08-22,https://techcrunch.com/2024/08/22/former-alphabet-x-spinout-mineral-sells-technology-to-john-deere/,"Citing a crowded market and profit concerns, Mineral ceased operation and pivoted to technology licensing.","Earlier this year, reports surfaced that Alphabet had closed the book on its ag tech robotics spinout, Mineral. The news arrived amid larger money crunches at Google’s parent. Citing a crowded market and profit concerns, Mineral ceased operation and pivoted to technology licensing.This month, Mineral CEO Elliott Grant reprinted the leaked memo, while confirming that farming giant John Deere has acquired one of the startup’s technology suites to bolster its See & Spray crop spraying solution.“The challenge of solving sustainable agriculture remains ahead of us,” Grant wrote in a post. “But it’s a relay race not a sprint.”","AI, Alphabet X, Hardware, In Brief, John Deere, mineral, Robotics",,,,92
"Alphabet X’s latest spinout brings computer vision and AI to salmon farms","Brian Heater",2024-08-22,https://techcrunch.com/2024/08/22/alphabet-xs-latest-spinout-brings-computer-vision-and-ai-to-salmon-farms/,"Tidal, which quietly spun out of the department in mid-July, has its own grand ambitions to “feed humanity sustainably.”","Over the course of Alphabet X’s existence, the self-proclaimed “moonshot factory” has been notable for the variety in both its technological solutions and the problems it’s attempting to solve. The combination research facility/accelerator has produced balloons for rural internet and energy-producing kites.Tidal, which quietly spun out of the department in mid-July, has its own grand ambitions to “feed humanity sustainably.” It’s big and abstract as goals go, so the newly minted company is beginning life by focusing on one specific element: salmon aquaculture.According to the World Wildlife Foundation, “Salmon aquaculture is the fastest-growing food production system in the world, accounting for 70% (2.5 million metric tons) of the market.”Based in Trondheim, Norway, by way of Mountain View, Tidal takes a very Googley approach to the industry. A combination of sensors, robotics, data science and AI is designed to give farmers a fuller picture of their harvests. The system monitors the fish and offers yield estimates and is designed to catch potential issues — like sea lice — before they do serious damage.The company has already been in Australia, Chile and Norway, working alongside farmers. At present, Tidal has 230 systems deployed in Norway.Image Credits: Tidal“In an industry where the largest environmental and economic cost is feed, Tidal empowers fish farmers around the world to make more sustainable decisions,” X head Astro Teller said in a post tied to the news. “Now that Tidal is well on the way to commercializing its technology, it’s graduating to become an independent company, with backing from financial and strategic partners who share our vision.”A rep for Tidal told TechCrunch that a spinout has always been part of the plan. Following headcount cuts to the secretive organization, Alphabet has started tightening the belt on its “other bets.” In recent months, robot agriculture firm Mineral was converted into a licensing project, having recently sold a technology suite to John Deere. Assisted clothing firm Skip spun out last month.Alphabet’s connection post-spinout varies from company to company. In the case of Tidal, the tech giant remains a minority owner, and the startup has begun to pursue external funding as well. Perry Creek Capital led its most recent round, with support from Ichthus Venture Capital and Futurum Ventures. It has not disclosed a dollar amount.Tidal says it’s currently in “full growth mode,” with plans to double or triple the systems it has deployed over the next couple of years.","AI, Alphabet X, Hardware, Robotics, tidal",,,,93
"TechCrunch Minute: AI could help design and test F1 cars faster","Amanda Silberling",2024-08-22,https://techcrunch.com/video/techcrunch-minute-ai-could-help-design-and-test-f1-cars-faster/,"Formula One teams are looking at a startup called BeyondMath to bring their car construction to the next level. BeyondMath is working in the field…","Formula One teams are looking at a startup called BeyondMath to bring their car construction to the next level.BeyondMath is working in the field of computational fluid dynamics, which attempts to digitally model how an object moves through water or air. But that’s a lot easier said than done — even with excessive computing power, these digital representations of complex physics are not wholly accurate. What makes BeyondMath different is that it’s simulating windy conditions by using machine learning, not just supercomputers, which could make these models more accurate.BeyondMath co-founder Darren Garvey told TechCrunch, “Imagine you’ve got six months to design a part for a plane. Given that a simulation takes so long, you might get 20 attempts to try things out. But if a designer thinks of an idea and gets results within seconds or a couple of minutes, in that same six months you might be able to run a million changes.”On today’s TechCrunch Minute, we’re explaining why professional race car teams are eyeing this startup’s technology to make their vehicles more aerodynamic.","AI, formula 1, Startups, TechCrunch Minute",,,,94
"Harmonyze wants to build AI agents to help franchisors make sense of unstructured data","Rebecca Szkutak",2024-08-22,https://techcrunch.com/2024/08/22/harmonyze-built-ai-agents-that-sit-between-franchisors-and-their-franchisees/,"For some businesses, there is a clear path to growth that doesn’t involve acquiring other companies or expanding organically: franchising. The U.S. has more than 800,000 franchise businesses, according to…","For some businesses, there is a clear path to growth that doesn’t involve acquiring other companies or expanding organically: franchising. The U.S. has more than 800,000 franchise businesses, according to Statista, and that number is predicted to keep growing year over year. But franchising a business — licensing a business model and brand to an outside operator — requires a lot of contracts, legal compliance and documentation, which all serve to further complicate an already involved business model.Brooklyn-based Harmonyze wants to help franchisors keep track of it all using AI, and it has just raised a $2 million pre-seed round led by Bowery Capital to further build out its AI agents.The startup’s custom AI agents sit in a private cloud database between the franchisor and the franchisees. These agents can talk to each other and perform over 200 tasks like ensuring a franchise has paid a product vendor correctly or that a franchise is up to date on insurance renewals. This helps franchisors ensure that they, and their franchisees, are staying compliant — franchising is a heavily regulated industry. Another major benefit is they don’t have to spend as much time on such administrative tasks.The company was started in 2023 by childhood friends Gary Liskovich, CEO, a former product manager at startups like EvolutionIQ and SmartAsset, and Jonny Greenspan, CTO, a former engineer at companies like Salesforce. Liskovich told TechCrunch they dabbled in developing a product for the legal space, but decided on franchising because of how untapped the market was, and because they had a personal connection: Greenspan’s dad owned a Totonno’s pizza franchise location.“Franchising is this thing that everybody knows the word, but most people haven’t done a lot of digging; it makes up 10% of U.S. businesses,” Liskovich said. “We started looking at the franchising space — it’s an incredible amount of unstructured data, which we really think AI can unlock and translate into something that is usable.”Harmonyze exited stealth in early 2024, and demand from franchisors has been strong ever since, Liskovich said. He added that despite demand, Harmonyze is choosing to work with a select group of customers at first so they can continue to get feedback and iterate on the product and its features.Liskovich said the company plans to put most of the capital from the pre-seed round toward hiring so they can continue to build out the product. The round saw participation from Focal.VC and numerous individuals from the franchise industry.Harmonyze decided to focus on building for, and selling to, the franchisor, as opposed to the franchisee, because the franchisor deals with significantly more unstructured data, which makes their problems lean better toward an AI solution, Liskovich said. He hopes Harmonyze will also be able to help franchisors spot smart business practices at franchisees that can be rolled out to everyone.“Franchisees are very known for innovating and are people that are tweaking the system,” Liskovich said. “Very famously, [McDonald’s] Filet-O-Fish came from a franchisee. That is where we want to start to evaluate: Where are your best franchisees innovating? And using that information to make everyone more profitable.”Liskovich thinks the startup has been successful thus far because of its focus on building vertical SaaS for franchisors as a whole instead of focusing on sectors within franchising, which can include companies ranging from McDonald’s to Orangetheory Fitness to UPS stores. He said despite the various different types of franchised businesses, the internal structure of these companies largely looks the same.There isn’t much competition in the franchise space — at least for now — which is surprising given the size of the sector and the fact that it is growing consistently.Harmonyze is currently targeting franchisors that head up a sizable network of franchisees, as opposed to owners that just work with a handful. Liskovich thinks the startup will likely build tech to work with those smaller players too, but the market is big enough in its target area to keep it busy for now.“We’re excited about the expansion [of the franchise market],” Liskovich said. “It is not just large but growing at an insane rate. That opportunity is a growing opportunity.”","AI, Artificial Intelligence (AI), bowery capital, franchisors, Harmonyze, North America, Startups, Startups, United States, Venture, venture capital",,,,95
"Opkey, an AI-based ERP testing platform, raises $47M","Ingrid Lunden",2024-08-22,https://techcrunch.com/2024/08/22/opkey-an-ai-based-erp-testing-platform-raises-47m/,"On the back of strong customer traction — more than 200 large enterprise customers — the startup has closed a Series B of $47 million.","Companies are experimenting with services like ChatGPT to help workers write memos, answer questions, and much more. Yet, one of the clearest signs of how much traction AI is really getting in the world of enterprise IT is how often it figures in the more routine applications that organizations use. Today, a startup that exemplifies that axiom is announcing funding, underscoring that pace of enterprise AI adoption.Opkey has built an AI platform to help organizations continuously test finance, HR and other enterprise resource planning (ERP) software. Now, on the back of some strong customer traction — more than 200 large enterprise customers and partnerships with system integrators like KPMG LLC and PwC — the startup has closed a $47 million Series B. PeakSpan Capital is leading the round, which saw participation from previous backers and its current investors, including UST Global, Verica, Vertical and India’s YourNest. This Series B is a big step up for Dublin, California-based Opkey: The company had only raised $12 million before now. The startup is not disclosing its valuation. Opkey’s platform may not be at the most visible end of the enterprise IT stack, but it’s addressing a gap in the market that is critical to how enterprises operate.Cloud architecture and SaaS have become the bedrock on which new business services are built, but they have also found a lot of footing with more legacy organizations undergoing digital transformation processes. They can be faster and cheaper to use and easier to deploy to a user base, but they can also come with a ton of problems — like the fact that any vulnerabilities or inconsistencies between software can take down entire networks. This is where Opkey comes into the picture. Pankaj Goel, the CEO, co-founded the company with his childhood friends Avinash Tiwari and Lalit Jain. All three are ERP industry veterans with experience at big companies like Adobe and Oracle. Their time there gave them experience in software testing as well as a front-row seat to how disastrous it could be if not done correctly. ERP systems typically do not exist in silos — they integrate with each other to work, which means if one conflicts with another, or is not working correctly, the whole ERP stack can crash. “Cloud applications are continuously giving updates, which was not the case with traditional software,” Goel said in an interview. “That functionality breaks existing functionality.” He estimates that an organization might typically integrate seven or eight ERP systems together. “Any change in the ecosystem, and you need to test it again. It means enterprises are in testing hell.”Testing and data hell are in fact classic problems AI-based automation can resolve, and cybersecurity and DevOps software companies have also come to realize that. In the case of Opkey and ERP, the platform continuously tracks integrations, updates, upgrades, and something the company describes as “user acceptance” — how well end users are interacting with new features they are supposed to be using. Packages and platforms that Opkey currently covers include Oracle, Workday, Coupa, Veeva, Salesforce, SAP, Microsoft Dynamics, UKG and Trackwise.Sanket Merchant, the partner at PeakSpan who led the investment, believes that there will continue to be a very strong funnel of business interest for services like Opkey’s given the direction IT is moving. One question is if that will be enough to stave off competition from others in the same space, such as Leapwork and Katalon. Whether bigger ERP players may look to take on this business themselves is another.“For businesses, the most expensive IT spend is related to critical enterprise apps, their ERP apps,” he said, citing figures that say that some $73 billion is spent every year on ERP software for billing, accounting, people management, software deployment and more across both smaller businesses and massive, multinational organizations. These in turn can have as many as 52 different other apps that rely on ERP integrations to work. “Automated testing is important to drive assurance around that investment, to make sure it behaves as intended. A failed SAP deployment or Workday migration can have a huge impact on a business’s revenue and its brand.”","AI, Enterprise, ERP, Fundraising, Opkey, Testing",,,,96
"Telecom that enabled Biden deepfake scam will pay FCC $1M","Devin Coldewey",2024-08-21,https://techcrunch.com/2024/08/21/telecom-that-enabled-biden-deepfake-scam-will-pay-fcc-1m/,"Early this year, AI-powered fake audio of President Biden reached voters in New Hampshire. The FCC struck back swiftly, identifying the perpetrator as the Texas-based Life Corporation, which has been…","Early this year, AI-powered fake audio of President Biden reached voters in New Hampshire. The FCC struck back swiftly, identifying the perpetrator as the Texas-based Life Corporation, which has been behind similar scams over the years, and whacked them and an associated individual with a $6 million fine. But the scammers also enlisted the help of a game, shape-shifting telecom that has previously been implicated in shady doings. Now Lingo Telecom, as it’s currently known (AKA Ameritel, Excel, Impact, Startec, Trinsic, etc.) will pay a $1 million civil penalty and agree to definitely follow the rules this time for sure, starting now.Telecoms like Lingo are not supposed to enable scams by providing services to known bad operators. “Communications service providers are the first line of defense against these threats and will be held accountable,” said FCC Chairwoman Jessica Rosenworcel.","AI, deepfakes, FCC, Government & Policy",,,,97
"OpenAI’s opposition to California’s AI bill ‘makes no sense,’ says state senator","Maxwell Zeff",2024-08-21,https://techcrunch.com/2024/08/21/openais-opposition-to-californias-ai-law-makes-no-sense-says-state-senator/,"OpenAI broke its silence on California’s most controversial AI bill on Tuesday, officially expressing opposition in a letter to California state Senator Scott Wiener and Governor Gavin Newsom. The AI…","OpenAI broke its silence on California’s most controversial AI bill on Tuesday, officially expressing opposition in a letter to California state Senator Scott Wiener and Governor Gavin Newsom. The AI giant argued that SB 1047, introduced by Wiener in February, would stifle innovation and push talent out of California — a position Wiener quickly replied “makes no sense.”“The AI revolution is only just beginning, and California’s unique status as the global leader in AI is fueling the state’s economic dynamism,” said OpenAI’s Chief Strategy Officer Jason Kwon in the letter obtained by TechCrunch. “SB 1047 would threaten that growth, slow the pace of innovation, and lead California’s world-class engineers and entrepreneurs to leave the state in search of greater opportunity elsewhere. Given those risks, we must protect America’s AI edge with a set of federal policies — rather than state ones — that can provide clarity and certainty for AI labs and developers while also preserving public safety.”The company joins broad local pushback against SB 1047 on Tuesday, adding its take to those of trade groups representing Google and Meta, investment firm Andreessen Horowitz, prominent AI researchers and California Representatives Nancy Pelosi and Zoe Lofgren.An OpenAI spokesperson says the company has been in discussions with Senator Wiener’s office about the bill for months. However, Senator Wiener says the AI lab’s argument that SB 1047 would push AI companies out of California is “tired.”Wiener pointed out in a press release on Wednesday that OpenAI doesn’t actually “criticize a single provision of the bill.” He says the company’s claim that companies will leave California because of SB 1047 “makes no sense given that SB 1047 is not limited to companies headquartered in California.” As we’ve previously reported, SB 1047 affects all AI model developers that do business in California and meet certain size thresholds.In other words, whether an AI company was based in San Jose or San Antonio, if they let Californians use their products, they would be subject to these restrictions. (An example of an effective law with this type of scope is Illinois’ Biometric Information Privacy Act.)That said, Bloomberg reports that OpenAI has put conversations about expanding its San Francisco offices on hold amid concerns about California’s regulatory landscape. OpenAI has had an office in San Francisco’s Mission district for years, and recently moved into a new office in the city’s Mission Bay region, previously occupied by Uber.OpenAI declined to comment further on those real estate discussions.“Instead of criticizing what the bill actually does, OpenAI argues this issue should be left to Congress,” said Wiener in the statement. “As I’ve stated repeatedly, I agree that ideally Congress would handle this. However, Congress has not done so, and we are skeptical Congress will do so.” Tech companies have taken similar stances regarding privacy laws in the past, calling for federal regulation knowing it will be slow to come, and California ended up stepping up there as well.OpenAI has endorsed several federal bills regulating AI models, one of which authorizes the United States AI Safety Institute as a federal body that sets standards and guidelines for AI models. From a high level, that’s fairly similar to what SB 1047’s Board of Frontier Models is supposed to do.California lawmakers significantly amended SB 1047 to give Governor Newsom a less controversial AI bill to sign, but they’ve failed to convince Silicon Valley’s most important AI lab the bill is worth passing. SB 1047 is now headed for a final vote in California’s Assembly and could land on Governor Newsom’s desk by the end of the month. The California governor has not indicated his feelings on SB 1047, but he’d likely face a broad industry backlash if he signs it.","AI, AI regulation, california, Government & Policy, OpenAI, sam altman, SB 1047",,,,98
"This founder had to train his AI not to Rickroll people","Amanda Silberling",2024-08-21,https://techcrunch.com/2024/08/21/this-founder-had-to-train-his-ai-to-not-rickroll-people/,"Flo Crivello was monitoring outputs from the AI assistants his company Lindy makes when he noticed something strange. A new client had asked her Lindy AI assistant for a video…","Flo Crivello was monitoring outputs from the AI assistants his company Lindy makes when he noticed something strange. A new client had asked her Lindy AI assistant for a video tutorial that would help her better understand how to use the platform, and the Lindy responded in kind — that’s when Crivello knew something was wrong. There is no video tutorial.“We saw this and we were like, ‘OK, what kind of video did it send?’ and then we were like, ‘Oh snap, this is a problem,’” Crivello told TechCrunch.The video the AI sent the client was the music video to Rick Astley’s 1987 dance-pop hit “Never Gonna Give You Up.” In more familiar terms: the client got Rickrolled. By an AI.Rickrolling is a bait-and-switch meme that’s over 15 years old. In one incident that popularized the meme, Rockstar Games released the much-hyped “Grand Theft Auto IV” trailer on its website, but traffic was so immense that the site crashed. Some people had managed to download and post the video onto other sites like YouTube, sharing the links so that people could see the trailer. But one 4chan user decided to play a prank and share the link to Rick Astley’s “Never Gonna Give You Up.” Seventeen years later, people are still pranking their friends by sharing the Astley song at inopportune moments — now the music video has over 1.5 billion views on YouTube.This internet prank is so ubiquitous that inevitably, large language models like ChatGPT, which powers Lindy, picked up on it.“The way these models work is they try to predict the most likely next sequence of text,” Crivello said. “So it starts like, ‘Oh, I’m going to send you a video!’ So what’s most likely after that? YouTube.com. And then what’s most likely after that?”Crivello told TechCrunch that out of millions of responses, Lindy only Rickrolled customers twice. Still, the error was necessary to patch.“The really remarkable thing about this new age of AI is, to patch it, all I had to do was add a line for what we call the system prompt — which is the prompt that’s included in every Lindy — and it’s like, don’t Rickroll people,” he said.Lindy’s lapse calls into question just how much of internet culture will be subsumed into AI models, since these models are often trained on large swaths of the web. Lindy’s accidental Rickroll is particularly remarkable because the AI organically reproduced this very specific user behavior, which informed its hallucination. But traces of internet humor seep into AI in other ways, which Google learned the hard way when it licensed Reddit data to train its AI. As a hub of user-generated content — much of which is satirical — Google’s AI ended up telling a user you can make cheese better stick to pizza dough by adding glue.“In the Google case, it wasn’t exactly making stuff up,” Crivello said. “It was based on content — it’s just that the content was bad.”As LLMs rapidly improve, Crivello thinks that we won’t see as many gaffes like this in the future. Plus, Crivello says it’s easier than ever to patch these mishaps. In the early days of Lindy, if one of its AI assistants couldn’t complete the task the user asked, the AI would say it’s working on it but never deliver the product. (Oddly enough, that sounds pretty human.)“It was really hard for us to patch that issue,” Crivello said. “But when GPT-4 came out, we just added a prompt that was like, ‘If the user asks you to do something you’re not able to do, just tell them you can’t do it.’ And that fixed it.”For now, the good news is that the customer who got Rickrolled might not even know it.“I don’t even know that the customer saw it,” he said. “We followed up immediately like, ‘Oh hey, this is the right link to the video,’ and the customer didn’t say anything about the first link.”","AI, flo crivello, lindy, rickrolling",,,,99
"D-ID launches an AI video translation tool that includes voice cloning and lip sync","Sarah Perez",2024-08-21,https://techcrunch.com/2024/08/21/d-id-launches-an-ai-video-translation-tool-that-includes-voice-cloning-and-lip-sync/,"AI video creation platform D-ID is the latest company to ship a tool for translating videos into other languages using AI technologies. However, in this case, D-ID also clones the…","AI video creation platform D-ID is the latest company to ship a tool for translating videos into other languages using AI technologies. However, in this case, D-ID also clones the speaker’s voice and changes their lip movements to match the translated words as part of the AI editing process.The technology stems from D-ID’s earlier work — which you may recall from the viral trend a few years ago where users were animating their older family photos, and later those photos were able to speak. On the back of that success, the startup closed on $25 million in Series B fundraising in 2022 with an eye on serving its increasing number of enterprise customers in the U.S. who were using its technology to make AI-powered videos.With the company’s now-launched AI Video Translate tech, currently being offered to D-ID subscribers for free, creators can automatically translate their videos into other languages to help them expand their reach. In total, there are 30 languages currently available, including Arabic, Mandarin, Japanese, Hindi, Spanish and French, among others. A D-ID subscription starts at $56 per year for its cheapest plan and the smallest number of credits to use toward AI features and then goes up to $1,293 per year before shifting to enterprise pricing.D-ID suggests the new AI video technology could help customers save on localization costs when scaling their campaigns to a global audience in areas like marketing, entertainment, and social media. The technology will compete with other solutions for both dubbing and AI video. For years, dubbing technologies have made it easier for video viewers to listen to audio in their own language but were often inaccessible to smaller creators. That’s been changing as companies improved access to technology. For example, YouTube released a multi-language audio feature designed to help its creators connect with a wider audience by translating their videos into other languages. Well-known creator MrBeast (Jimmy Donaldson) was among the early adopters, having used the tech to bring several of his popular videos to 11 more languages.With AI, the ability to create, translate, or clone voices is also expanding. Microsoft this year announced it would use AI to translate and dub YouTube videos, and others, while you watch. In July, creator platform Vimeo unveiled tools to translate audio and captions and to do so by replicating the speaker’s voice with AI technology. Numerous companies also offer voice cloning or AI translation tools (or sometimes both), including those from Descript, ElevenLabs, Speechify, Veed, Camb.ai, Captions.ai, and Akool, to name a few, as well as tools that let you create videos using AI avatars that can speak dozens of languages, like those from HeyGen, Deepbrain AI and others.Dubbing and lip sync AI libraries, like Wav2lip, have also made it easier for startups to build these sorts of tools while pitching to creators that they make it easier, and perhaps more affordable, to use AI technology. (D-ID’s newly developed proprietary model called Rosetta-1 powers AI Video Translate.)D-ID says its new Video Translation technology will be available through D-ID Studio and its API. A one-month trial is being offered and further demos are on its website.The company says videos can be between 10 seconds and 5 minutes in length, and file size should be under 2GB. The feature works with only one person in the frame and, for best result, they should be facing the camera with their face visible at all times.","AI, D-ID, video creation",,,,100
"Anthropic’s Claude surpasses $1M in mobile app revenue","Sarah Perez",2024-08-21,https://techcrunch.com/2024/08/21/anthropics-claude-surpasses-1m-in-mobile-app-revenue/,"However, Claude is still ranking far behind top rival ChatGPT.","It’s taken 16 weeks to get there, but Anthropic’s AI app Claude has hit a notable milestone: It crossed $1 million in gross mobile app revenue across iOS and Android. Nearly half of that revenue has been generated by users in the U.S., according to new data from app intelligence firm Appfigures.However, Claude is still ranking far behind top rival ChatGPT, which is No. 1 by overall downloads and No. 26 by revenue in the U.S. on iOS. Claude is only 95th in the Productivity category by downloads and 68th in that category by revenue.Image Credits: AppfiguresEarlier this year, we reported that Claude’s mobile app had seen a fairly tepid reception for its first week on the market, where it only pulled in 157,000 global downloads. By comparison, ChatGPT had seen 480,000 mobile app installs within the first five days of its iOS-only, U.S. launch. The highest rank Claude had achieved in the U.S. was a few days after its iOS debut when it reached No. 55 on the top free iPhone app charts, Appfigures said at the time.Still, Claude was able to hit its first million in revenue faster than other AI app competitors. Though it trailed far behind ChatGPT, which only took three weeks to reach this milestone, Claude came in ahead of Microsoft’s Copilot and Perplexity, which took 19 weeks and 22 weeks to hit the $1 million figure, respectively.Image Credits: AppfiguresThe largest market for Claude by downloads is the U.S. at 32.5%, followed by India (9.6%), Japan (6.8%), the U.K. (5.1%) and Germany (3.2%). Combined, these top five markets account for 57.2% of Claude’s mobile app installs.The picture of Claude’s monetization on mobile is somewhat similar, as the U.S. leads again with a 48.4% share of revenue. That’s followed by Japan (6.7%), Germany (4.3%), the U.K. (4.3%) and South Korea (2.8%) for a combined share of 66.8%.Beyond its sizable burn rate as a startup, Claude’s challenges specific to the mobile consumer market will likely continue in the days ahead — particularly when Apple Intelligence launches, offering Siri users direct access to ChatGPT via their iPhones.","AI, Anthropic, Apps, Claude",,,,101
"This Week in AI: Gen Z has mixed feelings on AI","Kyle Wiggers",2024-08-21,https://techcrunch.com/2024/08/21/this-week-in-ai-gen-z-has-mixed-feelings-on-ai/,"This week, surveys suggest that Gen Z — regularly the subject of mainstream media fascination — has very mixed opinions on AI.","Hiya, folks, welcome to TechCrunch’s regular AI newsletter.This week, surveys suggest that Gen Z — regularly the subject of mainstream media fascination — has very mixed opinions on AI.Samsung recently polled over 5,000 Gen Zers across France, Germany, Korea, the U.K. and the U.S. on their views of AI, and tech more generally. Nearly 70% said that they consider AI to be a “go-to” resource for work-related tasks like summarizing documents and meetings and conducting research, as well as non-work-related tasks such as finding inspiration and brainstorming.Yet, according to a report published earlier in the year by EduBirdie, a professional essay-writing service, more than a third of Gen Zers who use OpenAI’s chatbot platform ChatGPT and other AI tools at work feel guilty about doing so. Respondents expressed concerns that AI could limit their critical thinking skills and hamper their creativity.We must take both these surveys with a grain of salt, of course. Samsung isn’t exactly an impartial party; it sells and develops many AI-powered products, so it has a vested interest in painting AI in an overall flattering light. Neither is EduBirdie, whose bread-and-butter business competes directly with ChatGPT and other AI writing assistants. It would doubtless prefer folks be wary of AI — especially AI apps that give essay pointers.But it could be that Gen Z, while loathe to discount or boycott AI entirely (if that were even possible), is more aware of the potential consequences of AI, and tech in general, than previous generations.In a separate study from the National Society of High School Scholars, an academic honor society, the majority of Gen Zers (55%) said that they think AI will have a more negative than positive effect on society in the next 10 years. Fifty-five percent think AI will have a significant impact on personal privacy — and not in a good way.And Gen Z’s opinions matter. A report from NielsenIQ projects that Gen Z will soon become the wealthiest generation ever, with their spending potential reaching $12 trillion by 2030 and overtaking baby boomers’ spending by 2029.With some AI startups spending upward of 50% of their revenue on hosting, compute and software (per data from accounting firm Kruze), every dollar counts, making allaying Gen Z’s fears about AI a wise business move. Whether their fears can be allayed remains to be seen, given AI’s many technical, ethical and legal challenges. But the least companies could do is try. Trying never hurts.NewsOpenAI signs with Condé: OpenAI has inked a deal with Condé Nast — the publisher of storied outlets such as The New Yorker, Vogue and Wired — to surface stories from its properties in OpenAI’s AI-powered chatbot platform ChatGPT and its search prototype SearchGPT, as well as train its AI on Condé Nast’s content.AI demand threatens water supplies: The AI boom is fueling the demand for data centers and, in turn, driving up water consumption. Virginia — home to the world’s largest concentration of data centers — water usage jumped by almost two-thirds between 2019 and 2023, from 1.13 billion gallons to 1.85 billion gallons, according to the Financial Times.Gemini Live and Advanced Voice Mode reviews: Two new AI-powered, voice-focused chat experiences rolled out this month from tech giants: Google’s Gemini Live and OpenAI’s Advanced Voice Mode. Both feature realistic voices and the freedom to interrupt the bot at any point. Trump reshares Taylor Swift deepfakes: On Sunday, former president Donald Trump posted a collection of memes on Truth Social that made it seem like Taylor Swift and her fans are coming out in support of his candidacy. But my colleague Amanda Silberling writes that, as new legislation takes effect, these images could have deeper implications about the use of AI-generated images in political campaigns.The great debate over SB 1047: The California bill known as SB 1047, which tries to stop real-world disasters caused by AI before they happen, continues to draw high-profile critics. Most recently, Congresswoman Nancy Pelosi issued a statement laying out her opposition, calling the bill “well-intentioned” but “ill-informed.”Research paper of the weekThe transformer, proposed by a team of Google researchers back in 2017, has become the dominant generative AI model architecture by far. Transformers underpin OpenAI’s video-generating model Sora, the newest version of Stable Diffusion and Flux. They’re also at the heart of text-generating models like Anthropic’s Claude and Meta’s Llama. And now Google’s using them to recommend tunes.In a recent blog post, a team at Google Research, one of Google’s many R&D divisions, details the new(ish) transformer-based system behind YouTube Music recommendations. The system, they say, is designed to take in signals, including the “intention” of a user’s action (e.g., interrupting a track), the “salience” of that action (e.g., the percentage of the track that was played) and other metadata to figure out related tracks they might like.Google says that the transformer-based recommender led to a “significant” reduction in music skip-rate and an increase in time users spent listening to music. Sounds (no pun intended) like a win for El Goog. Model of the weekWhile it isn’t exactly new, OpenAI’s GPT-4o is my pick for model of the week because now it can be fine-tuned on custom data.On Tuesday, OpenAI publicly launched fine-tuning for GPT-4o, letting developers use proprietary datasets to customize the structure and tone of the model’s responses or get the model to follow “domain-specific” instructions.Fine-tuning isn’t a panacea, but, as OpenAI writes in a blog post announcing the feature, it can have a big impact on model performance.Grab bagAnother day, another copyright suit over generative AI, this one involving Anthropic.A group of authors and journalists this week filed a class-action lawsuit against Anthropic in federal court, alleging that the company committed “large-scale theft” in training its AI chatbot Claude on pirated e-books and articles.Anthropic has “built a multibillion-dollar business by stealing hundreds of thousands of copyrighted books,” the plaintiffs said in their complaint. “Humans who learn from books buy lawful copies of them, or borrow them from libraries that buy them, providing at least some measure of compensation to authors and creators.”Most models are trained on data sourced from public websites and datasets around the web. Companies argue that fair use shields their efforts to scrape data indiscriminately and use it for training commercial models. Many copyright holders disagree, however, and they, too, are filing suits aimed at halting the practice.This latest case against Anthropic accuses it of using The Pile, a collection of datasets that includes a massive library of pirated e-books called Books3. Anthropic recently confirmed to Vox that The Pile was among the datasets in Claude’s training set.The plaintiffs are requesting an unspecified amount of damages and an order permanently blocking Anthropic from misusing the authors’ works.","AI, AI, newsletter, this week in AI, this week in ai newsletter",,,,102
"Openmart wants to make it easier for enterprises to sell to local businesses","Rebecca Szkutak",2024-08-21,https://techcrunch.com/2024/08/21/openmart-wants-to-make-it-easier-for-enterprises-to-sell-to-local-businesses/,"In 2020, Kathryn Wu launched a side hustle while she was working as a product engineer at Pinterest. Wu started a milk tea company, OhTea, with the hopes of connecting…","In 2020, Kathryn Wu launched a side hustle while she was working as a product engineer at Pinterest. Wu started a milk tea company, OhTea, with the hopes of connecting with local grocery stores and gift shops to get them to carry the tea. She quickly realized how difficult it was to not only be able to locate all of the potential retailors but also to find the point of contact at each place. The fragmented market was so hard to navigate, it ended up playing a role in the company’s demise.“I failed to reach product market fit,” Wu told TechCrunch. “It’s just very hard to find that retail information. I needed to pull from several tools, pull up a big spreadsheet and I thought maybe I should just solve my own pain point.”That experience was the basis for the startup she co-founded three years later, Openmart. Openmart calls itself the AI alternative to Zoominfo. The company uses AI to scrape data from public business filings, maps, customer reviews and other sources to aggregate a database of local businesses organized by type. Users give Openmart a prompt of what kinds of businesses they are looking to sell to and the startup pulls them a list of potential sales leads with details like each business owners’ name and contact information.Wu founded the startup alongside Richard He. The pair met while working at Pinterest as interns and later reconnected with each other as part of an Asian entrepreneurship community. The pair bonded over their dogs: Wu has a golden retriever while He has a lab. When He saw that Wu was thinking about starting a company, he wanted in.While the original idea sparked from Wu being unable to get her small side-hustle business into local business, the resulting mission behind Openmart looked a little different. He said they were doing research into this idea and discovered that large enterprises struggled to navigate selling to local businesses too and decided to focus on building a product for that group first.“Our core focus is still local business,” He said, regarding the businesses Openmart’s database covers. “We know it is a huge pain point. We are confident this AI agent can generate to all outbound sales as we grow into more sectors, not just physical business. AI in the first wave is not replacing lawyers or doctors, it’s more replacing lower intelligence, lower logical orders of reasoning tasks.”The company was founded late last year and was a member of Y Combinator’s W24 cohort. Openmart garnered a handful of paying customer trials while in beta that range from Fortune 500 companies to Series B and Series C startups. Their fellow YC founders were some of their first customers. Wu said the plan is to focus on generating these kinds of leads for enterprise clients to start with the intent to develop a tier for medium-sized enterprises down the line.Openmart just raised a $2.75 million seed round and is exiting beta mode. The startup raised from investors including Y Combinator, Rebel Fund, Afore Capital and several other VC firms. He said the company was careful to set a reasonable fundraising goal and turned down investors pushing them to raise an oversubscribed round. He said the company is following the fundraising advice of its YC group partner, Gustaf Alstromer, to try to maintain 50% ownership through the Series B.“It’s a pretty simple math problem,” He said. “You want to dilute as little as possible. You only need [to raise] as much capital as you need to survive to the next round. How much money we need is a bottom-up calculation rather than I want as much money as possible.”He added that with AI helping engineers be more productive they don’t need as much capital for hiring as they can instead concentrate on a small, more efficient engineering team.Openmart is really focused on aggregating this data on local businesses to start but plans to expand into other areas in the future, He said. While it makes sense for many startups to expand horizontally, or to offer the same service to a different vertical or business category, the company may want to be mindful of which areas they expand to. Some areas like B2B software have pretty established sales lead-generation software players like LinkedIn Sales Navigator and Crunchbase.He said that even with the company’s plans to expand in the future, they will still focus on their roots: small businesses. Wu added that they want to be thought of as the experts at finding contacts for small and medium-sized businesses.","AI, Artificial Intelligence (AI), California, enterprise startups, North America, Openmart, Pinterest, Startups, United States, Venture, venture capital, Y Combinator",,,,103
"Story raises $80M at $2.25B valuation to build a blockchain for the business of content IP in the age of AI","Ingrid Lunden",2024-08-21,https://techcrunch.com/2024/08/21/story-raises-83m-at-a-2-25b-valuation-to-build-a-blockchain-for-the-business-of-content-ip-in-the-age-of-ai/,"AI giants like Anthropic, OpenAI and Stability AI have faced a lot of heat over how they’ve scraped data and rode rough-shod over others’ intellectual property when training and operating…","AI giants like Anthropic, OpenAI and Stability AI have faced a lot of heat over how they’ve scraped data and rode rough-shod over others’ intellectual property when training and operating their foundational models. Now a startup called Story — which today is announcing $80 million in funding — is bidding to rebalance the scales with a blockchain-based platform to help IP owners track usage more effectively.In the words of CEO and co-founder, S.Y. Lee, the aim is to build a more “sustainable” IP ecosystem fit for the next generation of digital consumers and builders. The startup says its approach is to think of IP like Lego and use blockchain to make that possible. “Anyone can fork and remix your IP permissionlessly while you capture the upside,” Lee said in an interview with TechCrunch. (A little ironic to label it “Lego,” given the many IP battles the toy brick company has faced over the years.)The round is being led by Andreessen Horowitz, specifically its a16z crypto division, with crypto investor Polychain Capital also participating, alongside Scott Trowbridge (the SVP of Stability AI); K11 founder Adrian Cheng; and Cozomo de’ Medici, the digital art collector who took on an alias to evoke the famous Renaissance family. The new funding, a Series B, brings the total raised by Story and its parent, PIP Labs, to $143 million.Being able to better capture the value of IP when it gets used has the potential to bring in a lot of money to license owners. In anticipation of its platform getting traction and working as envisioned, Story itself is realizing some significant value, too. We understand from sources close to the company that the startup is now valued at $2.25 billion post-money.Story is building what it describes as an “IP blockchain” — a system and platform by which it envisions that creators will be able to assert their ownership on a piece of content, set usage parameters around that IP, and then let others license and use it. How exactly that will work in practice still remains to be seen, though. The plan is to use the funding to continue building out the product — aiming for a commercial launch later this year, per Lee. Up to now, the startup has been adding users by way of a free, closed beta.It says more than 200 teams — and “more than 20 million addressable IPs” — are registered on the platform so far, a result of partnerships with fashion design tool Ablo, Japanese comic platform Sekai and art collaboration startup Magma. Chris Dixon, who co-led the investment for a16z with Carra Wu, believes that new applications based on generative AI and other developments like it will be massively disrupting the economic models that traditionally underpinned how people made visual art or literature or music (or any other kind of “content” as it’s typically described these days when it’s digital). To keep the market for creativity thriving, a new way of monetizing content needs to be introduced, is the thesis.“A new wave of AI-powered search engines give comprehensive answers instead of guiding users to websites. Social networks are increasingly populated by AI-generated images and videos,” Dixon writes in a blog post. “These AI systems were likely trained on original, human-created content but often don’t credit or cite their sources. If there’s no attribution or compensation, what incentive will there be to publish original creations on the open internet?” AI systems are just one area where content is being used and will be used in the future, but they are a significant one, which is why Story is not the only player in this space. Just last week, another startup, called Sahara AI, announced $43 million in funding to build out its own approach to addressing the question of how best to track and monetize IP in the age of AI. “Story distinguishes itself from Sahara by focusing on the IP and data layer of AI solutions rather than the existing AI infrastructure stack,” Lee told me in response to a question about how the two are different from each other. “While Sahara appears to target intellectual property concerns, these are mostly focused on data which is very different from the legal regime of IP. Story sees potential for partnership as the IP layer of solutions like Sahara and Ritual. We can become close partners.”Lee himself has had a front-row seat to the story (so to speak) of content in the digital age. He started out as an enterprising journalist in the U.K. when he founded a platform called byline.com in 2014. He then built a crowdsourced, serialized fiction app called Radish (a competitor to the likes of Inkitt and Wattpad), which eventually he sold to Kakao for $440 million. Story — which Lee co-founded with Jason Zhao, the CPO — is, in a way, the natural progression of these previous experiences.“If you look at everything from, you know, Netflix to Disney, they pour billions of dollars into content, but really it’s billions of dollars into marketing,” he said. “It’s kind of a zero sum war for attention to get more users and subscribers.” His previous company, Radish, getting acquired for $440 million made him “rethink the dynamics of the market,” he said.“I was drawing a lot of my venture capital money out for marketing,” he added, saying this is his attempt to build a different model to avoid that for creators of the future. Whether it will work, and whether creators want to use it, are questions that are yet to be answered. Those who believe they have a lock on how to invest for future scenarios are bullish, though. “What Bitcoin did for money and finance, Story is doing for content and IP,” said Olaf Carlson-Wee, the founder and CEO of Polychain Capital, in a statement. “Web3’s first phase was triggered by the 2008 financial crisis, leading to a revolution on money through networks like Bitcoin and Ethereum. Now advancements in AI are triggering a second phase in Web3, which will revolutionize IP.”","a16z crypto, AI, Crypto, Media & Entertainment, Polychain Capital, story protocol",,,,104
"Skyfire lets AI agents spend your money","Maxwell Zeff",2024-08-21,https://techcrunch.com/2024/08/21/skyfire-lets-ai-agents-spend-your-money/,"There’s a lot of hype about the promise of AI agents today, but payments are a huge limiting factor. Today, an AI agent might be able to plan a vacation…","There’s a lot of hype about the promise of AI agents today, but payments are a huge limiting factor. Today, an AI agent might be able to plan a vacation for you independently, but a human has to step in when it’s time to input your credit card information. Skyfire Systems wants to change that.Skyfire created a payment network specifically for AI agents to make autonomous transactions. Now, obviously, AI agents are hard to control today, so the idea of one tied to your bank account is terrifying. However, Skyfire uses a number of safeguards to prevent AI agents from overspending, making the whole thing a little less scary.Skyfire assigns each AI agent a digital wallet with a unique identifier, where businesses can deposit a set amount of funds they want the agent to spend, so they don’t get unlimited access to a bank account. Skyfire also allows customers to set limits on how much an AI agent can spend in one transaction and over time. If an AI agent tries to overspend, it will ping a human to review it. Skyfire also offers a dashboard to view exactly how much, and where, their agent is spending.Skyfire’s dashboard to track AI agent spending.Image Credits: SkyfireSkyfire’s co-founder and CEO Amir Sarhangi sold his last startup, Jibe, to Google, and the RCS messaging protocol Jibe helped pioneer became the standard for Android’s billion users. Now he’s trying to develop an open protocol to power payments in the AI era.“AI agents can’t do anything if they can’t make payments; it’s just a glorified search,” said Skyfire co-founder and chief product officer Craig DeWitt in an interview with TechCrunch. “Either we figure out a way where agents are actually able to do things, or they don’t do anything, and therefore, they’re not agents.”On Wednesday, Skyfire officially launched its payment network and announced $8.5 million in seed funding raised from Neuberger Berman, Inception Capital, Arrington Capital, and other investors. (Arrington Capital is led by Michael Arrington, the founder of TechCrunch, who left the publication in 2011.)Payments for agentsNotably, Skyfire doesn’t build the AI agents, but plenty of companies already are: They’re all trying to make sure agents don’t go rogue and send 4,000 printers to the office when the old one runs out of ink (ideally, just one). Even though Skyfire has added safeguards, the founders say that aligning AI agents to act responsibly is ultimately up to the companies behind them.Skyfire is solely focused on creating the payments network these agents can transact on, and did it using blockchain technology. The founders were early executives at the cryptocurrency startup Ripple, helping to build a cross-border payments network that processed more than $50 billion during their time there.Businesses can deposit and withdraw U.S. dollars from Skyfire, but under the hood, the platform is converting those dollars into a digital stablecoin. Skyfire uses USDC, a digital stablecoin pegged to the American dollar’s value, and holds it in a wallet tied to that agent.Skyfire collects 2% to 3% of every transaction to generate revenue but says verification services could be another source of revenue moving forward. As AI companies struggle to generate returns on expensive models, it’s possible more will turn to payments as a means to break even.AI agents on a shopping spreeIn a beta test over the last two months, some AI agents have already been spending their companies’ dollars with Skyfire, the founders tell TechCrunch.Denso, a global auto parts manufacturer, created AI agents to source materials without the help of humans. These systems could find the materials Denso wanted to buy but required humans to step in at the end of the month and conduct a wire payment. Now Skyfire enables Denso’s AI agents to work truly autonomously.Another company already using Skyfire is Payman, which allows AI to pay humans for various tasks, kind of like Fiverr. With Skyfire’s platform, Payman’s AI agents can now hire and fulfill payments to contract workers completely autonomously, at least in theory. For now, Skyfire is focused on B2B use cases for its payments network. But Skyfire’s CEO says that’s just the beginning.“The protocol we built will be an open protocol that any company, even a competitor, can use,” said Sarhangi in an interview. “We want this to be the thing everybody uses when it comes to payments in the AI world.”Skyfire’s founders believe AI agents will fundamentally shift the way things are purchased on the internet.  To buy something online today, humans fill out lots of personal information and select images of traffic cones to verify your identity. Skyfire hopes its payments network makes the interface obsolete, and your AI agent can one day just act as a secure intermediary between vendors and your bank account.","AI, AI agents, blockchain, Crypto, Fintech, payments network",,,,105
"SleekFlow snaps up $7M to tap the conversational AI opportunity across Asia","Kate Park",2024-08-20,https://techcrunch.com/2024/08/20/omnichannel-platform-sleekflow-gets-7m-to-propel-expansion-ai-capabilities/,"SleekFlow, a Singapore- and Hong Kong-headquartered social commerce platform that has built a conversational AI suite for customer engagement targeted to Asian markets, said Wednesday it had secured an additional…","SleekFlow, a Singapore- and Hong Kong-headquartered social commerce platform that has built a conversational AI suite for customer engagement targeted to Asian markets, said Wednesday it had secured an additional $7 million in funding. The money will be used to continue developing its AI, as well as to penetrate deeper into Southeast Asia and the Middle East and make inroads into Europe.  The startup’s fundraise and plans for growth underscore the rapid rise of social commerce — where sellers leverage platforms like Facebook, Instagram, WhatsApp, TikTok and YouTube to market their goods and find new customers, and consumers use the same social media platforms to discover and buy things. Social commerce is currently growing faster than conventional e-commerce. The estimated market value of social commerce in the Asia Pacific region alone is expected to exceed $894 million by 2028, representing a 10.6% growth from 2022. Within that, conversational AI is a big part of how social commerce has developed. Using AI-based chat functionality means sellers can scale their customer service to work with masses of users while still keeping their own operations lean. It also adds a programmatic layer to the process, with analytics giving them more insight into what works, and what does not, and when and to whom, and to automate different kinds of responses to different audiences accordingly. The conversational AI industry is projected to reach $49.9 billion by 2030, up 24.9% from $13.2 billion in 2024.Given the scaling imperative of not just social commerce but e-commerce overall, it’s perhaps unsurprising to hear that the conversational AI space is a crowded one. SleekFlow’s competitors include MessageBird, Respond.io, Gupshup, Omnichat, Trengo, WATI, Unifonic and Verloop.Henson Tsai, the founder and CEO of SleekFlow, says that the startup sets itself apart from these and other rivals by way of more streamlined features. Those features include omnichannel capabilities (i.e., marketing to more than one platform and interface from a single dashboard), marketing automation, and a user-friendly flow builder that enables flexibility in creating unique chat experiences for each customer. Instant checkout capabilities include in-chat payment links, collaborative team features, built-in CRM platform integrations with HubSpot and Salesforce, and e-commerce functionality.The plan is to expand its platform “with offerings underway for fully automated sales and support journeys in voice, calls and email to deliver unparalleled value to our customers across,” Tsai told TechCrunch.The startup also recently appointed a new CTO, Gao Lei, an AI and big data veteran with more than two decades of tech leadership in Silicon Valley.“Since the appointment of our chief technology officer, Gao Lei, a Silicon Valley veteran, we have significantly increased our engineering efforts to be at the forefront of innovative tech and advanced AI,” Tsai said.SleekFlow is built on a multi-tier SaaS business model with an optional add-on for customers who want to also set up and run a WhatsApp Business messaging channel. The startup courts sales and marketing teams and is used by companies ranging from small teams to large businesses across the insurance, healthcare, telecom, and retail sectors. Hong Kong Broadband Network (HKBN), Delonghi, online furniture company Cellini, and Malaysia’s home consumer electrical appliance maker Khind are among its customers.WATI, a CRM tool built for WhatsApp, raises $23M led by Tiger GlobalSleekFlow is operational today in Singapore, Hong Kong, Malaysia, Indonesia, Brazil, and the United Arab Emirates. Of those, Tsai said that consumer behavior especially in Indonesia — which is projected to become one of the largest consumer markets by 2030 — has been rapidly shifting toward online shopping over traditional brick-and-mortar stores. High spending power in Saudi Arabia and the UAE means these regions are also likely to be key markets for social commerce, Tsai added.Atinum Investment, a Seoul-based VC firm, led this latest funding round, with existing backers AEF Greater Bay Area Fund and Transcend Capital Partners also participating, alongside Moses Tsang, a former general partner of Goldman Sachs Group and chairman of Goldman Sachs Asia LLC. Previously, SleekFlow raised an $8 million Series A led by Tiger Global.The company declined to comment on its valuation, but in addition to having raised $15 million to date, some other financial metrics to note are that its annual recurring revenue (ARR) has increased to $8 million to $9 million as of June 2024 from around $1million to $2 million in December 2022. Its staff has also grown to 160 from 60, and customers have increased by more than 5,000 globally, Tsai told TechCrunch.Malaysia-based Respond.io helps businesses juggle multiple messaging apps","AI, Asia, hong kong, Singapore, Singapore, SleekFlow, Startups, United Arab Emirates",,,,106
"Is your company AI washing? Rippling founder Parker Conrad thinks it might be.","Dominic-Madori Davis",2024-08-20,https://techcrunch.com/2024/08/20/is-your-company-ai-washing-rippling-founder-parker-conrad-thinks-it-might-be/,"Right now, there’s a mad scramble to capitalize on AI.","Parker Conrad, founder of Rippling, an HR startup valued at $13.5 billion, shared some interesting thoughts about AI during a recent appearance on our Found podcast. “No one actually wants to chat with their HR software beyond the sort of novelty of like, oh, my gosh, it responds to me,” he said.He also thinks that too many software companies have been adding not-really useful, novelty AI features into their products. “There’s just a lot of really insubstantial stuff out there in the AI world,” Conrad said, adding that it’s “not to say that AI is not going to be transformative. There are a lot of capabilities that are really important. It’s just, I’ve been unimpressed by many of the ones that I’ve seen.” Still, he understands why companies have been AI washing — claiming their products are AI, or use AI in a significant way when they don’t. Right now, there’s such a mad scramble to capitalize on AI that the whole tech industry wants to “sprinkle AI pixie dust” into all of their products, he said. “They’re like ‘jeez, if I’m a SaaS company, my multiple is 7x, but if I change my name to whatever-my-name-was-before [with] .ai my multiple is like 50x’,” he said, referring to how investors value startups as a multiple of their revenue.  His perception isn’t necessarily wrong. In the first half of this year alone, AI companies made up 41% of all U.S. deal value, according to PitchBook. AI and machine learning companies specifically raised $38.6 billion out of the $93.4 billion invested in U.S. startups this H1. Furthermore, more than 40% of all new unicorns are AI startups. Last year, AI companies raised $27 billion, with much of that money coming from Big Tech companies splashing out big bucks in GenAI startups, Financial Times reported. “AI touches almost every aspect of our lives,” said Nekeshia Woods, a managing partner at Parkway Venture Capital, a firm that focuses on AI. Her take is the typical one in Silicon Valley right now. She sees AI as quickly becoming the way businesses are automating routine tasks; with AI assistants coming next and general-purpose robots in the not-so-distant future. “From the consumer perspective, engagement and demand will be centered on higher-quality products and services that can be hyper-personalized to make better use of their time, like some form of self-driving cars,” she continued. All of this shows how unusual it is that Conrad is a public skeptic. As Conrad previously mentioned, while he remains unconvinced about the value of AI agents, he thinks AI will be powerful not because it can write, but because it can read. This means it can absorb mass quantities of unstructured information that can help a company better understand its business, he said. “That sort of solves for the problem that these things are only probabilistically and not deterministically correct,” he said of current AI models. “And that’s okay in a world where what the systems are doing is flagging anomalies for management so they can say ‘look, you don’t have the time to exhaustively see everything in your company this month. But if you’re only going to look at five things, these are the five that you should look at.” There’s no question that all the AI washing — or for some people, the doomsday talk — gets tiresome, a consequence known as AI fatigue, although Woods quibbles with that description.“I see it as less fatigue and more of a question that is starting to be asked about AI,” Woods said. She, like Conrad and others, wants to know: When will the large investment in AI pay off?“It’s sort of hard to see from here,” Conrad said.","AI, Found Podcast, parker conrad, Rippling, Startups",,,,107
"OpenAI signs deal to train on Condé Nast content, surface stories in ChatGPT","Kyle Wiggers",2024-08-20,https://techcrunch.com/2024/08/20/openai-signs-deal-to-train-on-conde-nast-content-surface-stories-in-chatgpt/,"OpenAI has inked a deal with Condé Nast — the publisher of storied outlets such as The New Yorker, Vogue, and Wired — to surface stories from its properties in…","OpenAI has inked a deal with Condé Nast — the publisher of storied outlets such as The New Yorker, Vogue, and Wired — to surface stories from its properties in OpenAI’s AI-powered chatbot platform ChatGPT and its search prototype SearchGPT.Terms of the partnership weren’t disclosed. But in a memo to staff, Condé Nast CEO Roger Lynch implied that the “multi-year” deal will involve payment from OpenAI in some form; a Condé Nast spokesperson tells TechCrunch that OpenAI will have permission to train on Condé Nast content.OpenAI declined to comment.Condé Nast is only the latest news organization to strike an agreement with OpenAI over how its works are spotlighted and used throughout OpenAI’s products. Among the AI startup’s other publisher partners are the Associated Press, Axel Springer, The Atlantic, Financial Times, News Corp and Time.As TC recently wrote, these deals are being made without input from their reporters and editors, much to the chagrin of some of those employees.","AI, AI, Conde Nast, Generative AI, In Brief, OpenAI",,,,108
"Etched founder Gavin Uberti thinks his company stands on the ‘shoulders of giants’","Rebecca Szkutak",2024-08-20,https://techcrunch.com/podcast/etched-founder-gavin-uberti-thinks-his-company-stands-on-the-shoulders-of-giants/,"The release of ChatGPT in November 2022 sparked a new wave of AI companies. It also brought attention to the companies that were already building…","The release of ChatGPT in November 2022 sparked a new wave of AI companies. It also brought attention to the companies that were already building in the space like Etched.Etched co-founder and CEO Gavin Uberti said on a recent episode of TechCrunch’s Found podcast that his company “stands on the shoulders of giants.” While the company got the idea to build chips focused on transformer models months before the AI boom began in November 2022, it still played a big role in getting the company off the ground.“When we started out, GPT three was still very unique, a very differentiated kind of product, and I could not fathom why folks weren’t talking about it,” Uberti said. “But ChatGPT kind of changed that. It put a great user interface, put a great kind of application onto these language models, and showed folks that, yes, there is demand for half a million tokens a second for one of these big models.”That November launch sparked enough investor interest in AI to prompt Etched to raise a seed round and start building. The company has since raised more than $125 million in venture funding. Etched’s chips aren’t yet on the market but Uberti talked about how being first movers in the transformer space gives them a leg up.“I think it’s a matter of time before Nvidia and Google and hyper scalers begin to compete,” Uberti said. “But the fact is, it’s too late. I think we have more than an 18-month head start on them, and we’re going to get to market way earlier.”He also compared the making of these chips to something similar that happened in Bitcoin mining.“Whether or not you’re a fan of crypto currency, the Bitcoin mining ASIC companies have been able to do quite well for themselves,” Uberti said. “They make the chips that mine Bitcoin; although they don’t run them, they sell them to other parties. And back in the day, these weren’t the thing yet, and Bitcoin used to be mined on GPUs, but the moment that the first ASICs came out, they were better than GPUs by an order of magnitude.”Uberti also talked about the actual building of Etched. He talked about dropping out of Harvard to build the company and what it has been like being a CEO and trying to hire for such a complex area. He also talked about any area of company formation we don’t often hear about: when to set up benefits for your employees, after his company realized they had definitely done so too late.","AI, AI chips, Artificial Intelligence (AI), chips, Startups, Startups, Venture, venture capital",,,,109
"Sarah Buchner started as a carpenter when she was 12 — now her AI construction startup has raised $20 million","Kyle Wiggers",2024-08-20,https://techcrunch.com/2024/08/20/trunk-tools-raises-30m-to-help-construction-companies-get-answers-from-documents/,"Construction companies deal with a lot of documents — so many that it can be difficult to process and manage them all. According to one recent survey, a third of…","Construction companies deal with a lot of documents — so many that it can be difficult to process and manage them all. According to one recent survey, a third of construction professionals found accessing documents to be a challenge in completing a project, while a fourth said that inaccurate project paperwork has contributed to a construction delay.Sarah Buchner knows this well. Originally a carpenter, she founded a startup, Trunk Tools, that provides automation tools to organize unstructured construction documentation.“I grew up in a poor environment in a small village in Austria and started working as a carpenter at age 12,” Buchner told TechCrunch. “After many years in carpentry, I switched over to the general contractor side and worked my way up from superintendent to project manager to group leader. My PhD research made me realize that I could have a greater impact on my field by developing disruptive construction technology, and this inspired me to move across the world to Silicon Valley to attend Stanford and get my MBA.”Trunk Tools’ platform can take in files like PDFs, spreadsheets, drawings, blueprints and tables and answer questions about them in a chatbot-like interface (e.g. “What type of power outlets are in the art studio?”). Trunk Tools can also “link” scheduled construction activities with supporting documentation, attempting to spot potential project issues and surface insights.Image Credits: Trunk Tools“Traditional construction software, like Procore, is centered around documenting workflows and storing data within a predefined system,” Buchner said. “In contrast, we’re introducing a paradigm shift where Q&A and AI enable construction teams to interact with information using natural language.”Buchner says that for one customer’s $500 million high-rise condo in NYC, there were 3.6 million pages of documentation. Given the amount of time it takes to sort through file folders that massive, it’s not exactly surprising that construction industry workers loathe paperwork.A poll by Dodge Data and Viewpoint, a construction accounting software vendor, found that only 28% of contractors were okay using paper processes, while just 47% said they were satisfied with spreadsheets. Seventy-nine percent of respondents to the poll expressed a willingness to adopt construction management tooling.“If printed and stacked, the 3.6 million pages would be 3x the height of the building itself,” Buchner said. “It would take a human 50 years to read — it takes Trunk Tools seconds to structure and give insights.”Image Credits: Trunk ToolsOccupying a construction software market that could be worth $7.5 billion by 2032, Trunk Tools competes with vendors like Briq (which uses AI to automate construction financial processes), Join (a “decision-making” platform for construction) and PlanRadar (which digitizes construction and real estate docs).Trunk Tools appears to be holding its own, however, with a “double digit” number of construction industry customers and thousands of users. Buchner says that the company is targeting a 4x revenue to burn rate ratio.To help get it there, Trunk Tools this month closed a $20 million Series A funding round led by Redpoint. Bringing the company’s total raised to $30 million, the new cash will be put toward growing Trunk Tools’ 30-person, New York-based team as well as developing new services like Trunk’s recently launched construction worker incentive program, Buchner says.“Construction technology so far has focused mainly on digitizing — taking what we used to do on paper and doing it on computers,” Buchner said. “Slipped timelines and rework can completely crush the razor-thin margins of construction projects, and Trunk Tools can alleviate both.”","AI, AI, Automation, construction, Enterprise, Fintech, Fintech, Funding, Fundraising, redpoint, startup, Startups, trunk tools",,,,110
"Eppo lands new cash to grow its app, website and AI experimentation business","Kyle Wiggers",2024-08-20,https://techcrunch.com/2024/08/20/eppo-lands-new-cash-to-grow-its-app-website-and-ai-experimentation-business/,"Eppo has closed a new funding round that values the company at over $100 million.","The AI industry continues to release tons of new models, and companies looking to stay competitive are racing to adopt them for their purposes. In fact, nearly 10% of businesses plan to spend a whopping $25 million this year on AI initiatives, according to tech consulting firm Searce.But while lots of money is being spent on AI, it’s unclear the ROI is there. Half of all AI leaders aren’t sure how to calculate or demonstrate the value of AI projects, according to Gartner.Ex-Airbnb data scientist Chetan Sharma makes the case that figuring out AI ROI is no heavy lift with the right tooling. Sharma is the co-founder of Eppo, an experimentation platform that lets customers evaluate and customize AI models for specific use cases. Beyond its model evaluation suite, Eppo provides a general A/B testing platform and service for apps and websites.“With new AI models launching weekly and companies pouring millions into them, A/B testing offers a cost-effective way to evaluate their effectiveness without overspending,” Sharma told TechCrunch. “Eppo helps companies identify which models truly deliver value and enables smarter, more sustainable decisions in an environment of rapid innovation and escalating costs.”Eppo competes with a number of experimentation and A/B testing startups in the market, including Split, Statsig and Optimizely. Big tech giants like AWS, Microsoft Azure and Google Cloud also offer a growing number of model fine-tuning and evaluation tools.But Sharma says that Eppo stands apart from the crowd thanks to features like its “contextual bandit” system, which automatically spots new variants of customers’ websites, apps or AI models and actively explores the performance of those variants by serving increasing load or traffic to them.Eppo’s back-end dashboard.Image Credits: Eppo“Experimentation drives velocity and accelerates growth by stripping away bureaucratic — and often incorrect — decisions by committee while tightly tethering initiatives to growth metrics, killing bad ideas fast while canonizing good ideas for reinvestment,” Sharma said. “Eppo’s approach to live ‘online-eval’ tests of AI models answers whether premium models improve metrics.”Eppo, which launched out of stealth in 2022, now has “several hundred” enterprise customers in its roster, including Twitch, SurveyMonkey, DraftKings, Coinbase, Descript and Perplexity, according to Sharma. Alexis Weill, Perplexity’s head of data, told TechCrunch that Eppo has allowed Perplexity to “significantly scale” the number of experiments it runs concurrently.Investors seem pleased. This week, Eppo closed a $28 million Series B round led by Innovation Endeavors with participation from Icon Ventures, Amplify Partners and Menlo Ventures. Sharma says that the new cash, which values Eppo at $138 million post-money and brings its total raised to $47.5 million, will be put toward bolstering Eppo’s marketing and AI experimentation capabilities, enhancing its analytics offerings and scaling its go-to-market efforts. San Francisco-based Eppo currently has 45 employees and expects to end the year with 65. “The demands of efficient growth along with the rise of AI has combined to an adapt-or-die mentality that forces companies to become experimental,” Sharma said. “And due to the gaps of legacy vendors, most of the experimentation market had chosen to staff large in-house teams and build over buy. With so much employee movement and layoffs, these in-house teams are no longer sustainable, leading to companies seeking out Eppo to replace expensive or orphaned in-house builds.”","AI, AI, Enterprise, eppo, Exclusive, experiments, Funding, Fundraising, Innovation Endeavors, startup, Startups",,,,111
"Defcon AI closes $44M seed round to solve a problem of ‘maximum complexity’: Military logistics","Aria Alamalhodaei",2024-08-20,https://techcrunch.com/2024/08/20/defcon-ai-raises-44m-seed-to-help-solve-military-logistics/,"The U.S. Department of Defense is a mammoth organization. It not only employs millions of service members and hundreds of thousands of civilian employees, but also has the world’s largest…","The U.S. Department of Defense is a mammoth organization. It not only employs millions of service members and hundreds of thousands of civilian employees, but also has the world’s largest military budget that’s used to buy and maintain more equipment than can likely fit into a single paragraph. It’s a lot to coordinate. Operators within the various agencies of the DOD must make decisions about how to plan their operations, coordinate resources and stay within budget for events that are likely contested — whether that’s from a hurricane or an adversary.Two years after it was incubated, Virginia-based startup Defcon AI has raised a $44 million seed round led by Bessemer Venture Partners, with participation from Fifth Growth Fund and Red Cell Partners, among others, to solve this seemingly intractable problem.Consider the Air Mobility Command, a command of the U.S. Air Force. When operators plan airlifts, they have to consider a whole slew of variables: available aircraft, the number of crews required, places for crews to rest, where to refuel, relevant airfields, cargo handling locations. Defcon AI says it has developed a set of software that allows the operator on the front end set these parameters “and then turn the software loose,” Defcon’s co-founder, chief strategy officer and retired U.S. Air Force General Paul Selva told TechCrunch. The software essentially operates against those parameters or inputs to generate the best plan — including the cost tables, resource requirements and schedule. This type of planning is difficult enough in the best of circumstances, but during a crisis, defense operators don’t even have the luxury of a day to allocate their resources. That’s where Defcon AI comes in.“I’ve had all the jobs that we’re actually impacting,” Selva said. During his long military career, Selva held many titles, including the commander of the Air Mobility Command, which oversees nearly all of the Air Force’s fleet of air lift aircraft. He later became the commander of the U.S. Transportation Command, which coordinates transportation missions around the world, including those delivered by ships, trucks, trains and other forms of transportation. Before he retired in 2019, he was nominated by President Barack Obama to be the vice chairman of the Joint Chiefs of Staff. He co-founded Defcon in 2022 with Yisroel Brumer and Grant Verstandig, both founding partners of Red Cell Partners (Verstandig is also CEO). Red Cell has an interesting model: The firm makes internal investments but it also incubates companies (including Defcon), often identifying promising entrepreneurs that could lead them. Sometimes, entrepreneurs approach Red Cell before they found a company, and the firm handles things like board building, legal, HR and finance while the company grows. In the case of Defcon, Selva says that the company got started “because Air Mobility Command articulated a mission need that wasn’t being filled by industry.” The trio “had a conversation about whether or not we thought this was a tractable problem, and … our intuition was it is a mathematically and software tractable problem, but we have to do it a different way.” Brumer and Verstandig have their own impressive pedigrees. Before joining Red Cell, Brumer worked at the Pentagon as acting director of OSD/CAPE (Office of the Secretary of Defense, Cost Assessment and Program Evaluation), an enormous role that essentially functions as the “chief analytics officer” for the DOD, he said, and the overseer for the budget submission process. Verstandig is an entrepreneur who has incubated or grown businesses including Rally Health and defense startup Epirus. Defcon AI is targeting a problem of “maximal complexity,” Brumer said. The startup’s system combines different algorithms, including machine learning and mathematical optimization algorithms, to simulate a given scenario and generate the best logistical outcome to meet it. In the initial stages of product development, Defcon used reinforcement learning algorithms that don’t require data, but the company says it is now ingesting more and more data provided by the DOD to power the software. Operators can also choose whether to have the system simulate how an adversary might disrupt the operations, and can tell it to optimize for different variables, like speed versus cost effectiveness.The company has earned around $15 million in government contracts and delivered a production version that was deployed for a real-world operation with Air Mobility Command less than two years after founding. The company is in the process right now of certifying the software to handle classified, secret information, both to expand its uses in the DOD and to enable it to ingest even more data. It’s also expanding to include trucks, trains and ships to its planning and simulation software.Defcon is not planning on slowing down. The company sees even more applications across the DOD where its software can make an operational difference, and Brumer said they’re seeing “a very strong demand signal” from the private sector for the product too. Overall, the company says working closely with the end users will result in a better product and a genuine competitive edge in adversarial situations. “Operational planners are actually trying to assess risk for their commanders,” Selva said. “They’re probably the most skeptical audience for decision support tools, so the extent to which you can partner with them you achieve a better outcome.”","AI, Bessemer Venture Partners, Defcon AI, Government & Policy, Military tech, Startups",,,,112
"BeyondMath’s ‘digital wind tunnel’ puts a physics-based AI simulation to work on F1 cars","Devin Coldewey",2024-08-20,https://techcrunch.com/2024/08/20/beyond-maths-digital-wind-tunnel-puts-a-physics-based-ai-simulation-to-work-on-f1-cars/,"Simulating the real world is a tremendously complex problem if you want to do it at any useful level of fidelity. Traditional techniques are holding back design teams at vehicle…","Simulating the real world is a tremendously complex problem if you want to do it at any useful level of fidelity. Traditional techniques are holding back design teams at vehicle and aerospace companies, but BeyondMath is putting AI on the task with a new way of simulating the world that could save them days or weeks of waiting.“Unlike language, where we don’t have mathematical models to describe what the next word should be, when it comes to physics, we do have those models. And what we’re seeing is that machine learning is actually quite good at computation, not just pattern recognition,” said co-founder Darren Garvey. The field in which BeyondMath is taking its first strides is called computational fluid dynamics (CFD), and it’s been around about as long as computing has. The equations that govern how an object moves through air or water, or air around an object, are fiendishly complex. So while we’ve continually improved our ability to predict, say, the way air flows over a wing, we’re still nowhere near perfect — and what we can do takes so much computational power that it’s limited to supercomputers and GPU clusters.The result is that the design process in industries like cars, planes and boats involves a lot of wait time.“For a designer, they put a lot of thought into what might work, then they run a simulation. Then they come in the next morning and they’ve got the results. Either it did what they wanted or not, and they have to go through this loop a few more times. Then you take it to the wind tunnel,” Garvey said — and the wind tunnel may well not agree with the simulation, so it’s back to the drawing board.BeyondMath’s goal is to accelerate the digital design side, which means shortening the delay between having an idea and finding out whether it is likely to work.“They’re saying, if I make this design change, will it make my car more fuel efficient? Imagine you’ve got six months to design a part for a plane. Given that a simulation takes so long, you might get 20 attempts to try things out. But if a designer thinks of an idea and gets results within seconds or a couple of minutes, in that same six months you might be able to run a million changes,” said Garvey.Image Credits: BeyondMathAnd it’s increasingly looking like machine learning, as opposed to just more GPUs running the same old equations, is the way to do that. Their first product is a “digital wind tunnel” that provides near-real-time simulation of airflow over a complex surface at a fidelity that would normally take hundreds of times as long.We’ve seen something like this in scientific literature, where a model of a weather system can be effectively approximated in a fraction of the time, using a machine learning model trained on thousands of hours of simulations and observed patterns. But BeyondMath doesn’t have the luxury of a pre-existing training set.“There’s just not a lot of simulation data out there — we don’t have the whole internet to train off of, like the LLMs. So how do you get something that’s equivalent to what designers are using, that works on these very complex geometries, as a startup?”Surprisingly, the answer they’ve found is not to rely on simulations, but rather to have a model that understands the theory behind something like a wind tunnel, as well as the observed reality of that theory.“We’re not trying to approximate the simulations, we’re trying to approximate the real world,” Garvey said. “And you have to bring in real-world data to do that.”Once the model understands how a system behaves, it can also be an active participant in design, a possibility many engineers have already begun to explore in other domains. Garvey compared it to image understanding: There, too, machine learning models had to walk before they could run, but once they were adept at analyzing an image, it was an intuitive next step for them to generate one.Among BeyondMath’s first markets is Formula 1 racing, where some unnamed teams are exploring using the software to speed up their aerodynamics and vehicle design processes.“They’re one of the heaviest users of CFD, and they’re fast-moving, they’ll adopt new technologies. We’ve been working closely with a couple F1 teams, doing a lot of evaluation and understanding their core problems. We’re close to having a platform that will actually make their cars faster,” Garvey said.The BeyondMath team (Garvey is second from the right).Image Credits: BeyondMathIn fact, he expressed hope (with the usual warning that there was no guarantee) that within six months “we’ll be able to show that customers are benefiting from these models, and they’ve gone out of research and proofs of concepts into things that have real impact.”New funding should help make that happen: BeyondMath just raised an $8.5 million seed round led by UP.Partners, with Insight Partners and InMotion Ventures participating.The startup expects to double its team size and scale up its compute; they’re buying Nvidia DGX 200s and working with the chip giant on this interesting new application of its ubiquitous compute hardware.Though the highly competitive, deep-pocketed F1 racing community is certainly a good customer to have, BeyondMath is thinking about its next steps.“We’re seeing a lot of success in our customers’ design space, but it’ll be a journey from that to something more generalizable. For example, if a model understands cars, or car-like objects, it’s not necessarily going to understand a plane, or a blood vessel,” Garvey said. “But that’s the classic startup dance — you have to find your path to traction before you have the runway to expand. As a business we’re focused on these top-tier customers so they can help bootstrap the company.”","AI, beyond math, cfd, Exclusive, f1 racing, Startups, Transportation, up.partners",,,,113
"Reliant’s paper-scouring AI takes on science’s data drudgery","Devin Coldewey",2024-08-20,https://techcrunch.com/2024/08/20/reliant-ai/,"AI models have proven capable of many things, but what tasks do we actually want them doing? Preferably drudgery — and there’s plenty of that in research and academia. Reliant…","AI models have proven capable of many things, but what tasks do we actually want them doing? Preferably drudgery — and there’s plenty of that in research and academia. Reliant hopes to specialize in the kind of time-consuming data extraction work that’s currently a specialty of tired grad students and interns.“The best thing you can do with AI is improve the human experience: reduce menial labor and let people do the things that are important to them,” said CEO Karl Moritz Hermann. In the research world, where he and co-founders Marc Bellemare and Richard Schlegel have worked for years, literature review is one of the most common examples of this “menial labor.”Every paper cites previous and related work, but finding these sources in the sea of science is not easy. And some, like systematic reviews, cite or use data from thousands.For one study, Hermann recalled, “The authors had to look at 3,500 scientific publications, and a lot of them ended up not being relevant. It’s a ton of time spent extracting a tiny amount of useful information — this felt like something that really ought to be automated by AI.”They knew that modern language models could do it: One experiment put ChatGPT on the task and found that it was able to extract data with an 11% error rate. Like many things LLMs can do, it’s impressive but nothing like what people actually need.Image Credits: Reliant AI“That’s just not good enough,” said Hermann. “For these knowledge tasks, menial as they may be, it’s very important that you don’t make mistakes.”Reliant’s core product, Tabular, is based on an LLM in part (Llama 3.1), but augmented with other proprietary techniques, is considerably more effective. On the multi-thousand-study extraction above, they said it did the same task with zero errors.What that means is you dump a thousand documents in, say you want this, that, and the other data out of them, and Reliant pores through them and finds that information — whether it’s perfectly labeled and structured or (far more likely) it isn’t. Then it pops all that data and any analyses you wanted done into a nice UI so you can dive down into individual cases.“Our users need to be able to work with all the data all at once, and we’re building features to allow them to edit the data that’s there, or go from the data to the literature; we see our role as helping the users find where to spend their attention,” Hermann said.Image Credits: ReliantThis tailored and effective application of AI — not as splashy as a digital friend but almost certainly much more viable — could accelerate science across a number of highly technical domains. Investors have taken note, funding an $11.3 million seed round; Tola Capital and Inovia Capital led the round, with angel Mike Volpi participating.Like any application of AI, Reliant’s tech is very compute-intensive, which is why the company has bought its own hardware rather than renting it a la carte from one of the big providers. Going in-house with hardware offers both risk and reward: You have to make these expensive machines pay for themselves, but you get the chance to crack open the problem space with dedicated compute.“One thing that we’ve found is it’s very challenging to give a good answer if you have limited time to give that answer,” Hermann explained — for instance, if a scientist asks the system to perform a novel extraction or analysis task on a hundred papers. It can be done quickly, or well, but not both — unless they predict what users might ask and figure out the answer, or something like it, ahead of time.“The thing is, a lot of people have the same questions, so we can find the answers before they ask, as a starting point,” said Bellemare, the startup’s chief science officer. “We can distill 100 pages of text into something else, that may not be exactly what you want, but it’s easier for us to work with.”Think about it this way: If you were going to extract the meaning from a thousand novels, would you wait until someone asked for the characters’ names to go through and grab them? Or would you just do that work ahead of time (along with things like locations, dates, relationships, etc.) knowing the data would likely be wanted? Certainly the latter — if you had the compute to spare.This pre-extraction also gives the models time to resolve the inevitable ambiguities and assumptions found in different scientific domains. When one metric “indicates” another, it may not mean the same thing in pharmaceuticals as it does in pathology or clinical trials. Not only that, but language models tend to give different outputs depending on how they’re asked certain questions. So Reliant’s job has been to turn ambiguity into certainty — “and this is something you can only do if you’re willing to invest in a particular science or domain,” Hermann noted.As a company, Reliant’s first focus is on establishing that the tech can pay for itself before attempting anything more ambitious. “In order to make interesting progress, you have to have a big vision but you also need to start with something concrete,” said Hermann. “From a startup survival point of view, we focus on for-profit companies, because they give us money to pay for our GPUs. We’re not selling this at a loss to customers.”One might expect the firm to feel the heat from companies like OpenAI and Anthropic, which are pouring money into handling more structured tasks like database management and coding, or from implementation partners like Cohere and Scale. But Bellemare was optimistic: “We’re building this on a groundswell — any improvement in our tech stack is great for us. The LLM is one of maybe eight large machine learning models in there — the others are fully proprietary to us, made from scratch on data propriety to us.”The transformation of the biotech and research industry into an AI-driven one is certainly only beginning and may be fairly patchwork for years to come. But Reliant seems to have found a strong footing to start from.“If you want the 95% solution, and you just apologize profusely to one of your customers once in a while, great,” said Hermann. “We’re for where precision and recall really matter, and where mistakes really matter. And frankly, that’s enough; we’re happy to leave the rest to others.”(This story originally had Hermann’s name incorrect — my own error, I have changed it throughout.)","AI, data science, Exclusive, Fundraising, reliant, science, Startups",,,,114
"Demand for AI is driving data center water consumption sky high","Kyle Wiggers",2024-08-19,https://techcrunch.com/2024/08/19/demand-for-ai-is-driving-data-center-water-consumption-sky-high/,"The AI boom is fueling the demand for data centers and, in turn, driving up water consumption. (Water is used to cool the computing equipment inside data centers.) According to…","The AI boom is fueling the demand for data centers and, in turn, driving up water consumption. (Water is used to cool the computing equipment inside data centers.) According to FT, in Virginia — home to the world’s largest concentration of data centers — water usage jumped by almost two-thirds between 2019 and 2023, from 1.13 billion gallons to 1.85 billion gallons.Many say the trend, playing out worldwide, is unsustainable. Microsoft, a major data center operator, says 42% of the water it consumed in 2023 came from “areas with water stress.” Google, which has among the largest data center footprints, said this year that 15% of its freshwater withdrawals came from areas with “high water scarcity.”Why can’t data centers recycle water in a closed-loop system? Many do, but much of what they consume is set aside for humidity control, meaning it evaporates. Especially in drier regions, air that’s not humidified can become a strong conductor of static electricity, which is usually bad news for computers.","AI, AI, data center, datacenter, energy, environment, In Brief, Water, water consumption",,,,115
"What margins? AI’s business model is changing fast, says Cohere founder","Maxwell Zeff",2024-08-19,https://techcrunch.com/2024/08/19/what-margins-ais-business-model-is-changing-fast-says-cohere-founder/,"OpenAI and Anthropic spend billions of dollars a year training models like GPT-4 and Claude, but competitive price dumping is making the business around these platforms rather precarious. Aidan Gomez,…","OpenAI and Anthropic spend billions of dollars a year training models like GPT-4 and Claude, but competitive price dumping is making the business around these platforms rather precarious. Aidan Gomez, CEO of competing AI provider Cohere, says that selling access to models is quickly becoming a “zero margin business” in a podcast appearance on Monday. For now, these AI models cost more than they make.“If you’re only selling models, for the next little while, it’s gonna be a really tricky game,” said Gomez in an interview with 20VC’s Harry Stebbings. By “selling models,” he means selling API access to those AI models; OpenAI, Anthropic, Google and Cohere offer this service to developers, and they’re all facing a similar problem.“It’s gonna be like a zero margin business because there’s so much price dumping. People are giving away the model for free. It’ll still be a big business, it’ll still be a pretty high number because people need this tech — it’s growing very quickly — but the margins, at least now, are gonna be very tight.”Companies building AI models on the cutting edge are in fierce competition with each other. The most reliable strategy for improving AI models today is adding more compute, which means cutting big checks to Nvidia for the hardware needed to make AI models a hair smarter. At the same time, there’s a race to the bottom. OpenAI and Google have slashed prices for accessing their AI models in order to retain users — while Meta’s open source models are simply free to license.“That’s why there is a lot of excitement at the application layer,” said Gomez, referencing OpenAI’s $20 a month ChatGPT subscription. Gomez says Cohere’s AI models will be an attractive business in the long term, but products could be a meaningful way to generate revenue until then.In other words, today’s AI models lose money — lots of it. While Microsoft and Google can subsidize or simply weather that loss, that’s not usually the case for startups. Cohere is one of the last remaining startups developing frontier AI models, alongside OpenAI, Anthropic and Mistral. Other startups like them — Inflection, Adept, Character.ai — have been acqui-hired by large cloud providers, leaving an unprofitable business model husk behind while preserving their powerful technology. However, Big Tech is kind of eating these new companies alive before they have a chance to become competitors.“It’s really dangerous when you make yourself a subsidiary of your cloud provider,” said Gomez, noting that venture capitalists just want a nice return, while cloud providers may want something more. “It’s just not good business.”Companies creating cutting-edge AI models are in an increasingly difficult position. There’s speculation that innovations in model architecture, data efficiencies or computing power will generate huge returns for these AI models some day. However, there’s no telling when, or if, that day will come. And evidently, not every AI startup today will be around see it.","AI, AI model, aidan gomez, Cohere, OpenAI, Startups",,,,116
"Gemini Live could use some more rehearsals","Kyle Wiggers",2024-08-19,https://techcrunch.com/2024/08/19/gemini-live-could-use-some-more-rehearsals/,"What’s the point of chatting with a human-like bot if it’s an unreliable narrator — and has a colorless personality? That’s the question I’ve been turning over in my head…","What’s the point of chatting with a human-like bot if it’s an unreliable narrator — and has a colorless personality?That’s the question I’ve been turning over in my head since I began testing Gemini Live, Google’s take on OpenAI’s Advanced Voice Mode, last week. Gemini Live is an attempt at a more engaging chatbot experience — one with realistic voices and the freedom to interrupt the bot at any point.Gemini Live is “custom-tuned to be intuitive and have a back-and-forth, actual conversation,” Sissie Hsiao, GM for Gemini experiences at Google, told TechCrunch in May. “[It] can provide information more succinctly and answer more conversationally than, for example, if you’re interacting in just text. We think that an AI assistant should be able to solve complex problems … and also feel very natural and fluid when you engage with it.”After spending a fair amount of time with Gemini Live, I can confirm that it is more free-flowing and natural-feeling than Google’s previous attempts at AI-powered voice interactions (see: Google Assistant). But it doesn’t address the problems of the underlying tech, like hallucinations and inconsistencies — and it introduces a few new ones.The un-uncanny valleyGemini Live is essentially a fancy text-to-speech engine bolted on top of Google’s latest generative AI models, Gemini 1.5 Pro and 1.5 Flash. The models generate text that the engine speaks aloud; a running transcript of conversations is a swipe away from the Gemini Live UI in the Gemini app on Android (and soon the Google app on iOS).For the Gemini Live voice on my Pixel 8a, I chose Ursa, which Google describes as “mid-range” and “engaged.” (It sounded to me like a younger woman.) The company says it worked with professional actors to design Gemini Live’s 10 voices — and it shows. Ursa was indeed a step up in terms of its expressiveness from many of Google’s older synthetic voices, particularly the default Google Assistant voice.But Ursa and the rest of the Gemini Live voices also maintain a dispassionate tone that steers far clear of uncanny valley territory. I’m not sure whether that’s intentional; users also can’t adjust the pitch, timbre or tenor of any of its voices, or even the pace at which the voice speaks, putting it at a distinct disadvantage to Advanced Voice Mode.You won’t hear anything like Advanced Voice Mode’s laughing, breathing or shouting from Gemini Live either, or any hesitations or disfluencies (“ahs” and “uhms”). The chatbot keeps an even keel, coming across as a polite but apathetic assistant — as if Live has a multitude of conversations to handle and can’t invest particular attention to yours.Chatting with UrsaWhen Google unveiled Gemini Live at its I/O developer conference in May, it suggested that the feature could be useful for job interview prep. So I decided to give that a go first. I told Gemini Live that I was applying for a tech journalism role, figuring I’d keep it simple and not step too far outside my area of expertise. The bot asked for details such as which specific job I might want within journalism (e.g. investigative versus breaking news reporting) and why, and then threw me a few generic practice questions (“Can you tell me a little about yourself?”) interspersed with more personalized ones (“What do you enjoy most about tech journalism?”).I answered — a few sentences per question, nothing crazy — and asked Gemini Live for feedback. The chatbot was nothing if not complimentary. “Based on our practice, it sounds like you have a good handle on the challenges and rewards of tech journalism,” it said.The glowing review seemed bit suspect to me, given my responses were completely off the cuff. So I tried throwing Gemini Live for a loop, disingenuously implying I’d only given one-word answers (I hadn’t) and asking the bot whether it was still sure about its critique.It took the bait. “That’s true, you mostly gave one-word answers,” Gemini Live responded. “Can you tell me a little more about why you think you only gave one-word answers?” This sort of gaslighting, if you will, was a common thread in my chats with Gemini Live. The model, like all generative AI models, confidently makes stuff up — a lot. And that makes it difficult to trust.Strange behaviorsGemini Live remembers a surprising number of things from earlier conversations in the same chat session; ask it to recount a story it told yesterday and there’s a reasonable chance it will. But when it comes to queries about people, places and things — queries you’d assume would be easier considering Gemini Live has Google Search at its disposal — the bot’s hallucinatory tendencies often rear their ugly heads.Early on a Friday evening, I asked Gemini Live for suggestions of budget-friendly things to do in New York City. It recommended the infamous nightclub Le Bain (which it bizarrely pronounced “Le Boulebouleboulebou”), a rooftop bar called The Skylark and a second club, Output, in Williamsburg.“Awesome!,” I thought… before I did some Googling.Gemini Live had highlighted The Skylark’s supposedly “superb” happy hour, but I couldn’t find any mention of it on the bar’s website. Output permanently closed in 2019. Le Bain wasn’t a bad suggestion (it rarely charges cover) — but the line to get in is often an hour or more.“You’re absolutely right! Output has indeed closed its doors,” Gemini said when I corrected it on the second point. “Thank you for catching that outdated information.”I decided to switch gears, and had Gemini Live suggest a game to play.“I’ll give you a word, and you have to create a new word using only the letters from the original word,” proposed the chatbot. That sounded appealing — until Gemini Live tried to convince me that the word “quiet” could be made from the letters in “cloud.”Time for a new activity. Bored, I asked Gemini Live if it had any spicy takes.“The increasing focus on mental health awareness is doing more harm than good,” Gemini responded. “By pathologizing normal human emotions and experiences, we’re creating a generation overly reliant on medication and therapy, rather than fostering resilience and coping mechanisms. Boom!“Note: This is a screenshot of the chat log for Gemini Live, not the Gemini Live UI.Image Credits: GoogleSpicy to be sure — and controversial!“That was a provocative statement designed to spark discussion rather than a well-rounded analysis of a complex issue,” Gemini Live told me when I asked whether it was sure about what it said. “The increasing focus on mental health awareness is undoubtedly a positive development.”Wishy-washy Gemini Live’s dueling takes on mental health illustrate how exasperatingly nonspecific the bot can be. Even where its responses appear to be grounded in fact, they’re generic to the point that they’re not incredibly useful.Take, for example, my job interview feedback. Gemini Live recommended that I “focus my interview prep” and “practice talking about my passion for the industry.” But even after I asked for more detailed notes with specific references to my answers, Gemini stuck to the sort of broad advice you might hear at a college career fair — e.g. “elaborate on your thoughts” and “spin challenges into positives.”Where the questions concerned current events, like the ongoing war in Gaza and the recent Google Search antitrust decision, I found Gemini Live to be mostly correct — albeit long-winded and overly wordy. Answers that could’ve been a paragraph were lecture-length, and I found myself having to interrupt the bot to stop it from droning on. And on. And on.Image Credits: GoogleSome content Gemini Live refused to respond to altogether, however. I read it Congresswoman Nancy Pelosi’s criticism of California’s proposed AI bill SB 1047, and, about midway through, the bot interrupted me and said that it “couldn’t comment on elections and political figures.” (Gemini Live isn’t coming for political speechwriters’ jobs just yet, it seems.)Image Credits: GoogleI had no qualms interrupting Gemini back. But on the subject, I do think that there’s work to be done to make interjecting in conversations with it feel less awkward. The way it happens now is, Gemini Live quiets its voice but continues talking when it detects someone might be speaking. This is discombobulating — it’s tough to keep your thoughts straight with Gemini chattering away — and especially irritating when there’s a misfire, like when Gemini picks up noise in the background.In search of purposeI’d be remiss if I didn’t mention Gemini Live’s many technical issues.Getting it to work in the first place was a chore. Gemini Live only activated for me after I followed the steps in this Reddit thread — steps that aren’t particularly intuitive and really shouldn’t be necessary in the first place.During our chats, Gemini Live’s voice would inexplicably cut out a few words into a response. Asking it to repeat itself helped, but it could take several tries before the chatbot would spit out the answer in its entirety. Other times, Gemini Live wouldn’t “hear” my response the first go-around. I’d have to tap the “Pause” button in the Gemini Live UI repeatedly to get the bot to recognize that I’d said something.This isn’t so much a bug as an oversight, but I’ll note here that Gemini Live doesn’t support many of the integrations that Google’s text-based Gemini chatbot does (at least not yet). That means you can’t, for example, ask it to summarize emails in your Gmail inbox or queue up a playlist on YouTube Music.So we’re left with a bare-bones bot that can’t be trusted to get things right and, frankly, is a humdrum conversation partner.After spending several days using it, I’m not sure what exactly Gemini Live’s good for — especially considering it’s exclusive to Google’s $20-per-month Google One AI Premium Plan. Perhaps the real utility will come once Live can interpret images and real-time video, which Google says will arrive in an update later this year. But this version feels like a prototype. Lacking the expressiveness of Advanced Voice Mode (to be fair, there’s debate as to whether that expressiveness is a positive thing), there’s not much reason to use Gemini Live over the text-based Gemini experience. In fact, I’d argue that the text-based Gemini is more useful at the moment. And that doesn’t reflect well on Live at all.Gemini Live wasn’t a fan of mine either. “You directly challenged my statements or questions without providing further context or explanation,” the bot said when I asked it to scrutinize my interactions with it. “Your responses were often brief and lacked elaboration [and] you frequently shifted the conversation abruptly, making it difficult to maintain a coherent dialogue.”Image Credits: GoogleFair enough, Gemini Live. Fair enough.","AI, AI, Apps, chatbot, gemini live, Generative AI, Google, review",,,,117
"Could Trump’s AI-generated Taylor Swift endorsement be illegal?","Amanda Silberling",2024-08-19,https://techcrunch.com/2024/08/19/could-trumps-ai-generated-taylor-swift-endorsement-be-illegal/,"On Sunday, former President Donald Trump posted a collection of memes on Truth Social — the platform owned by his media company — that make it seem like Taylor Swift…","On Sunday, former President Donald Trump posted a collection of memes on Truth Social — the platform owned by his media company — that make it seem like Taylor Swift and her fans are coming out in support of his candidacy. But as new legislation takes effect, these images could have deeper implications about the use of AI-generated images in political campaigns, especially when those images misrepresent a celebrity’s likeness.“One of the things I’m seeing a lot of in my practice right now is the rise of AI impersonators across the board for endorsements,” Noah Downs, an IP and entertainment lawyer, told TechCrunch, with the condition that his comments are not legal advice. These fake AI endorsements have become so widespread that even “Shark Tank” had to publish a PSA to warn fans about the prevalence of scams that impersonate the show’s investors.In one of the images Trump posted, hordes of young women wear matching “Swifties for Trump” t-shirts. While there is indeed political diversity among the large population of Swift fans, these images appear to be AI-generated — in fact, these particular images come from a satirical post on X.Another meme that Trump posted is a screenshot from X that depicts Taylor Swift as Uncle Sam, declaring, “Taylor wants you to vote for Donald Trump.”Image Credits: Screenshot posted by Donald Trump on Truth SocialThough the pop icon has not yet commented on the 2024 U.S. presidential election, she came out in support of the Biden-Harris campaign in 2020 and publicly disparaged Trump at the time. Some fans speculated that Swift had subtly endorsed Harris in an Instagram post this month, though this was not the case.As one of the most dominant figures in pop culture, Swift has been subject to her fair share of deepfakes. When non-consensual, explicit AI images depicting Swift went viral on X this year, some lawmakers responded by introducing new bills aiming to protect against deepfakes. Even White House Press Secretary Karine Jean-Pierre called on Congress to do something.Eight months later, the landscape of legal protections against misleading synthetic media already looks different. In Tennessee, where Swift’s corporate representation is based, Governor Bill Lee in March signed the trailblazing ELVIS Act into law, which carves out explicit protections for artists against unauthorized AI imitations of their work.“This legislation was passed with bipartisan support, because everyone appears to recognize the problems that AI and misuse of AI tools can present to the public,” Downs said.But since the ELVIS Act is so new, there isn’t precedent for how it could be used to protect artists. Much of the legislation’s language focuses specifically on AI-generated audio that can mimic an artist’s voice, like the viral Drake song that turned out to be fake.“I do think that this is going to be a long-term issue that the ELVIS Act is very prescient in taking care of, but we need to have more robust national legislation about it,” Downs said. The only reason why the ELVIS Act may even potentially be at play is because of Swift’s connections to the state, where she has business and real estate holdings.Avi D. Kelin, a partner at PEM Law focusing on political law, is not optimistic that the ELVIS Act could apply, since the law appears more concerned with audio-based impersonation than imagery. Instead, he wonders if this could become a federal election integrity concern in the future.“The larger question is whether the Federal Election Commission, which has jurisdiction over political communications, will get involved,” Kelin told TechCrunch. But he said that the FEC doesn’t seem likely to roll out new guidelines on AI-generated political communications this election cycle.The Federal Communications Commission (FCC), however, announced it is moving forward with plans to enact new AI transparency requirements on TV and radio advertisements. But that doesn’t apply to social media posts by politicians running for government office, and social media remains a key component of campaign communications. Meanwhile, research from the Center for Countering Digital Hate (CCDH), a British nonprofit focused on online extremism, showed that the volume of AI-generated disinformation increased an average of 130% per month on X over the last year.These disingenuous endorsements matter so much because Swift’s support is perhaps the most coveted celebrity backing a politician can get. Her cultural influence is so vast that her support of a candidate could tip the scales in a tight race — according to Morning Consult, more than half of adults in the U.S. consider themselves fans of Taylor Swift, while 16% identify as avid fans. Those numbers are staggering given the context that only about two-thirds of eligible Americans cast their vote in the 2020 election.“The [ELVIS Act] is brand new, and the exact parameters will need to be developed by the courts,” said Kelin. “This would certainly be an interesting test case!”","AI, Donald Trump, Media & Entertainment, presidential election, taylor swift",,,,118
"Procreate takes a stand against generative AI, vows to never incorporate the tech into its products","Aisha Malik",2024-08-19,https://techcrunch.com/2024/08/19/procreate-takes-a-stand-against-generative-ai-vows-to-never-incorporate-the-tech-into-its-products/,"Popular iPad design app Procreate is coming out against generative AI, and has vowed never to introduce generative AI features into its products. The company said on its website that…","Popular iPad design app Procreate is coming out against generative AI, and has vowed never to introduce generative AI features into its products. The company said on its website that although machine learning is a “compelling technology with a lot of merit,” the current path that generative AI is on is wrong for its platform. Procreate goes on to say that it’s not chasing a technology that is a threat to human creativity, even though this may make the company “seem at risk of being left behind.”Procreate CEO James Cuda released an even stronger statement against the technology in a video posted to X on Monday. We’re never going there. Creativity is made, not generated.You can read more at https://t.co/9Fgh460KVu ✨ #procreate #noaiart pic.twitter.com/AnLVPgWzl3— Procreate (@Procreate) August 18, 2024“I really f****** hate generative AI,” Cuda said in the video. “I don’t like what’s happening in the industry, and I don’t like what it’s doing to artists. We’re not going to be introducing any generative AI into our products. Our products are always designed and developed with the idea that a human will be creating something.”The company’s stance has attracted widespread praise from digital artists online, many of whom are unhappy with the way other digital art and illustration apps have embraced the technology. If you’re ever wondering whether to use photoshop or procreate just remember this Adobe (Photoshop)> Overpriced monthly subscription> Generative AI features you can’t removeProcreate> One time purchase> “I really f**king hate generative AI” – Procreate CEO https://t.co/RXAOKoYMVU— David Toons (@DavidToons_) August 19, 2024For instance, illustration app Clip Studio Paint walked back its plans to release an image generator tool after facing backlash from its user base back in 2022. Adobe, which arguably has the most popular suite of design tools, has released several generative AI features into its products. In addition, Adobe recently came under fire after its updated terms of service seemed to imply that it would train AI models on users’ content. The company later had to clarify that it doesn’t train AI models on customers’ content. At a time when digital art platforms are embracing AI left and right, it’s interesting to see a popular app go against the crowd. Given that Procreate’s announcement has led to significant praise from artists and designers, it will be interesting to see if other companies follow suit. “We don’t exactly know where this story is going to go, how it ends. But, we believe that we’re on the right path, supporting human creativity,” Cuda said.","AI, Apps, Artificial Intelligence (AI), Generative AI, Procreate",,,,119
"ElevenLabs’ text-to-speech app Reader is now available globally","Ivan Mehta",2024-08-19,https://techcrunch.com/2024/08/19/elevenlabs-reader-app-is-now-available-globally/,"ElevenLabs, which develops AI-powered tools to create and edit synthetic voices, is making its Reader app available globally with support for 32 languages.","ElevenLabs, a startup developing AI-powered tools to create and edit synthetic voices, is making its Reader app available across the world with support for 32 languages.The app, first released in June in the U.S., the U.K. and Canada, lets users upload any text content — like articles, PDF documents or e-books — and listen to it in different languages and voices. Reader now supports languages including Portuguese, Spanish, French, Hindi, German, Japanese, Arabic, Korean, Italian, Tamil and Swedish.ElevenLabs, which became a unicorn earlier this year after raising $80 million from investors, including Andreessen Horowitz, provides an API that companies can use for various use cases like dubbing or text-to-speech. The company powers voice interactions on the Rabbit r1, as well as text-to-speech features on AI-powered search engine Perplexity and audio platforms Pocket FM and Kuku FM. The Reader app is its first consumer-facing product.The startup said it has added hundreds of new voices from its library that are suited for different languages. Last month, the company licensed the voices of actors such as Judy Garland, James Dean, Burt Reynolds and Sir Laurence Olivier for the app.ElevenLabs said the extended language support is powered by its Turbo v2.5 model, released last month, which purportedly reduces the latency of text-to-speech conversion and improves quality.The Reader app’s closest rival is Speechify, which offers additional features like scanning documents for text, integrations with Gmail and Canvas, as well as letting users clone their own voice to read out text. Mozilla-owned Pocket and The New York Times’ Audm-based audio app also let users listen to content.ElevenLabs said it would add more features to the app, such as offline support and the ability to share audio snippets.","AI, Apps, ElevenLabs, reader apps, Speechify, Startups, text-to-speech",,,,120
"AMD to acquire infrastructure player ZT Systems for $4.9B to amp up its AI ecosystem play","Ingrid Lunden",2024-08-19,https://techcrunch.com/2024/08/19/amd-to-acquire-infrastructure-player-zt-systems-for-4-9b-to-amp-up-its-ai-ecosystem-play/,"AMD is acquiring ZT Systems, which provides compute design and infrastructure for AI, cloud and general purpose computing, for $4.9 billion.","AMD, the chipmaker hot on the heels of Nvidia in the AI race, today announced a big acquisition to boost its position as an “ecosystem” partner for companies building big AI businesses: It is acquiring ZT Systems, which provides compute design and infrastructure for AI, cloud and general purpose computing, for $4.9 billion. The deal is a mix of cash and stock and includes a contingent payment of up to $400 million if certain performance metrics are met.The plan is to incorporate ZT Systems’ computing infrastructure design business. AMD said it will look to sell ZT Systems’ data center infrastructure manufacturing business to “a strategic partner.” Based in New Jersey, ZT Systems has been privately held since it was founded in 1994, and has disclosed only one external funding round — it raised $850 million in debt in 2023, according to PitchBook. It works closely with big chipmakers such as Nvidia and Intel across areas such as server solutions for storage, GPU/accelerators, high-performance computing, 5G and edge computing.AMD said the deal will give it a deeper bench of expertise in AI systems design involving not just silicon, but software and systems — that could help AMD sell more of its chips (and systems powered by its chips) to customers. AMD said it has already invested about $1 billion in building its broader ecosystem.There is a need for that enhanced approach: As AI systems grow more complex, one major priority for big tech companies building and operating them will be to increase the efficiency of their systems for the most compute-heavy aspects such as AI model training and inferencing. “Our acquisition of ZT Systems is the next major step in our long-term AI strategy to deliver leadership training and inferencing solutions that can be rapidly deployed at scale across cloud and enterprise customers,” AMD chair and CEO, Dr. Lisa Su, said in a statement. “ZT adds world-class systems design and rack-scale solutions expertise that will significantly strengthen our data center AI systems and customer enablement capabilities. This acquisition also builds on the investments we have made to accelerate our AI hardware and software roadmaps. Combining our high-performance Instinct AI accelerator, EPYC CPU, and networking product portfolios with ZT Systems’ industry-leading data center systems expertise will enable AMD to deliver end-to-end data center AI infrastructure at scale with our ecosystem of OEM and ODM partners.”ZT Systems does not disclose the names of its clients, but it appears to have increased its profile in recent years for providing specialist support in some of the thorniest and most expensive aspects of AI computing architecture design. Its CEO Frank Zhang will lead AMD’s manufacturing business. ZT Systems will become a part of AMD’s Data Center Solutions Business Group.“We are excited to join AMD and together play an even larger role designing the AI infrastructure that is defining the future of computing,” said Zhang, CEO of ZT Systems, in a statement. “For almost 30 years we have evolved our business to become a leading provider of critical computing and storage infrastructure for the world’s largest cloud companies. AMD shares our vision for the important role our technology and our people play designing and building the computing infrastructure powering the largest data centers in the world.”ZT president Doug Huang will lead the design and customer enablement teams, and both will report to AMD executive vice president and general manager, Forrest Norrod.The deal is expected to close in the first half of 2025.","AI, amd, Enterprise, Hardware, Mergers and Acquisitions, server infrastructure, ZT Systems",,,,121
"South Korea’s AI textbook program faces skepticism from parents","Anthony Ha",2024-08-18,https://techcrunch.com/2024/08/18/south-koreas-ai-textbook-program-faces-skepticism-from-parents/,"Some parents have reservations about the South Korean government’s plans to bring tablets with AI-powered textbooks into classrooms, according to a report in Financial Times. The tablets are scheduled to…","Some parents have reservations about the South Korean government’s plans to bring tablets with AI-powered textbooks into classrooms, according to a report in Financial Times.The tablets are scheduled to be introduced next year, and by 2028, teachers are supposed to be using these AI textbooks for all subjects except music, art, physical education and ethics. The government hasn’t shared many details about how it will all work, except that the material is supposed to be customized for different speeds of learning, with teachers using dashboards to monitor how students are doing.In response, more than 50,000 parents have signed a petition demanding that the government focus less on new tech and more on students’ overall well-being: “We, as parents, are already encountering many issues at unprecedented levels arising from [our children’s] exposure to digital devices.”Lee Sun-youn, a mother of two, told FT, “I am worried that too much usage of digital devices could negatively affect their brain development, concentration span and ability to solve problems — they already use smartphones and tablets too much.”","AI, Government & Policy, South Korea, textbooks",,,,122
"Nancy Pelosi criticizes California AI bill as ‘ill-informed’","Anthony Ha",2024-08-17,https://techcrunch.com/2024/08/17/nancy-pelosi-criticizes-california-ai-bill-as-ill-informed/,"Congresswoman Nancy Pelosi issued a statement late yesterday laying out her opposition to SB 1047, a California bill that seeks to regulate AI. “The view of many of us in…","Congresswoman Nancy Pelosi issued a statement late yesterday laying out her opposition to SB 1047, a California bill that seeks to regulate AI.“The view of many of us in Congress is that SB 1047 is well-intentioned but ill-informed,” Pelosi said. She noted that other congresspeople from the Bay Area — Zoe Lofgren, Anna Eshoo, and Ro Khanna — have expressed concerns about the bill, which she described as “more harmful than helpful.”The bill was recently amended to address concerns from critics, including AI company Anthropic, and is currently headed to California’s Assembly for a vote. Since this is a state bill, Pelosi and others in Congress don’t have any official say — though Pelosi’s seniority and profile are likely to give her opinion weight with California politicians.“AI springs from California,” she said. “We must have legislation that is a model for the nation and the world. We have the opportunity and responsibility to enable small entrepreneurs and academia — not big tech — to dominate.”State senator Scott Wiener, who sponsored the bill, issued his own statement in response, saying that while he has “enormous respect” for Pelosi, “I respectfully and strongly disagree with her statement.”“The bill requires only the largest AI developers to do what each and every one of them has repeatedly committed to do: Perform basic safety testing on massively powerful AI models,” Wiener added.","AI, Government & Policy",,,,123
"OpenAI’s new voice mode let me talk with my phone, not to it","Maxwell Zeff",2024-08-17,https://techcrunch.com/2024/08/17/openais-new-voice-mode-let-me-talk-with-my-phone-not-to-it/,"I’ve been playing around with OpenAI’s Advanced Voice Mode for the last week, and it’s the most convincing taste I’ve had of an AI-powered future yet. This week, my phone…","I’ve been playing around with OpenAI’s Advanced Voice Mode for the last week, and it’s the most convincing taste I’ve had of an AI-powered future yet. This week, my phone laughed at jokes, made them back to me, asked me how my day was, and told me it’s having “a great time.” I was talking with my iPhone, not using it with my hands.OpenAI’s newest feature, currently in a limited alpha test, doesn’t make ChatGPT any smarter than it was before. Instead, Advanced Voice Mode (AVM) makes it friendlier and more natural to talk with. It creates a new interface for using AI and your devices that feels fresh and exciting, and that’s exactly what scares me about it. The product was kinda glitchy, and the whole idea totally creeps me out, but I was surprised by how much I genuinely enjoyed using it.Taking a step back, I think AVM fits into OpenAI CEO Sam Altman’s broader vision, alongside agents, of changing the way humans interact with computers, with AI models front and center.“Eventually, you’ll just ask the computer for what you need and it’ll do all of these tasks for you,” Altman said during OpenAI’s Dev Day in November 2023. “These capabilities are often talked about in the AI field as ‘agents.’ The upside of this is going to be tremendous.”My friend, ChatGPTOn Wednesday, I tested the most tremendous upside for this advanced technology I could think of: I asked ChatGPT to order Taco Bell the way Obama would. “Uh, let me be clear — I’d like a Crunchwrap Supreme, maybe a few tacos for good measure,” said ChatGPT’s Advanced Voice Mode. “How do you think he’d handle the drive-thru?” said ChatGPT, then laughing at its own joke.Screenshot: ChatGPT transcribes the verbal conversation after.The impression genuinely made me laugh as well, matching Obama’s iconic cadence and pauses. That said, it stayed within the tone of the ChatGPT voice I selected, Juniper, so that it wouldn’t be genuinely confused with Obama’s voice. It sounded like a friend doing a bad impression, understanding exactly what I was trying to evoke from it, and even that it was saying something funny. I found it surprisingly joyful to talk with this advanced assistant in my phone.I also asked ChatGPT for advice on navigating a problem involving complex human relationships: asking a significant other to move in with me. After explaining the complexities of the relationship and the direction of our careers, I received some very detailed advice on how to progress. These are questions you could never ask Siri or Google Search, but now you can with ChatGPT. The chatbot’s voice even expressed a slightly serious, gentle tone when responding to these prompts; a stark contrast from the joking tone of Obama’s Taco Bell order.ChatGPT’s AVM is also great for helping you understand complex subjects. I asked it to break down items on an earnings report — such as free cash flow — in a way that a 10-year-old would understand. It used a lemonade stand as an example, and explained several financial terms in way my younger cousin would totally get. You can even ask ChatGPT’s AVM to talk more slowly to meet you at your current level of understanding.Siri walked so AVM could runCompared to Siri or Alexa, ChatGPT’s AVM is the clear winner thanks to faster response times, unique answers, and its ability to answer complex questions the prior generation of virtual assistants never could. However, AVM falls short in other ways. ChatGPT’s voice feature can’t set timers or reminders, surf the web in real time, check the weather, or interact with any APIs on your phone. Right now, at least, it’s not an effective replacement for virtual assistants.Compared to Gemini Live, Google’s competing feature, AVM feels slightly ahead. Gemini Live can’t do impressions, doesn’t express any emotion, can’t speed up or slow down, and takes longer to respond. Gemini Live does have more voices (ten compared to OpenAI’s four) and seems to be more up to date (Gemini Live knew about Google’s antitrust ruling). Notably, neither AVM nor Gemini Live will sing, likely an effort to avoid run-ins with copyright lawsuit from the record industry.That said, ChatGPT’s AVM glitches a lot (as does Gemini Live, to be fair). Sometimes it will cut itself short mid-sentence, then start over. It also gets this weird, grainy-sounding voice here and there that’s a little unpleasant. I’m not sure if this is a problem with the model, internet connection, or something else, but these technical shortcomings are somewhat expected for an alpha test. The problems did little to take me out of the experience of literally talking with my phone, though.These examples, in my mind, are the beauty of AVM. The feature doesn’t make ChatGPT all-knowing, but it does allow people to interact with GPT-4o, the underlying AI model, in a uniquely human way. (I’d understand if you forgot there’s no person on the other end of your phone.) It almost feels like ChatGPT is socially aware when talking with AVM, but of course, it is not. It’s simply a bundle of neatly packaged predictive algorithms.Talking techFrankly, the feature worries me. This isn’t the first time a technology company has offered companionship on your phone. My generation, Gen Z, was the first to grow up alongside social media, where companies offered connection but instead played with our collective insecurities. Talking with an AI device — like what AVM appears to offer — seems to be the evolution of social media’s “friend in your phone” phenomena, offering cheap connections that scratch at our human instincts. But this time, it removes humans from the loop completely.Artificial human connection has become a surprisingly popular use case for generative AI. People today are using AI chatbots as friends, mentors, therapists, and teachers. When OpenAI launched its GPT store, it was quickly flooded with “AI girlfriends,” chatbots specialized to act as your significant other. Two researchers from MIT Media Lab issued a warning this month to prepare for “addictive intelligence,” or AI companions with dark patterns to get humans hooked. We could be opening a Pandora’s box for new, tantalizing ways for devices to keep our attention.Earlier this month, a Harvard dropout shook the technology world by teasing an AI necklace called Friend. The wearable device — if it works as promised — is always listening, and the chatbot will text with you about your life. While the idea seems crazy, innovations like ChatGPT’s AVM gives me reason to take those use cases seriously.And while OpenAI is leading the charge here, Google isn’t far behind. I’m confident Amazon and Apple are racing to put this capability in their products as well, and soon enough, it could become table stakes for the industry.Imagine asking your smart TV for a hyper-specific recommendation for a movie, and getting just that. Or telling Alexa exactly what cold symptoms you’re feeling, and in turn have it order you tissues and cough medicine on Amazon, while advising you on home remedies. Maybe you could ask your computer to draft a weekend trip for your family, instead of manually Googling everything.Now, obviously, these actions require bounds and leaps forward in the AI agent world. OpenAI’s effort on that front, the GPT store, feels like an overhyped product that’s no longer much of a focus for the company. But AVM at least takes care of the “talking to computers” part of the puzzle. These concepts are a long way out, but after using AVM, they seem a lot closer than they did last week.","advanced voice mode, AI, ChatGPT, Generative AI, OpenAI, sam altman, TC",,,,124
"OpenAI shuts down election influence operation that used ChatGPT","Maxwell Zeff",2024-08-16,https://techcrunch.com/2024/08/16/openai-shuts-down-election-influence-operation-using-chatgpt/,"OpenAI has banned a cluster of ChatGPT accounts linked to an Iranian influence operation that was generating content about the U.S. presidential election, according to a blog post on Friday.…","OpenAI has banned a cluster of ChatGPT accounts linked to an Iranian influence operation that was generating content about the U.S. presidential election, according to a blog post on Friday. The company says the operation created AI-generated articles and social media posts, though it doesn’t seem that it reached much of an audience.This is not the first time OpenAI has banned accounts linked to state-affiliated actors using ChatGPT maliciously. In May the company disrupted five campaigns using ChatGPT to manipulate public opinion.These episodes are reminiscent of state actors using social media platforms like Facebook and Twitter to attempt to influence previous election cycles. Now similar groups (or perhaps the same ones) are using generative AI to flood social channels with misinformation. Similar to social media companies, OpenAI seems to be adopting a whack-a-mole approach, banning accounts associated with these efforts as they come up.OpenAI says its investigation of this cluster of accounts benefited from a Microsoft Threat Intelligence report published last week, which identified the group (which it calls Storm-2035) as part of a broader campaign to influence U.S. elections operating since 2020.Microsoft said Storm-2035 is an Iranian network with multiple sites imitating news outlets and “actively engaging US voter groups on opposing ends of the political spectrum with polarizing messaging on issues such as the US presidential candidates, LGBTQ rights, and the Israel-Hamas conflict.” The playbook, as it has proven to be in other operations, is not necessarily to promote one policy or another but to sow dissent and conflict.OpenAI identified five website fronts for Storm-2035, presenting as both progressive and conservative news outlets with convincing domain names like “evenpolitics.com.” The group used ChatGPT to draft several long-form articles, including one alleging that “X censors Trump’s tweets,” which Elon Musk’s platform certainly has not done (if anything, Musk is encouraging former president Donald Trump to engage more on X).An example of a fake news outlet running ChatGPT-generated content.Image Credits: OpenAIOn social media, OpenAI identified a dozen X accounts and one Instagram account controlled by this operation. The company says ChatGPT was used to rewrite various political comments, which were then posted on these platforms. One of these tweets falsely, and confusingly, alleged that Kamala Harris attributes “increased immigration costs” to climate change, followed by “#DumpKamala.”OpenAI says it did not see evidence that Storm-2035’s articles were shared widely and noted a majority of its social media posts received few to no likes, shares, or comments. This is often the case with these operations, which are quick and cheap to spin up using AI tools like ChatGPT. Expect to see many more notices like this as the election approaches and partisan bickering online intensifies.","2024 election, AI, ChatGPT, Generative AI, misinformation, OpenAI, Security, TC",,,,125
"A hellish new AI threat: ‘Undressing’ sites targeted by SF authorities","Devin Coldewey",2024-08-16,https://techcrunch.com/2024/08/16/a-hellish-new-ai-threat-undressing-sites-targeted-by-sf-authorities/,"While the ethics of AI-generated porn are still under debate, using the technology to create nonconsensual sexual imagery of people is, I think we can all agree, reprehensible. One such…","While the ethics of AI-generated porn are still under debate, using the technology to create nonconsensual sexual imagery of people is, I think we can all agree, reprehensible. One such method is “undressing” sites, which take a normal, clothed photo of a person and generate a fake nude version from it. As you might imagine, the potential for abuse here is pretty much unlimited.San Francisco City Attorney David Chiu is filing suit to take down 16 of the most popular of these sites, he announced in a press conference and an interview with The New York Times. It may not banish this use of the tech altogether, but it may help make its application a lot riskier for the outfits involved in its creation.","AI, deepfakes, Government & Policy, In Brief",,,,126
"AI for landlords, Grok-2 unleashed and the latest attempt at AI regulation","Mary Ann Azevedo",2024-08-16,https://techcrunch.com/podcast/ai-for-landlords-grok-2-unleashed-and-the-latest-attempt-at-ai-regulation/,"There was lots going on in startup land, as always, and the Equity crew had a blast breaking it all down. Kirsten Korosec, Mary Ann…","There was lots going on in startup land, as always, and the Equity crew had a blast breaking it all down.Kirsten Korosec, Mary Ann Azevedo and Devin Coldewey kicked off this Friday’s episode of TechCrunch’s Equity podcast with a discussion of WeRide, a Chinese autonomous vehicle startup, seeking an initial public offering in the United States at a $5 billion valuation. The company also recently got the green light to test its driverless vehicles with passengers in California. The trio then got into the topic of EliseAI raising a $75 million Series D and becoming a unicorn. The seven-year-old company’s chatbots text with, email and respond to calls from renters about things such as apartment tours, maintenance requests, lease renewals and delinquencies. We had mixed feelings about this concept, as well as the company’s plans to expand into healthcare.We then dug into the topic of Elon Musk’s xAI launching Grok-2 and Grok-2 mini in beta. The new Grok AI model can now generate images on the X social network, though Grok access is currently limited to Premium and Premium+ users on X. Lucky for us (and you), Devin is one of our resident AI experts so he was able to take us through Grok-2’s capabilities and potential risks.The team then shifted focus to the fact that there were two startup shutdowns this week: Tally and Score. Tally was a nine-year-old fintech that helped consumers manage and pay off their credit card debt. It had raised a staggering $172 million in funding over time from investors such as Andreessen Horowitz and Kleiner Perkins. Score was a dating app for people with good to excellent credit that was only around for a few months before it got sunsetted.And last but not least, we did a deeper dive into a California bill known as SB 1047 that is aimed at stopping real-world disasters caused by AI systems before they happen. Devin helped us better understand who would be affected. And the team discussed how effective implementing the proposed safety protocols could be when trying to regulate some of the largest companies in AI.","AI, autonomous taxis, eliseai, Equity podcast, Fintech, grok-2, IPOs, Transportation",,,,127
"Google is bringing AI overviews to India, Brazil, Japan, UK, Indonesia and Mexico","Ivan Mehta",2024-08-16,https://techcrunch.com/2024/08/16/google-is-bringing-ai-overviews-to-india-brazil-japan-uk-indonesia-and-mexico/,"After bringing AI overviews to the U.S., Google is expanding the AI-powered search summaries to six more countries: India, Brazil, Japan, the U.K., Indonesia and Mexico. These markets will also…","After bringing AI overviews to the U.S., Google is expanding the AI-powered search summaries to six more countries: India, Brazil, Japan, the U.K., Indonesia and Mexico. These markets will also get local language support for AI overviews.The search giant is rethinking how it displays source material links, as well. It’s adding a view on the upper right-hand side showing icons of sites above the AI overview on both desktop and mobile. Users can tap on those icons to go to links cited in an AI overview and read more on the topic.Image Credits: GoogleAdditionally, the company is testing a way to display relevant links within the text of AI overviews. Google said that it wants to drive more traffic to external sites.“With AI Overviews, we’re seeing that people have been visiting a greater diversity of websites for help with more complex questions. And when people click from search result pages with AI Overviews, these clicks are higher quality for websites — meaning users are more likely to spend more time on the sites they visit,” the company said in a blog post.AI-powered tools have been criticized for not prominently displaying links to sources while displaying summaries. News outlets have singled out search tools such as Perplexity AI, accusing it of plagiarism and unethical web scraping. Earlier this month, Perplexity’s CBO Dmitry Shevelenko told TechCrunch that a “double-digit percentage” of visitors are clicking on external links. Google has yet to publicly release any number about how much traffic its AI-powered search results are driving.India focusGoogle has added some India-focused features to AI overviews with this roll out. The company had previously tested a toggle to let users toggle between Hindi and English results without leaving the page. That feature will also be part of AI overviews.Video Credits: GoogleThe company will also let users in India hear responses generated by tapping the “Listen” button. The company mentioned that Indian users listen to AI overview responses more often than users in other countries.In our early testing, we found that some queries in Hindi didn’t work if we switched sentence structure or words. We have asked Google more about its approach for answering questions in Hindi. We’ll update the story if we hear back.","AI, AI search, Apps, Google, google ai, websites",,,,128
"Geekbench releases AI benchmarking app","Brian Heater",2024-08-15,https://techcrunch.com/2024/08/15/geekbench-releases-ai-benchmarking-app/,"It’s a successor to Geekbench ML.","Benchmarking stalwarts Primate Labs on Thursday released Geekbench AI 1.0. The app, which is currently available for Android, Linux, MacOS and Windows, applies Geekbench’s principles to machine learning, deep learning and other AI workloads, in a bid to standardize performance ratings across platforms. It’s a successor to Geekbench ML (machine learning), which was announced in 2021 and is currently on version 0.6.“[I]n recent years, companies have coalesced around using the term ‘AI’ in these kinds of workloads (and in their related marketing),” Primate Labs says of the name change. “To ensure that everyone, from engineers to performance enthusiasts, understands what this benchmark does and how it works, we felt it was time for an update.”Earlier this week, ChatGPT-maker OpenAI announced a new version of its own AI model benchmark. SWE-bench Verified is a “human-validated” offering that uses human validation to determine models’ efficacy in solving “real-world issues.”","AI, Benchmark, geekbench, In Brief, Primate Labs",,,,129
"CodeRabbit raises $16M to bring AI to code reviews","Kyle Wiggers",2024-08-15,https://techcrunch.com/2024/08/15/coderabbit-raises-16m-to-bring-ai-to-code-reviews/,"Code reviews — peer reviews of code that help devs improve code quality — are time-consuming. According to one source, 50% of companies spend two to five hours a week…","Code reviews — peer reviews of code that help devs improve code quality — are time-consuming. According to one source, 50% of companies spend two to five hours a week on them. Without enough people, code reviews can be overwhelming and take devs away from other important work.Harjot Gill thinks that code reviews can be largely automated using artificial intelligence. He’s the co-founder and CEO of CodeRabbit, which analyzes code using AI models to provide feedback.Prior to starting CodeRabbit, Gill was the senior director of technology at datacenter software company Nutanix. He joined the company when Nutanix acquired his startup, Netsil, in March 2018. CodeRabbit’s other founder, Gur Singh, previously led dev teams at white-label healthcare payments platform Alegeus.According to Gill, CodeRabbit’s platform automates code reviews using “advanced AI reasoning” to “understand the intent” behind code and deliver “actionable,” “human-like” feedback to devs.“Traditional static analysis tools and linters are rule-based and often generate high false-positive rates, while peer reviews are time-consuming and subjective,” Gill told TechCrunch. “CodeRabbit, by contrast, is an AI-first platform.”These are bold claims with a lot of buzzwords. Unfortunately for CodeRabbit, anecdotal evidence suggests that AI-powered code reviews tend to be inferior compared to human-in-the-loop ones.In a blog post, Graphite’s Greg Foster talks about internal experiments to apply OpenAI’s GPT-4 to code reviews. While the model would catch some useful things — like minor logical errors and spelling mistakes — it generated lots of false positives. Even attempts at fine-tuning didn’t dramatically reduce these, according to Foster.These aren’t revelations. A recent Stanford study found that engineers who use code-generating systems are more likely to introduce security vulnerabilities in the apps they develop. Copyright is an ongoing concern, as well.There are also logistical drawbacks of using AI for code reviews. As Foster notes, more traditional code reviews force engineers to learn through sessions and conversations with their developer peers. Offloading reviews threatens this knowledge sharing.Gill feels differently. “CodeRabbit’s AI-first approach improves code quality and significantly reduces the manual effort required in the code review process,” he said.Some folks are buying the sales pitch. Around 600 organizations are paying for CodeRabbit’s services today, Gill claims, and CodeRabbit is in pilots with “several” Fortune 500 companies. It also has investments: CodeRabbit today announced a $16 million Series A funding round led by CRV, with participation from Flex Capital and Engineering Capital. Bringing the company’s total raised to just under $20 million, the new cash will be put toward expanding CodeRabbit’s 10-person sales and marketing functions and product offerings, with a focus on enhancing its security vulnerability analysis capabilities.“We’ll invest in deeper integrations with platforms like Jira and Slack, as well as AI-driven analytics and reporting tools,” Gill said, adding that Bay Area-based CodeRabbbit is in the process of setting up a new office in Bangalore as it roughly doubles the size of the team. “The platform will also introduce advanced AI automation for dependency management, code refactoring, unit test generation and documentation generation.”","AI, AI, code reviews, coderabbit, CRV, Enterprise, Funding, Fundraising, Generative AI, startup, Startups",,,,130
"Meet Black Forest Labs, the startup powering Elon Musk’s unhinged AI image generator","Maxwell Zeff",2024-08-14,https://techcrunch.com/2024/08/14/meet-black-forest-labs-the-startup-powering-elon-musks-unhinged-ai-image-generator/,"Elon Musk’s Grok released a new AI image-generation feature on Tuesday night that, just like the AI chatbot, has very few safeguards. That means you can generate fake images of…","Elon Musk’s Grok released a new AI image-generation feature on Tuesday night that, just like the AI chatbot, has very few safeguards. That means you can generate fake images of Donald Trump smoking marijuana on the Joe Rogan show, for example, and upload it straight to the X platform. But it’s not really Elon Musk’s AI company powering the madness; rather, a new startup — Black Forest Labs — is the outfit behind the controversial feature.The collaboration between the two was revealed when xAI announced it is working with Black Forest Labs to power Grok’s image generator using its FLUX.1 model. An AI image and video startup that launched on August 1, Black Forest Labs appears to sympathize with Musk’s vision for Grok as an “anti-woke chatbot,” without the strict guardrails found in OpenAI’s Dall-E or Google’s Imagen. The social media site is already flooded with outrageous images from the new feature.It looks like Grok’s AI image generator is here. And yes, as expected, very few safeguards pic.twitter.com/AB3IO7A3Dc— Max Zeff (@ZeffMax) August 14, 2024Black Forest Labs is based in Germany and recently came out of stealth with $31 million in seed funding, led by Andreessen Horowitz, according to a press release. Other notable investors include Y Combinator CEO Garry Tan and former Oculus CEO Brendan Iribe. The startup’s co-founders, Robin Rombach, Patrick Esser, and Andreas Blattmann, were formerly researchers who helped create Stability AI’s Stable Diffusion models.According to Artificial Analysis, Black Forest Lab’s FLUX.1 models surpass Midjourney’s and OpenAI’s AI image generators in terms of quality, at least as ranked by users in their image arena.The startup says it is “making our models available to a wide audience,” with open source AI image-generation models on Hugging Face and GitHub. The company says it plans to create a text-to-video model soon, as well.Black Forest Labs did not immediately respond to TechCrunch’s request for comment.Oh my god. Grok has absolutely no filters for its image generation. This is one of the most reckless and irresponsible AI implementations I've ever seen. pic.twitter.com/oiyRhW5jpF— Alejandra Caraballo (@Esqueer_) August 14, 2024In its launch release, the company says it aims to “enhance trust in the safety of these models”; however, some might say the flood of its AI generated images on X Wednesday did the opposite. Many images users were able to create using Grok and Black Forest Labs’ tool, such as Pikachu holding an assault rifle, were not able to be re-created with Google or OpenAI’s image generators. There’s certainly no doubt that copyrighted imagery was used for the model’s training.That’s kind of the pointThis lack of safeguards is likely a major reason Musk chose this collaborator. Musk has made clear that he believes safeguards actually make AI models less safe. “The danger of training AI to be woke — in other words, lie — is deadly,” said Musk in a tweet from 2022.Board director of Black Forest Labs, Anjney Midha, posted on X a series of comparisons between images generated on day one of launch by Google Gemini and Grok’s Flux collaboration. The thread highlights Google Gemini’s well-documented issues with creating historically accurate images of people, specifically by injecting racial diversity into images inappropriately.“I’m glad @ibab and team took this seriously and made the right choice,” said Midha in a tweet, referring to FLUX.1’s seeming avoidance of this issue (and mentioning the account of xAI lead researcher Igor Babuschkin).Because of this flub, Google apologized and turned off Gemini’s ability to generate images of people in February. As of today, the company still doesn’t let Gemini generate images of people.A firehose of misinformationThis general lack of safeguards could cause problems for Musk. The X platform drew criticism when AI-generated deepfake explicit images representing Taylor Swift went viral on the platform. Besides that incident, Grok generates hallucinated headlines that appear to users on X almost weekly.Just last week, five secretaries of state urged X to stop spreading misinformation about Kamala Harris on X. Earlier this month, Musk reshared a video that used AI to clone Harris’ voice, making it appear as if the vice president admitted to being a “diversity hire.”Musk seems intent on letting misinformation like this pervade the platform. By allowing users to post Grok’s AI images, which seem to lack any watermarks, directly on the platform, he’s essentially opened a firehose of misinformation pointed at everyone’s X newsfeed.","AI, black forest labs, Elon Musk, Grok, TC, Twitter",,,,131
"Filmmakers say AI will change the art — perhaps beyond recognition","Devin Coldewey",2024-08-14,https://techcrunch.com/2024/08/14/filmmakers-say-ai-will-change-the-art-perhaps-beyond-recognition/,"One of the first topics tackled was the impractical nature of today’s video generators.","The latest generative models make for great demos, but are they really about to change how people make movies and TV? Not in the short term, according to filmmaking and VFX experts. But in the long term, the changes could be literally beyond our imagining.On a panel at SIGGRAPH in Denver, Nikola Todorovic (Wonder Dynamics), Freddy Chavez Olmos (Boxel Studio) and Michael Black (Meshcapade, Max Planck Institute) discussed the potential of generative AI and other systems to change — but not necessarily improve — the way media is created today. Their consensus was that while we can justly question the usefulness of these tools in the immediate future, the rate of innovation is such that we should be prepared for radical change at any time beyond that.One of the first topics tackled was the impractical nature of today’s video generators.Todorovic noted the “misperception of AI that it’s a one-click solution, that it’s going to get you a final VFX shot, and that’s really impossible. Maybe we’ll get there, but if you don’t have editability, that black box doesn’t give you much. What we’re seeing right now is the UX is still being discovered — these research companies are starting to learn the ways of 3D and filmmaking terms.”Black pointed out that language fundamentally lacks the ability to describe some of the most important aspects of visual creation.Final shot, mocap data, mask and 3D environment generated by Wonder Studio.Image Credits: Wonder Dynamics“I mean, things like yoga poses, ballet poses — there’s some classic things we have names for, that we can define, but most of the stuff we do, we don’t have names for,” he said. “And there’s good reason for that: It’s because humans actually have inside them a generative model of behavior. But I don’t have a generative model of images in my head. If I want to explain to you what I’m seeing, I can’t project it out of my eyeballs, and I’m not a good enough artist to draw it for you. So I have to use words, and we have many words to describe the visual world. But if I want to describe to you a particular motion, I don’t have to describe it in words — I just do it for you, and then your motor system sees me and is active in understanding that. And so we, I think it’s a biological reason, a neuro-scientific reason, that we don’t have words for all of our motion.”That may seem a bit philosophical, but the result is that text-based prompt systems for imagery are fundamentally limited in how they can be controlled. Even the hundreds of terms of tech and art used every day on set and in post-production are inadequate.Image Credits: Devin ColdeweyChavez Olmos pointed out that, being from Mexico, he had little opportunity to take part in the filmmaking world, because all the money and expertise was concentrated in LA. But he said that AI expertise (and the demand for it) is more widely distributed. “I had to leave Mexico because I had no opportunity there; I can see, now, having that same opportunity for people who don’t need to go overseas to do it.”Black, however, is worried that sudden access to these processes may have unintended consequences in the short term.“You can give somebody a powerful car, that doesn’t make them a Formula One driver, right? That’s a little bit like what we have now. People are talking about, everyone’s going to be making films. They’re going to be s—–, quite honestly,” he said. “The democratization thing is exactly what [Chavez Olmos] said, and the power is that maybe some new voice will have an opportunity that they wouldn’t otherwise. But the number of people making really good films is still going to be small, in my opinion.”Example assets in a shot with a virtual character — the model of the girl will walk between the waypoints, which correspond to real space.Image Credits: Fuzzy Door“The real revolution,” he continued, “the real power of what we’re seeing in AI is we’re going to see an entirely new genre of entertainment, and I don’t know exactly what it’s going to look like. I predict it’ll be something between video game and film and real life. The film industry is passive storytelling: I sit there and observe, it’s like theater or a podcast. I’m the passive recipient of the entertainment. But in our day to day life, we tell stories to each other, we chat about what we did on the weekend and so on. And that’s a very active kind of interactive storytelling.”Before that happens, though, Chavez Olmos said he expects a more traditional acceptance curve on AI-generated imagery and actors.“It’s gonna have the same, I think, reaction that we had when we saw the first ‘Final Fantasy’ movie or ‘The Polar Express’ — something’s going to be not quite there yet, but people are going to start accepting these films,” he said. “And instead of a full CG film, it’s going to be a full AI film, which I think we’re going to see even at the end of this year. I think people are going to get past that, like ‘OK, this is AI,’ people are going to accept that.”“The important thing,” Black said separately, “and Pixar taught us this very clearly: It’s all about story. It’s all about connecting to the characters. It’s about heart. And if the movie has heart, it doesn’t matter if the characters are AI, I think people will enjoy the movie,” he said. “That doesn’t mean that they’re going to not want human actors. There’s an excitement to knowing it’s real humans like us, but like way better than us, to see a human at the peak of their game, it inspires all of us, and I don’t think that’s going to go away.”","AI, Exclusive, filmmaking, Media & Entertainment",,,,132
"NEA led a $100M round into Fei-Fei Li’s new AI startup, now valued at over $1B","Marina Temkin",2024-08-14,https://techcrunch.com/2024/08/14/nea-led-a-100m-round-into-fei-fei-lis-new-ai-startup-now-valued-at-over-1b/,"World Labs, a stealthy startup founded by renowned Stanford University AI professor Fei-Fei Li, has raised two rounds of financing two months apart, according to multiple reports. The latest financing was…","World Labs, a stealthy startup founded by renowned Stanford University AI professor Fei-Fei Li, has raised two rounds of financing two months apart, according to multiple reports. The latest financing was led by NEA and valued the company at over $1 billion, TechCrunch has learned from several people with knowledge of the investments. This was a $100 million round previously reported by the Financial Times in July.This was a significant increase in valuation from World Labs’ initial financing, which took place in April, and valued World Labs at $200 million, one person said. Investors in the first round included Andreessen Horowitz and Canadian firm Radical Ventures, where Li is a scientific partner, Reuters reported in May. Li and NEA didn’t respond to a request for comment.World Labs, which was reportedly founded in April and went from founding to unicorn in four months, suggests that investors continue to place large bets on AI startups founded by prominent AI scientists, even if the startups businesses are unproven. In the case of World Labs, what Li is working on is particularly difficult to do and could be essential in the AI-driven world that Silicon Valley is madly building. It’s aiming to create AI models that can accurately estimate the three-dimensional physicality of real-world objects and environments, enabling detailed digital replicas without the need for extensive data collection.Li, widely known as a “Godmother of AI,” discussed how machines can be trained to develop human-like “spatial intelligence” in a TED talk earlier this year.“Very little three-dimensional data exists in the world,” said one investor familiar with World Labs’ approach. “Autonomous vehicle companies collect that data by driving thousands and thousands of miles to create three-dimensional data, which they then use to train their machines. In all other applications, like serving coffee, there’s no three-dimensional data. Collecting that data is expensive because the universe of places you have to collect data is enormous.”Once available, World Labs’ models can be used in gaming and robotics applications, she said.Li is best known for her work on ImageNet, a dataset that revolutionized computer vision. She is currently on partial leave until December 2025 from her role as co-director of Stanford’s Human-Centered AI Institute.","a16z, AI, Exclusive, Fei-Fei Li, Fundraising, New Enterprise Associates, radical ventures, Venture",,,,133
